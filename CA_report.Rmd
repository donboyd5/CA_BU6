---
title: "California Bargaining Unit 6 Compensation Analysis"
author: "Don Boyd"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook:
    df_print: paged
    fig_height: 6
    fig_width: 8
    toc: yes
    toc_depth: 5
    toc_float: true
    number_sections: yes
editor_options:
  chunk_output_type: console
---

# Preparation
```{r links}
# https://download.bls.gov/pub/time.series/cm/
# NCS: https://download.bls.gov/pub/time.series/nb/
# https://www.pewtrusts.org/~/media/Assets/2014/08/StateEmployeeHealthCareReportSeptemberUpdate.pdf

```

```{r runall, eval=FALSE, echo=FALSE}
# When we want a final report, run the following code selectively "by hand" (interactively)
# -- NEVER using Knit with eval=TRUE
# note <br> breaks line for html output but \n should break for pdf; also could try |

rmdfn <- "CA_report.rmd" # this file
outfn <- paste0("report_", format(Sys.time(), "%Y-%m-%d"), ".html")
rmarkdown::render(rmdfn, output_format="html_document", output_file=outfn)

# library("RCurl")
# ftpUpload(outfn, "ftp://kffrig:boyd4812@files.000webhost.com/public_html/KFF_RIG_MedicaidCuts_new.html")

# Note may b safest to fully exit RStudio and restart it before running whole thing. Otherwise knitr may get confused
# and include repetitive information in the output html file.

```

```{r setup, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = FALSE, include=FALSE, eval=TRUE, message = FALSE, warning = FALSE,
                      rows.print=25,  # enough to allow summaries of regressions with many variables
                      fig.width=6, fig.height=8)
```


```{r libraries}

library(tidyverse)
options(tibble.print_max = 80, tibble.print_min = 80) # if more than 60 rows, print 60 - enough for states
library(scales)
library(lubridate)
library(purrr)
library(readxl)
# devtools::install_dev("vroom")
library(vroom)
library(haven)
library(RSQLite)

library(RcppRoll)

# data tools
library(Hmisc)
library(fastDummies)

library(arrow)

# graphs, maps and tables
library(kableExtra)
library(gt)
library(knitr)
library(maps)
# https://cran.r-project.org/web/packages/usmap/vignettes/mapping.html
library(usmap)
library(gridExtra)

library(ggbreak)
library(patchwork)
library(RColorBrewer)

library(fredr)

# econometrics
library(fixest)
library(fable)
# library(cgwtools)  # for resave

library(btools)
library(bdata)

# clustering
library(cluster)    # clustering algorithms
library(factoextra) # clustering visualization
library(dendextend) # for comparing two dendrograms

devtools::session_info()
```

# Introduction

The goals of this project are to address two main questions in relation to California Correctional Peace Officers (Bargaining Unit 6 -- BU6):

-   What do relevant available data say about:

    -   How unit members are compensated relative to appropriate comparisons, including other states and, to the extent practical, the private sector?
    -   How much higher or lower is their compensation?
    -   How has their absolute and relative compensation changed since the last compensation study (prepared in 2013, released in 2015)?

    In doing this, adjust for regional cost differences to the extent practical. Pay attention to the fact that salaries and benefits of new hires have changed in recent years.

-   What are the leverage points -- the key methodological and data choices that might influence what a new CalHR study would conclude?

```{r locations}
# acsdir <- r"(E:\data\acs\)"
# pumsdir <- paste0(acsdir, "pums/")
# csvdir <- paste0(pumsdir, "csv/")

rppdir <- r"(E:\data\BEA_regional_price_parities\)"

resdir <- r"(E:\data\oesw\oes_research\)"

wpid <- r"(E:\data\BLS_WorkplaceInjuries\)"

oeswcad <- r"(E:\data\oesw_caledd\)"

pumsdir <- r"(E:\data\acs\pums\)"
pumsdocs <- paste0(pumsdir, r"(5year\documentation\)")
fnpumscodes <- "ACSPUMS2015_2019CodeLists.xlsx"

sqlitedir <- r"(E:\data\acs\pums\sqlite\)"

acsfn <- "acs2019_5year"
acsdb <- paste0(sqlitedir, acsfn, ".sql3")

```

```{r constants}

# 33-3012	Correctional Officers and Jailers  OES code
# 3802 Correctional officers and jailers 33-3012   # occ code 2018
# NY, MA
# TX, FL
# AZ, NV, OR, WA

compstates <- c("AZ", "NV", "OR", "WA", # near neighbors
                "TX", "FL",  # large
                "NY", "MA")  # large, expensive

obs_cutoff <- 50

#.. ACS constants ----
acsvars_string <- "serialno, st, puma, powsp, powpuma, adjinc, pwgtp, agep, cow, mar, schl, sex, wagp, hisp, rac1p, occp, naicsp"

# define the filter definition for a worker so we  have it in only one place
# worker <- expression(wagp >= 10e3, agep >= 18)  # haven't gotten this to work
# sworker <- "schl > 15 & wagp >= 10e3 & agep >= 18"  # as a string - works with filter(eval(parse(text=sworker))), albeit awkward
sworker <- "wagp >= 10e3 & agep >= 18"  # as a string - works with


#.. graph theme items ----
legend_none <- theme(legend.position = "None")
legend_notitle <- theme(legend.title = element_blank())
caption_left <- theme(plot.caption = element_text(hjust = 0))

#.. ACS logical expressions and related ----
casco <- expression(stabbr=="CA" & soc=="33-3012" & level=="state")  # California state correctional officer
casco_pct <- function(mod) {exp(coef(mod)["cascoTRUE"]) - 1} # get casco premium from a model with casco dummy

#.. source notes ----
source_acs <- "U.S. Bureau of the Census, American Community Survey, 2015-2019 PUMS"
source_oesres <- "U.S. Bureau of Labor Statistics, Occupational Employment and Wage Statistics Research Database"
source_rpp <- "U.S. Bureau of Economic Analysis Regional Price Parities"
source_wpi <- "U.S. Bureau of Labor Statistics, Survey of Occupational Injuries and Illnesses"

```

<!-- Get previously created data, needed in the following sections. -->

```{r load_functions}
source(here::here("r", "functions_misc.r"))
source(here::here("r", "functions_ACS_factors.r"), echo=TRUE)

```


# ONETIME DATA CREATION

## Price measures

### National price indexes
```{r ONETIME_gdppi_cpi}

fred_apikey <- "a5e1199baac333154cbffcba3b263c28"
fredr_set_key(fred_apikey)

# Gross domestic product (chain-type price index)
# FRED https://fred.stlouisfed.org/series/A191RG3A086NBEA
price <- fredr("A191RG3A086NBEA", frequency = "a")
gdppi <- price %>%
  rename(gdppi=value) %>%
  mutate(year=year(date),
         igdppi=gdppi[year==2020] / gdppi) %>%
  select(year, gdppi, igdppi)
saveRDS(gdppi, here::here("data", "gdppi.rds"))

# CPI 2015=100
# https://fred.stlouisfed.org/series/CPALTT01USA661S
cpi <- fredr("CPALTT01USA661S", frequency = "a") %>%
  rename(cpi=value) %>%
  mutate(year=year(date),
         icpi=cpi[year==2020] / cpi) %>%
  select(year, cpi, icpi) %>%
  filter(!is.na(cpi))
saveRDS(cpi, here::here("data", "cpi.rds"))

```

### Regional price measures

This section:

-   Gets regional price parity indexes (i.e., regional price indexes) from the [Bureau of Economic Analysis](https://apps.bea.gov/regional/downloadzip.cfm) (BEA) for states, Metropolitan Statistical Areas (MSAs), and the metro-nonmetro areas of individual states, for all available years (2008-2019).
-   Parses the data and saves for later use.

We need these data because we want to adjust for regional price differences when comparing correctional officer salaries across states, and when comparing these salaries to private sector salaries in different regions of California.

```{r rpp_info}

# https://apps.bea.gov/regional/downloadzip.cfm
# SARPP.zip is states
# MARPP.zip is metropolitan areas
# PARPP.zip is metro/non-metro areas within states


# https://www.bea.gov/news/2020/real-personal-income-state-and-metropolitan-area-2019
# Regional Price Parities in 2019
# 
# Regional price parities (RPPs) measure the differences in price levels across states and metropolitan areas for a given year and are expressed as a percentage of the overall national price level. The all items RPP covers all consumption goods and services, including housing rents. Areas with high/low RPPs typically correspond to areas with high/low price levels for rents.
# 
# States with the highest RPPs were Hawaii (119.3), California (116.4), and New York (116.3) (table 3).
# States with the lowest RPPs were Mississippi (84.4), Arkansas (84.7), and Alabama (85.8).
# Across states, California had the highest RPP for housing rents (153.6), and Mississippi had the lowest (60.0).
# Large metropolitan areas with the highest RPPs were San Francisco-Oakland-Berkeley, CA (134.5), New York-Newark-Jersey City, NY-NJ-PA (125.7), and Los Angeles-Long Beach-Anaheim, CA (118.8) (table 6).
# Large metropolitan areas with the lowest RPPs were Cleveland-Elyria, OH (89.9), St. Louis, MO-IL (90.1), and Cincinnati, OH-KY-IN (90.6).
# Across large metropolitan areas, San Francisco-Oakland-Berkeley, CA, had the highest RPP for housing rents (200.3), and Cleveland-Elyria, OH, had the lowest (76.3).
# Across all metropolitan areas, San Jose-Sunnyvale-Santa Clara, CA, had the highest RPP for housing rents (224.0), and Beckley, WV, had the lowest (44.0).
```


```{r ONETIME_get_rpp, eval=FALSE}
# https://www.bea.gov/data/prices-inflation/regional-price-parities-state-and-metro-area
# 12/21/2021 I downloaded the files by hand because I could not find static urls
mpath <- here::here("data_raw", "MARPP.zip")
ppath <- here::here("data_raw", "PARPP.zip")
spath <- here::here("data_raw", "SARPP.zip")
unzip(mpath, list=TRUE) # MARPP_MSA_2008_2020.csv
unzip(ppath, list=TRUE) # PARPP_PORT_2008_2020.csv # metro / non-metro PORTions
unzip(spath, list=TRUE) # SARPP_STATE_2008_2020.csv


#.. state regional price parities ----
# read directly from zip file
sarpp1 <- read_csv(unz(spath,
                    "SARPP_STATE_2008_2020.csv"), 
                col_types = cols(.default = "c"))

#.... save data for CA for purposes of report text ----
tab <- sarpp1 %>%
  filter(GeoName=="California") %>%
  select(GeoName, LineCode, Description, `2015`:`2020`) %>%
  gt()
gtsave(tab, filename="ca_rpp.png", path=here::here("results"))

sarpp2 <- sarpp1 %>%
  filter(LineCode=="1") %>%
  mutate(stfips=str_sub(GeoFIPS, 1, 2)) %>%
  left_join(stcodes %>% select(stfips, stabbr), by = "stfips")
sarpp2 %>% select(stfips, stabbr, GeoName)
  
sarpp <- sarpp2 %>%
  pivot_longer(cols=`2008`:`2020`, names_to = "year", values_to = "rpp") %>%
  mutate(stfips=as.integer(stfips), year=as.integer(year), rpp=as.numeric(rpp) / 100) %>%
  select(stabbr, stfips, year, rpp)

#.. metropolitan area indexes ----
marpp1 <- read_csv(unz(mpath,
                    "MARPP_MSA_2008_2020.csv"), 
                col_types = cols(.default = "c"))

marpp <- marpp1 %>%
  filter(LineCode=="1") %>%
  pivot_longer(cols=`2008`:`2020`, names_to = "year", values_to = "rpp") %>%
  mutate(fips=as.integer(GeoFIPS), 
         year=as.integer(year), 
         rpp=as.numeric(rpp) / 100) %>%
  select(fips, geoname=GeoName, year, rpp)

#.. metro-nonmetro by state price indexes ----
zname <- "PARPP.zip"
fn <- "PARPP_PORT_2008_2019.csv"
con <- unz(paste0(rppdir, zname), fn) # read directly from zip file
df <- read_csv(con, col_types = cols(.default = "c"))
glimpse(df)

parpp1 <- read_csv(unz(ppath,
                    "PARPP_PORT_2008_2020.csv"), 
                col_types = cols(.default = "c"))

parpp <- parpp1 %>%
  filter(LineCode=="1") %>%
  pivot_longer(cols=`2008`:`2020`, names_to = "year", values_to = "rpp") %>%
  mutate(type=case_when(str_sub(GeoFIPS, 3, 5)=="998" ~ "metro",
                        str_sub(GeoFIPS, 3, 5)=="999" ~ "nonmetro",
                        str_sub(GeoFIPS, 3, 5)=="000" ~ "US",
                        TRUE ~ "ERROR"),
         stfips=str_sub(GeoFIPS, 1, 2),
         year=as.integer(year), 
         rpp=as.numeric(rpp) / 100) %>%
  left_join(stcodes %>% select(stfips, stabbr), by = "stfips") %>%
  mutate(stfips=as.integer(stfips)) %>%
  select(stfips, stabbr, geoname=GeoName, type, year, rpp)

#.. which metropolitan areas are in California ----
carpp <- marpp %>%
  filter(str_detect(geoname, coll("CA"))) %>%
  mutate(stabbr="CA", type="metro") %>%
  bind_rows(parpp %>%
              filter(type=="nonmetro", stabbr=="CA") %>%
              select(stabbr, geoname, type, year, rpp))
count(carpp, fips, geoname)


# create a lagyear variable for each file so that we can merge against 1 year earlier
sarpp <- sarpp %>% mutate(yearplus1=year + 1)
marpp <- marpp %>% mutate(yearplus1=year + 1)
carpp <- carpp %>% mutate(yearplus1=year + 1)

save(sarpp, marpp, carpp, file=here::here("data", "rpp.rdata"))


# There are 26 Californial regional price indexes
# fips  geoname                                                                  n
#    <chr> <chr>                                                                <int>
#  1 12540 Bakersfield, CA (Metropolitan Statistical Area)                         12
#  2 17020 Chico, CA (Metropolitan Statistical Area)                               12
#  3 20940 El Centro, CA (Metropolitan Statistical Area)                           12
#  4 23420 Fresno, CA (Metropolitan Statistical Area)                              12
#  5 25260 Hanford-Corcoran, CA (Metropolitan Statistical Area)                    12
#  6 31080 Los Angeles-Long Beach-Anaheim, CA (Metropolitan Statistical Area)      12
#  7 31460 Madera, CA (Metropolitan Statistical Area)                              12
#  8 32900 Merced, CA (Metropolitan Statistical Area)                              12
#  9 33700 Modesto, CA (Metropolitan Statistical Area)                             12
# 10 34900 Napa, CA (Metropolitan Statistical Area)                                12
# 11 37100 Oxnard-Thousand Oaks-Ventura, CA (Metropolitan Statistical Area)        12
# 12 39820 Redding, CA (Metropolitan Statistical Area)                             12
# 13 40140 Riverside-San Bernardino-Ontario, CA (Metropolitan Statistical Area)    12
# 14 40900 Sacramento-Roseville-Folsom, CA (Metropolitan Statistical Area)         12
# 15 41500 Salinas, CA (Metropolitan Statistical Area)                             12
# 16 41740 San Diego-Chula Vista-Carlsbad, CA (Metropolitan Statistical Area)      12
# 17 41860 San Francisco-Oakland-Berkeley, CA (Metropolitan Statistical Area)      12
# 18 41940 San Jose-Sunnyvale-Santa Clara, CA (Metropolitan Statistical Area)      12
# 19 42020 San Luis Obispo-Paso Robles, CA (Metropolitan Statistical Area)         12
# 20 42100 Santa Cruz-Watsonville, CA (Metropolitan Statistical Area)              12
# 21 42200 Santa Maria-Santa Barbara, CA (Metropolitan Statistical Area)           12
# 22 42220 Santa Rosa-Petaluma, CA (Metropolitan Statistical Area)                 12
# 23 44700 Stockton, CA (Metropolitan Statistical Area)                            12
# 24 46700 Vallejo, CA (Metropolitan Statistical Area)                             12
# 25 47300 Visalia, CA (Metropolitan Statistical Area)                             12
# 26 49700 Yuba City, CA (Metropolitan Statistical Area)                           12

```


## Occupational Employment and Wage Statistics (OES or OESW) BLS Research database

This section downloads, parses, and saves:

-   [OES research data](https://www.bls.gov/oes/current/oes_research_estimates.htm) for the government sector, many years. This has the advantage of breaking out ownership (state, local government), by state, by detailed occupation, for many years.

We can get ownership for sector 99 but not for other sectors.

### Sector 99 OES research data
```{r oesres_codes}
# https://www.bls.gov/oes/current/oes_research_estimates.htm
# The OEWS program provides wage and employment estimates by state and industry
# beginning with the May 2012 reference period. These estimates are intended for
# research purposes, and users should be aware of the limitations of the data.
# Estimates prior to May 2012 are not available. Estimates are only available
# for states; industry-specific estimates for metropolitan areas are not
# available. Estimates are only available for detail and major occupation
# groups; industry-specific estimates for broad and minor occupation groups are
# not available.

urlbase <- "https://www.bls.gov/oes/special.requests/"

stcodes
# Add Guam to stcodes
stcodes2 <- bind_rows(stcodes,
                      tibble(stabbr="GU", stfips="66", stname="Guam"))

```

```{r ONETIME_bls_oes_research_naics99, eval=FALSE}

#.. NAICS 99 has federal, state, and local govt separately ----
# https://www.bls.gov/oes/special.requests/oes_research_2012_sec_99.xlsx
f2 <- function(year){
  print(year)
  fname <- paste0("oes_research_", year, "_sec_99.xlsx")
  upath <- paste0(urlbase, fname)
  dlpath <- paste0(resdir, fname)
  print(dlpath)
  download.file(upath, dlpath, mode = "wb")
}

purrr::map(2012:2020, f2)

(fnames <- paste0("oes_research_", 2012:2020, "_sec_99.xlsx"))
(fpaths <- paste0(resdir, fnames))

df <- read_excel(fpaths[1], sheet="data")

year <- 2012

str_subset(fpaths, "2012")

f <- function(year){
  print(year)
  fpath <- str_subset(fpaths, as.character(year))
  df <- read_excel(fpath, sheet=1, col_type="text") %>%
    setNames(str_to_lower(names(.))) %>%
    mutate(year=!!year)
  df
}

df <- purrr::map_dfr(2012:2020, f)
glimpse(df)

df2 <- df %>%
  mutate(occ=ifelse(is.na(`occ code`), occ_code, `occ code`),
         occname=ifelse(is.na(`occ title`), occ_title, `occ title`)) %>%
  mutate(across(c(tot_emp:hourly, pct_total), as.numeric)) %>%
  select(-c(occ_code, `occ code`, occ_title, `occ title`))

glimpse(df2)
count(df2, occ, occname)
count(df2, area, area_title)  # 54 -- states + DC, Guam, Puerto Rico, Virgin Islands
count(df2, year)


df3 <- df2 %>%
  left_join(stcodes2 %>% select(area=stfips, stabbr), by="area") %>%
  select(stabbr, year, occ, occname, everything())
count(df3, stabbr)

df3 %>%
  filter(stabbr=="CA", year==2012, occ=="33-3012")

saveRDS(df3, paste0(resdir, "oesres_sec99.rds"))

```

```{r ONETIME_bls_oes_research_all_download, eval=FALSE}

#.. All NAICS sectors for 2016-2020 ----

f1 <- function(year){
  print(year)
  fname <- paste0("oes_research_", year, "_allsectors.xlsx")
  upath <- paste0(urlbase, fname)
  dlpath <- paste0(resdir, fname)
  print(dlpath)
  download.file(upath, dlpath, mode = "wb")
}
purrr::map(2016:2020, f1)
# 2016 area	area_title	naics	naics_title	occ code	occ title	group	i_group	tot_emp	emp_prse	pct_total	h_mean	a_mean	mean_prse	h_pct10	h_pct25	h_median	h_pct75	h_pct90	a_pct10	a_pct25	a_median	a_pct75	a_pct90	annual	hourly
# 2020 AREA	AREA_TITLE	NAICS	NAICS_TITLE	I_GROUP	OCC_CODE	OCC_TITLE	O_GROUP	TOT_EMP	EMP_PRSE	PCT_TOTAL	H_MEAN	A_MEAN	MEAN_PRSE	H_PCT10	H_PCT25	H_MEDIAN	H_PCT75	H_PCT90	A_PCT10	A_PCT25	A_MEDIAN	A_PCT75	A_PCT90	ANNUAL	HOURLY
```

```{r ONETIME_bls_oes_research_all, eval=FALSE}
(fnames <- paste0("oes_research_", 2016:2020, "_allsectors.xlsx"))
(fpaths <- paste0(resdir, fnames))

df <- read_excel(fpaths[1], sheet=1)

# make one big file
g <- function(x){
  x <- str_replace_all(x, "`", "")
  str_replace_all(x, " ", "_")
}
# g("`occ code`")
f1a <- function(year){
  # read a year, fix variable names
  print(year)
  fpath <- str_subset(fpaths, as.character(year))
  df <- read_excel(fpath, sheet=1, col_type="text") %>%
    setNames(str_to_lower(names(.))) %>%
    rename_with(.fn=g) %>%
    mutate(year=!!year)
  df
}
df <- purrr::map_dfr(2016:2020, f1a)
glimpse(df)
count(df, year)

df2 <- df %>%
  mutate(across(c(tot_emp:hourly, hourly), as.numeric))
glimpse(df2)

df3 <- df2 %>%
  left_join(stcodes2 %>% select(area=stfips, stabbr), by="area") %>%
  select(stabbr, year, occ=occ_code, occname=occ_title, everything())
count(df3, stabbr)

df3 %>%
  filter(stabbr=="CA", year==2020, occ=="33-3012")

saveRDS(df3, paste0(resdir, "oesres_allsectors.rds"))

# clean up and slim down the externally created file
oesres1 <- readRDS(paste0(resdir, "oesres_allsectors.rds"))
glimpse(oesres1)
count(oesres1, stabbr, area, area_title)
count(oesres1, annual) # 24641=1, 4.5m=NA  # record does not have hourly data
count(oesres1, hourly)  # record does not have annual data
count(oesres1, o_group)  # for some years, tells whether it is detailed, major, total, or something else
count(oesres1, group) # same
count(oesres1, group, o_group)
count(oesres1, i_group)


oesres2 <- oesres1 %>%
  filter(stabbr %in% c("DC", state.abb)) %>%
  mutate(ogroup=ifelse(is.na(o_group), group, o_group)) %>%
  select(stabbr, year, occ, occname, ogroup,
         igroup=i_group, naics, naicstitle=naics_title, 
         emp=tot_emp, hmean=h_mean, amean=a_mean)
count(oesres2, ogroup)

count(oesres2, naics, naicstitle)

# assign level to corrections (why not to all naics 99ish??)
f_corrlevel <- function(occ, naics){
  case_when(occ != "33-3012" ~ NA_character_,
            naics %in% c("99", "999000") ~ "fslg",
            naics == "999100" ~ "federal",
            naics == "999200" ~ "state",
            naics == "999300" ~ "local",
            TRUE ~ "private")
  }

oesres3 <- oesres2 %>%
  mutate(level=f_corrlevel(occ, naics))
count(oesres3, level)

saveRDS(oesres3, paste0(resdir, "oesres_clean.rds"))

```

```{r oesres_compare, include=FALSE}
# compare the all sectors and sector 99 data for one state and year
dfall <- readRDS(paste0(resdir, "oesres_clean.rds")) # 2016-2019
dfall <- dfall %>% filter(stabbr=="CA", year==2020)
count(dfall, stabbr) # 51 incl dc
count(dfall, igroup) # 3-6 and sector
count(dfall, ogroup, igroup)
count(dfall %>% filter(occ=="33-3012"), ogroup, igroup) # detailed 3, 4, and sector
dfall %>% filter(occ=="33-3012")  # we want detailed 4-digit (which is just 4-digit)

df99 <- readRDS(paste0(resdir, "oesres_sec99.rds"))
df99 <- df99 %>% filter(stabbr=="CA", year==2020)

comp <- bind_rows(dfall %>% mutate(type="sec99"),
                  dfall %>% mutate(type="secall")) %>%
  filter(occ=="33-3012") %>%
  arrange(occ, igroup, naics, type)
# good, they have the same numbers, so we only need the "clean" file if we are just using one year

```


### California EDD OESW data for California

```{r caledd_oesw, eval=FALSE}
# from open data
url <- "https://data.edd.ca.gov/api/views/pwxn-y2g5/rows.csv?accessType=DOWNLOAD"
fn <- "Occupational_Employment_and_Wage_Statistics__OEWS_.csv"
# download.file(url, paste0(oeswcad, fn), mode="wb")  # only download if data base changed

df1 <- read_csv(paste0(oeswcad, fn), col_types=cols(.default = "c"))
glimpse(df1)
summary(df1)

df2 <- df1 %>%
  select(atype=1, aname=2, year=3, qtr=4, indname=5, soc=6, occname=7, wtype=8, emp=9, wage=10)
count(df2, atype) # 4
# California-Statewide	1598			
# California - Statewide	19438			
# Metropolitan Area	355428			
# OES Survey Region	38744	
count(df2, atype, aname)  # 43
count(df2, indname)  # 1, all industries
count(df2, soc, occname)  # 1,110
count(df2, wtype)  # 2 Annual wage or salary, Hourly wage
count(df2, qtr)  # only 1

# qy(1, 2000) qtr <- c("1", "2") year <- c("2000", "2001") btools::qy(as.integer(qtr), as.integer(year))

df3 <- df2 %>%
  filter(str_detect(wtype, "Annual")) %>%
  select(atype, aname, year, soc, occname, emp, wage) %>%
  mutate(year=as.integer(year),
         emp=as.numeric(emp),
         wage=as.numeric(wage),
         soc=ifelse(soc=="0",
                    soc,
                    paste0(str_sub(soc, 1, 2), "-", str_sub(soc, 3, -1))))
count(df3, soc, occname)

# fix some errors in the data!
df4 <- df3 %>%
  # wow! shouldn't have to fix this
  mutate(emp=ifelse(emp==0, NA_real_, emp),
         wage=ifelse(wage==0, NA_real_, wage),
         occname=str_replace(occname, coll(" **"), ""),
         occname=str_replace(occname, coll("*"), ""))

diffnames <- df4 %>%
  select(soc, year, occname) %>%
  distinct() %>%
  group_by(soc) %>%
  mutate(nnames=length(unique(occname))) %>%
  ungroup %>%
  filter(nnames > 1) %>%
  arrange(soc, year)

# get most recent occname for each code
df5 <- df4  %>%
  group_by(soc) %>%
  mutate(mroccname=unique(occname[year==max(year)])) %>%
  ungroup

check <- df5 %>% filter(mroccname != occname)

caledd_oesw <- df5 %>%
  select(atype, aname, year, soc, occname=mroccname, emp, wage)
saveRDS(caledd_oesw, here::here("data", "caledd_oesw.rds"))

```


## American Community Survey (ACS) data preparation

This section has two subsections:

-   Preparation of codes needed for use with the ACS
-   Preparation of the two main ACS data subsets used in the analysis, extracting relevant information from an SQLITE database of the ACS. This program does not get the full ACS - I did that in a separate program that downloaded the ACS and created the SQLITE database. That was done separately because of the size of the ACS.

### Preparation of ACS codes

#### Define a "worker"

This section defines variables to pull from the ACS, and what a "worker" is:

-   The 2015-2019 ACS is a sample of approximately 15 million people nationally.
-   Only some of them are workers (some are children, some are retired, some are prisoners, some are unemployed, etc.)
-   Currently I define a worker as someone who:
-   Is an employee of a private not-for-profit or for-profit entity, or a federal, state, or local government employee. I exclude anyone who is self-employed, or working without pay on a family business or farm, or was unemployed; and
-   Is at least 18 years old
-   Earned at least $10,000

We need to define a worker for purposes of comparing correctional officer wages to those of other workers. The definition here is based largely on definitions used in academic papers that estimate wage regressions.


#### Get a crosswalk of occupation codes

This section:

-   Gets a [crosswalk](https://www2.census.gov/programs-surveys/acs/tech_docs/pums/code_lists/ACSPUMS2015_2019CodeLists.xlsx) between occupation codes used by the Bureau of the Census in the ACS and the somewhat more detaled occupation codes maintained by the Bureau of Labor Statistics and also CalHR (California Human Resources)
-   Parses and saves the data for later use.

We need this crosswalk so that we can (a) identify correctional officers and people in other occupations, and (b) collapse identify selected occupations that are similar in some way to correctional officers.

```{r acs_occ_codes, eval=FALSE}
acsocodes1 <- read_excel(paste0(pumsdocs, fnpumscodes),
                      sheet="OCCP & SOCP",
                      range="A11:C881",
                      col_names=c("occp", "soc", "occname"))
acsocodes <- acsocodes1 %>%
  filter(nchar(occp)==4) %>%
  mutate(occp=as.integer(occp))

saveRDS(acsocodes, here::here("data", "acsocodes.rds"))

# https://www.labormarketinfo.edd.ca.gov/OccGuides/detail.aspx?Soccode=518031&Geography=0601000000

```

### PUMA-MSA crosswalk for California

This section:

-   Gets a [crosswalk](https://usa.ipums.org/usa/resources/volii/MSA2013_PUMA2010_crosswalk.xls) from [IPUMS USA](https://usa.ipums.org/) between:
-   Public Use Microdata Areas (PUMAs), relatively small geographic areas defined for and used in the Census Bureau's American Community Survey (ACS) that is rarely used outside of the ACS; (there are 265 PUMAs in California)l and
-   Metropolitan Statistical Areas, larger and more-widely known geographic areas; (there are 26 MSAs in California);
-   Parses the data
-   Creates a California subset, and
-   Saves for later use

We need such a crosswalk for two reasons:

-   We only have BEA regional price indexes for MSAs, not for PUMAs. ACS microdata identifies the PUMA for each person in the file, but not their MSA. Thus, we need a way to map the 265 California PUMAs in the ACS to the 26 California MSAs, so that we can get the MSA regional price index for each person in the data.
-   There are relatively few observations in some PUMAs for some occupational categories. Thus, the geographically larger MSAs can be more useful for substate regional analyses in California than the PUMAs. Plus, MSAs are more familiar to most people than are PUMAs.

```{r acs_pumas_notes}
# https://www.census.gov/programs-surveys/geography/guidance/geo-areas/pumas.html
# Public Use Microdata Areas (PUMAs) are non-overlapping, statistical geographic
# areas that partition each state or equivalent entity into geographic areas
# containing no fewer than 100,000 people each. They cover the entirety of the
# United States, Puerto Rico, Guam, and the U.S. Virgin Islands. The Census
# Bureau defines PUMAs for the tabulation and dissemination of decennial census
# and American Community Survey (ACS) Public Use Microdata Sample (PUMS) data.
# Additionally, the ACS and Puerto Rico Community Survey use them to disseminate
# their respective period estimates.

# The delineation of new PUMAs occurs after the completion of the decennial
# census as part of a program involving the State Data Centers (SDCs). Decennial
# census population counts and updated census tracts are critical inputs into
# the delineation process.

# PUMA Character 5 Public use microdata area code (PUMA) based on 2010 Census
# definition (areas with population of 100,000 or more, use with ST for unique
# code) 00100..70301 .Public use microdata area codes

# https://www2.census.gov/geo/docs/reference/puma/
# https://www2.census.gov/geo/docs/reference/puma/2010_PUMA_Names.txt

# https://www.brookings.edu/wp-content/uploads/2018/07/ES_THP_071018_where_work_pays_tech_appendix.pdf
# IPUMS has created a crosswalk between PUMAs and metropolitan statistical areas
# (MSAs) that denotes what percent of a given PUMA is in a given MSA. We use
# this crosswalk to group PUMAs into metropolitan areas and state
# non-metropolitan areas. An individual is characterized as living in a MSA if
# they live in a PUMA that is more than 50% in that MSA. They are classified as
# living in a state nonmetropolitan area if they live in a PUMA that is less
# than 50% in any metropolitan area. All states except for Delaware, New Jersey,
# and Rhode Island (and the District of Columbia) have non-metropolitan areas.

# PUMAs to MSAs -- looks like 24-26 MSAs
# https://usa.ipums.org/usa-action/variables/met2013#description_section
# https://usa.ipums.org/usa/resources/volii/MSA2013_PUMA2010_crosswalk.xls
# https://rdrr.io/github/greaterlouisvilleproject/glptools/man/MSA_PUMA.html


# PUMAs to counties -- 58 counties
# https://www.psc.isr.umich.edu/dis/data/resource/detail/1527.html
# https://www.psc.isr.umich.edu/dis/workshop/utilities/p2c.html
# https://www.psc.isr.umich.edu/dis/data/resource/detail/1528.html
# https://www.psc.isr.umich.edu/dis/workshop/utilities/p2c.html
# Three additional fields are output:  the five‐digit FIPS county code, county name, and total county population based on the PUMA populations given in the p2c.equ cross‐walk file.

```

```{r acs_pumas_caxwalk, eval=FALSE}
# https://usa.ipums.org/usa/resources/volii/MSA2013_PUMA2010_crosswalk.xls
pumasdir <- r"(E:\data\acs\pums\pumas\)"
pfn <- "MSA2013_PUMA2010_crosswalk.xls"

# MSA Code	MSA Title	State FIPS Code	State Name	PUMA Code	PUMA Name	MSA 2010 Population	PUMA 2010 Population	Intersection 2010 Population	Percent MSA Population	Percent PUMA Population

pumamsa1 <- read_excel(paste0(pumasdir, pfn)) 
names(pumamsa1)
pumamsa2 <- pumamsa1 %>%
  setNames(c("msacode", "msaname", "stfips", "stname", "puma", "pumaname",
             "msapop", "pumapop", "interpop",
             "pctmsa", "pctpuma")) 
# do we assign any puma to more than one msa??
dups <- pumamsa2 %>%
  group_by(puma, pumaname) %>%
  mutate(n=n()) %>%
  ungroup %>%
  filter(n > 1) %>%
  arrange(puma, pumaname, desc(interpop)) 

pumamsa3 <- pumamsa2 %>%
  # for each puma, keep only the msa to which it has the most assigned pop (interpop)
  # so that we assign 1 and only 1 msa for each puma %>%
  arrange(stfips, puma, pumaname, desc(interpop)) %>%
  group_by(puma, pumaname) %>%
  filter(row_number()==1) %>%
  ungroup %>%
  mutate(across(c(stfips, puma, msacode), as.integer))

pumas_caxwalk <- pumamsa3 %>%
  filter(stfips==6)

# how far off are we?
pumas_caxwalk %>%
  group_by(msacode, msaname) %>%
  summarise(msapop=first(msapop),
            pumasum=sum(interpop),
            .groups = "drop") %>%
  mutate(pdiff=pumasum / msapop -1) %>%
  arrange(-abs(pdiff)) # almost perfect

saveRDS(pumas_caxwalk, here::here("data", "pumas_caxwalk.rds"))

```


#### Define other ACS codes

This section has functions that develop variables that will serve as controls in regression equations, generally by collapsing detailed ACS variables into more-aggregated categories. For example, it:

-   Race and ethnicity variables are collapsed from 9 race categories by multiple ethnic categories into a single variable with 5 categories
-   Years of schooling is calculated
-   Educational attainment is collapsed into
-   Work experience is calculated as age minus years of schooling minus 6

### Create ACS data subsets to be used in the analysis

```{r connect_acsdb}
# make sure to have sourced the functions files first
# and defined constants

# dbDisconnect(db) # in case it is connected - will throw an error if not, but that's ok
db <- dbConnect(SQLite(), dbname=acsdb)

```

#### Create subset representing all state correctional workers in the U.S.

This subset has approximately 9,800 observations.

We construct real wages for each worker by using the BEA state-level regional price parity index for the state for the relevant year of the person sampled (one of 2015-2019).

```{r acs_corrections_US, eval=FALSE}
# get all state government corrections officers in the US
corr_sqlcmd <- paste0("SELECT ", acsvars_string, " FROM pus WHERE occp=3802") # 10 secs
system.time(corr_base <- collect(tbl(db, sql(corr_sqlcmd))))  # 3 secs
glimpse(corr_base) # 21,989 obs
summary(corr_base)
count(corr_base, st)
count(corr_base, puma, st)
count(corr_base %>% filter(st==06), puma) %>% arrange(-n)
max(corr_base$puma) # 70301

corr_workers <- corr_base %>%
  filter(eval(parse(text=sworker))) %>%
  filter(cow == 4) %>%  # state government
  mutate(f_create_vars(.)) %>% # returns the data frame with additional variables, including rwagp
  # adjust rwagp again, using the gdp price index, to bring it from 2019 to 2020
  # igddppi is the multiplier that converts a year to 2020
  mutate(rwagp=rwagp * gdppi$igdppi[gdppi$year==2019]) %>%
  left_join(stcodes %>% 
              select(st=stfips, stabbr) %>% 
              mutate(st=as.integer(st)),
            by="st") %>%
  left_join(sarpp %>%
              select(stabbr, year, rpp),  # merge on the prior year
            by=c("stabbr", "year")) %>%
  mutate(rppwagp=rwagp / rpp,  # rwagp is real wage (adjusted for year), rppwagp is region adjusted
         lrppwagp=log(rppwagp),
         level="state",
         soc="33-3012",
         casco=eval(!!casco)) %>%  
  group_by(stabbr) %>%
  mutate(n=n()) %>%
  ungroup

summary(corr_workers)
count(corr_workers, stabbr)
corr_workers %>%
  group_by(stabbr) %>%
  summarise(n=n(), wtdn=sum(pwgtp), rwagp=wtd.mean(rwagp, pwgtp))

saveRDS(corr_workers, here::here("data", "corr_workers.rds"))

```

#### Create subset representing all sampled workers in California

This subset has approximately 640,000 observations.

We construct real wages for each California worker by using the BEA MSA-level regional price parity index for the worker's California MSA, or for non-metro areas as a whole if the worker is not in an MSA, for the relevant year of the person sampled (one of 2015-2019).

```{r acs_caworkers, eval=FALSE}
sqlcmd <- paste0("SELECT ", acsvars_string, " FROM pus WHERE st=06")

system.time(cadf <- collect(tbl(db, sql(sqlcmd))))  # 4 secs
glimpse(cadf)
summary(cadf)
count(cadf, st) # 1.9m
count(cadf, puma) %>% arrange(-n)

# cadf %>% 
#   mutate(year=str_sub(serialno, 1, 4)) %>% 
#   group_by(year) %>%
#   summarise(minadjinc=min(adjinc), maxadjinc=max(adjinc))
#   year  minadjinc maxadjinc
#   <chr>     <int>     <int>
# 1 2015    1080470   1080470
# 2 2016    1073449   1073449
# 3 2017    1054606   1054606
# 4 2018    1031452   1031452
# 5 2019    1010145   1010145

caworkers <- cadf %>%
  filter(eval(parse(text=sworker))) %>%
  filter(cow %in% 1:5) %>%
  mutate(f_create_vars(.),
         cowf=f_cow(cow),
         level=case_when(str_detect(cowf, "Private") ~ "private",
                         str_detect(cowf, "Local") ~ "local",
                         str_detect(cowf, "State") ~ "state",
                         str_detect(cowf, "Federal") ~ "federal",
                         TRUE ~ "ERROR")) %>%
  # adjust rwagp again, using the gdp price index, to bring it from 2019 to 2020
  # igddppi is the multiplier that converts a year to 2020
  mutate(rwagp=rwagp * gdppi$igdppi[gdppi$year==2019]) %>% 
  # get state abbreviation
  left_join(stcodes %>% 
              select(st=stfips, stabbr) %>% 
              mutate(st=as.integer(st)),
            by="st") %>%
  left_join(acsocodes, by="occp") %>%
  # get msa (fips) code and msaname that the puma is (mostly) within
  left_join(pumas_caxwalk %>% 
              select(puma, pumaname, msacode, msaname),
            by = "puma") %>%
  # get regional price parity index
  left_join(carpp %>% 
              filter(type=="metro") %>%
              select(msacode=fips, year, rpp),
            by=c("msacode", "year")) %>%
  mutate(msacode=ifelse(is.na(msacode), -9999, msacode),
         msaname=ifelse(is.na(msaname), "nonmetro", msaname),
         type=ifelse(msacode==-9999, "nonmetro", "metro")) %>%
  # merge again to get regional price parity for the nonmetro areas
  left_join(carpp %>% 
              filter(type=="nonmetro") %>%
              select(type, year, rpp_nonmetro=rpp),
            by=c("type", "year")) %>%
  mutate(rpp=ifelse(type=="nonmetro", rpp_nonmetro, rpp),
         rppwagp=rwagp / rpp,  # rwagp is real wage (adjusted for year), rppwagp is region adjusted
         lrppwagp=log(rppwagp),
         casco=eval(!!casco)) %>%
  group_by(soc, level) %>%
  mutate(yoschool_wmean=wtd.mean(yoschool, pwgtp)) %>%
  ungroup %>%
  select(-rpp_nonmetro)
summary(caworkers)

count(caworkers, occp, occname) %>% arrange(-n)
count(caworkers, occp, soc, occname) %>% filter(str_sub(soc, 1, 3)=="33-")
count(caworkers, cow, cowf, level)

saveRDS(caworkers, here::here("data", "caworkers.rds"))

```


#### Create ACS summary of educational attainment of california workers by occupation and sector

```{r job_educ, eval=FALSE}
cajobeduc <- caworkers %>%
  group_by(soc, occp, occname, level, cow, cowf, edattain) %>%
  summarise(n=n(),
            wtdn=sum(pwgtp),
            yoschool=median(yoschool, na.rm=TRUE),
            ltassoc=sum(ltassoc * pwgtp),
            rwagp=sum(rwagp * pwgtp),
            rppwagp=sum(rppwagp * pwgtp),
            .groups="drop") %>%
  group_by(soc, occp, occname, level, cow, cowf) %>%
  summarise(n=sum(n),
            ltassoc=sum(ltassoc),
            assoc=sum(wtdn[edattain %in% c("associate")]),
            ba=sum(wtdn[edattain %in% c("BA")]),
            maplus=sum(wtdn[edattain %in% c("MA+")]),
            rwagp=sum(rwagp),
            rppwagp=sum(rppwagp),
            # MUST put wtdn last so it is not revised before being used
            wtdn=sum(wtdn),
            .groups="drop") %>%
  mutate(across(c(ltassoc, assoc, ba, maplus, rwagp, rppwagp), ~ .x / wtdn)) %>%
  select(soc, occname, occp, cow, cowf, level, n, wtdn, everything())
summary(cajobeduc)

saveRDS(cajobeduc, here::here("data", "cajobeduc.rds"))

```

## Goverment Compensation in California, State Controller's Office
```{r ONETIME_gcc}
# https://publicpay.ca.gov/Reports/RawExport.aspx
# https://publicpay.ca.gov/Reports/DataDictionary.aspx
# https://publicpay.ca.gov/RawExport/2020_StateDepartment.zip

# Regular Pay
# The dollar amount paid to an employee for their normal hours worked, including any leave time used and/or paid holidays.

# Overtime Pay
# The dollar amount paid to the employee for hours worked in addition to normal hours.

# Lump-Sum Pay
# The dollar amount paid to the employee for one-time cash-outs (including, but not limited to, paid excess vacation and sick leave, and legal settlements).

# Other Pay
# The dollar amount paid to the employee for any other pay not reported as regular pay, overtime pay, or lump-sum pay (such as car allowances, meeting stipends, incentive pay, bonus pay, etc.). Elected Officials' pay reported on IRS Form 1099 also is included as Other Pay. For the University of California, the largest categories of Other Pay are health sciences faculty non-base compensation derived from clinical revenue and contracts and grants, as well as additional compensation to faculty for summer session teaching and externally-funded research conducted during the summer.

# Health/Dental/Vision Contribution
# The dollar amount paid by the employer toward the employee's health, dental, and/or vision care plans.

urlbase <- "https://publicpay.ca.gov/RawExport/"
fnz <- "2020_StateDepartment.zip"
fnc <- "2020_StateDepartment.csv"
download.file(url=paste0(urlbase, fnz), here::here("data_raw", fnz), mode="wb")

gcc1 <- read_csv(unz(here::here("data_raw", fnz), fnc))
glimpse(gcc1)

# https://publicpay.ca.gov/Reports/State/StateEntity.aspx?entityid=3761&year=2020
# employees: 66,623
# Total Wages $5,887,870,119
# Total Retirement & Health Contribution $2,705,069,656

gcc1 %>%
  filter(EmployerName=="Corrections & Rehabilitation, Department of") %>%
  summarise(n=n(), across(c(TotalWages, TotalRetirementAndHealthContribution), sum))
# good, matches what they show on their website

count(gcc1 %>% filter(str_detect(Position, "Correctional Officer")), Position)
#   Position                                n
#   <chr>                               <int>
# 1 Correctional Officer, Range 1         256
# 2 Correctional Officer, Range A           8
# 3 Correctional Officer, Range B          16
# 4 Correctional Officer, Range C           9
# 5 Correctional Officer, Range J        2916
# 6 Correctional Officer, Range K       21154
# 7 Youth Correctional Officer, Range A     3
# 8 Youth Correctional Officer, Range J    68
# 9 Youth Correctional Officer, Range K   174

# get casco
casco_gcc1 <- gcc1 %>%
  filter(str_detect(Position, "Correctional Officer"),
         !str_detect(Position, "Youth")) %>%
  select(Year, emptype=EmployerType, empname=EmployerName, dept=DepartmentOrSubdivision,
         minsalary=MinPositionSalary, maxsalary=MaxPositionSalary,
         regpay=RegularPay, otpay=OvertimePay, lumppay=LumpSumPay, OtherPay, totwage=TotalWages,
         dberc=DefinedBenefitPlanContribution, dbercbehalf=EmployeesRetirementCostCovered,
         dcerc=DeferredCompensationPlan, health=HealthDentalVision,
         totrethealth=TotalRetirementAndHealthContribution) %>%
  setNames(str_to_lower(names(.)))
glimpse(casco_gcc1)
count(casco_gcc1, empname)
casco_gcc <- casco_gcc1 %>%
  select(-emptype)
summary(casco_gcc) # why is dcerc $0?? I thought there is 2% contribution???

saveRDS(casco_gcc, here::here("data", "casco_gcc.rds"))

casco_gcc <- readRDS(here::here("data", "casco_gcc.rds"))  # check

```



## Workplace injury rates

```{r eval=FALSE}
# url_base <- "https://download.bls.gov/pub/time.series/hc/"
# files <- c("hc.age", "hc.case", "hc.category", "hc.category2", "hc.contacts", "hc.data.0.Current", "hc.data.1.AllData", "hc.datatype", "hc.event", "hc.footnote", "hc.gender", "hc.industry", "hc.los", "hc.nature", "hc.occupation", "hc.pob", "hc.race", "hc.series", "hc.source", "hc.txt")
# keep <- setdiff(files, "hc.data.0.Current")

url_base <- "https://download.bls.gov/pub/time.series/cs/"
files <- c("cs.age", "cs.case", "cs.category", "cs.contacts", "cs.data.0.Current", "cs.data.1.AllData", "cs.datatype", "cs.event", "cs.footnote", "cs.gender", "cs.hour", "cs.industry", "cs.los", "cs.nature", "cs.occupation", "cs.ownership", "cs.pob", "cs.race", "cs.series", "cs.source", "cs.special", "cs.state", "cs.time", "cs.txt", "cs.weekday")
keep <- setdiff(files, c("cs.data.0.Current", "cs.series"))

for(file in keep){
  url <- paste0(url_base, file)
  path <- paste0(wpid, "cs/",  file)
  download.file(url, path, mode="wb")
}

# Example: CSU00X3300003O100
# CSU00X 330000 3 O 1 00
#        330000 Occupation = Protective Service Occupations
#        3 Data Type = Injury and illness rate per 10,000 full-time workers
#        1 Ownership = Private Industry (skip the O -- oh, not zero)
#        00 Area = All US

# get and save the workplace injuries data
# Field #/Data Element		Length		Value(Example)
# 1.  series_id			  17		HCUSH332233
# 2.  year			   4		1998
# 3.  period			   3		M01
# 4.  value			  12		2360
# 5.  footnote_codes		  10		It varies
# 
# The series_id (HCUSH332233) can be broken out into:
# Code				=			Value
# survey abbreviation		=			HC
# seasonal adjustment code	=			U
# case category			=			SH
# detail code			=			3322
# datatype code			=			3
# case type code			=			3


# datatype_code	datatype_text
# 3	Injury and illness rate per 10,000 full-time workers
# 6	Injury and illness Cases
# 7	Median days lost


# case_code	case_text
# 3	Selected characteristic by detailed industry
# A	Industry division or selected characteristic by age
# E	Industry division or selected characteristic by detailed event or exposure
# G	Industry division or selected characteristic by gender
# H	Industry division or selected characteristic by hours at work
# L	Industry division or selected characteristic by length of service
# M	Industry division or selected characteristic by special combinations
# N	Industry division or selected characteristic by detailed nature of condition
# O	Industry division or selected characteristic by detailed occupation
# P	Industry division or selected characteristic by detailed part of body affected
# R	Industry division or selected characteristic by race or ethnicity
# S	Industry division or selected characteristic by detailed source of injury/illness
# T	Industry division or selected characteristic by time of day
# W	Industry division or selected characteristic by day of week

# ownership_code	ownership_name
# 0	All ownerships
# 1	Private industry
# 7	State government
# 8	Local government
# 9	State and local government combined

wpiown <- read_tsv(paste0(wpid, "cs/", "cs.ownership"))

wpioccs1 <- read_tsv(paste0(wpid, "cs/", "cs.occupation"), col_types = "ccccc")
wpioccs <- wpioccs1 %>%
  # clean up occupation_text -- delete non-alphanumeric and selected punctuation
  mutate(oname=str_replace_all(occupation_text, "[^[:alnum:] (),-]", ""),
         oname=str_replace(oname, "sheriffs", "sheriff's"))

wpistates <- read_tsv(paste0(wpid, "cs/", "cs.state"), col_types = "ccccc")

length(unique(wpioccs$occupation_code))==nrow(wpioccs)
# df <- read_table(paste0(wpid, "cs/", "cs.data.1.AllData"), col_types = "cicnc")  # TOO SLOW!

a <- proc.time()
wpi_all <- vroom(paste0(wpid, "cs/", "cs.data.1.AllData"), col_types = "cicnc")
b <- proc.time()
b - a # 31 secs
saveRDS(wpi_all, paste0(wpid, "wpi_all.rds"))

wpi_all <- readRDS(paste0(wpid, "wpi_all.rds"))
glimpse(wpi_all)
count(wpi_all, year)

# https://www.bls.gov/help/hlpforma.htm#CS
# Example: CSU00X3300003O100, from Colin Emberland, BLS
# CSU00X 330000 3 O 1 00
#        330000 Occupation = Protective Service Occupations
#        3 Data Type = Injury and illness rate per 10,000 full-time workers
#        1 Ownership = Private Industry (skip the O -- oh, not zero)
#        00 Area = All US
# CSU00X3330123O100	227.8	345.1	285.3	190.8	345.4	252.4	157.9	145.0	174.8

tmp <- wpi_all %>% filter(series_id=="CSU00X3330123O700")  # state correctional officers rates
# good, matches data from Colin Emberland, BLS
# CSU00X3330123O700	675.6	480.0	446.6	491.2	457.5	450.8	445.9	483.5	495.5

# get rates and cases by occupation
df2 <- wpi_all %>%
  filter(str_sub(series_id, 1, 6)=="CSU00X",  # occupational detail
         str_sub(series_id, 13, 13) %in% c("3", "6"), # datatype 3 rate, 6 is cases
         str_sub(series_id, 14, 14) == "O") # case type -- Oh means by occupation
         )  
rm(df1)
gc(verbose=TRUE)

# simplify
df3 <- df2 %>%
  mutate(ocode=str_sub(series_id, 7, 12),  # detail is the occ code in the CS occupational detail file
         datatype=str_sub(series_id, 13, 13) %>% as.integer,
         own=str_sub(series_id, 15, 15) %>% as.integer,
         stfips=str_sub(series_id, 16, 17)) %>%
  select(series_id, ocode, datatype, own, stfips, year, value, footnote_codes)
count(df3, footnote_codes) # good, all are NA
count(df3, datatype)
count(df3, own)

# factors and joins
df4 <- df3 %>%
  mutate(datatype=factor(datatype, levels=c(3, 6), labels=c("rate", "cases")),
         ownf=factor(own, 
                      levels=c(0, 1, 7, 8, 9),
                      labels=c("allown", "private", "state", "local", "slg")),
         ownf2=factor(own, levels=wpiown$ownership_code, labels=wpiown$ownership_name)) %>%
  left_join(wpioccs %>% 
              select(ocode=occupation_code, oname=occupation_text, displevel=display_level),
            by="ocode") %>%
  left_join(wpistates %>%
              select(stfips=state_code, stname=state_name),
            by="stfips") %>%
  select(datatype, ocode, oname, displevel, own, ownf, ownf2, stfips, stname, year, value)
count(df4, stfips, stname)
count(df4, displevel)
count(df4, datatype)  # why so many cases records compared to rates records??
count(df4, year)
count(df4, own, ownf, ownf2)
  
# pivot, and calculate implied ftes 
df5 <- df4 %>%
  pivot_wider(names_from = datatype) %>%
  filter(!is.na(rate)) %>%
  left_join(stcodes %>% select(stfips, stabbr), by="stfips") %>%
  mutate(stname=ifelse(stfips=="00", "United States", stname),
         ftes=cases / rate * 10e3)
 
count(df5, stfips, stabbr, stname) # BLS has different stfips for Guam, Puerto Rico, Virgin Islands

tmp <- df5 %>%
  filter(displevel==4, stabbr=="US", year==2019, own %in% c(1, 7, 8))
tmp <- df5 %>% filter(ocode=="292051", ownf=="private")
t2 <- count(df5, ocode, oname)

df5 %>%
  filter(ocode=="333012", own %in% c(1, 7, 8)) %>%
  ggplot(aes(year, rate, colour=ownf)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks=2000:2020)

wpius <- df5 %>%
  filter(displevel==4, stabbr=="US", own %in% c(1, 7, 8))
saveRDS(wpius, here::here("data", "wpius.rds"))

# https://data.bls.gov/cgi-bin/dsrv
# Nonfatal cases involving days away from work: selected characteristics (2011 forward)
# Series Id:	CSUE113300003O000  CSU E11 330000 3 O 0 00
# Area:	All U.S.
# Ownership:	All ownerships
# Data Type:	Injury and illness rate per 10,000 full-time workers
# Case Type:	Industry division or selected characteristic by detailed occupation
# Category:	Event - Intentional injury by other person
# Occupation:	Protective service occupations
# Year	Annual
# 2011	35.7
# 2012	31.9
# 2013	26.9
# 2014	22.9
# 2015	30.9
# 2016	33.3
# 2017	26.8
# 2018	25.9
# 2019	24.4
# 2020	22.6

# Series Id:	CSUE113330123O100
# Area:	All U.S.
# Ownership:	Private industry; CSUE113330123O700 is state govt
# Data Type:	Injury and illness rate per 10,000 full-time workers
# Case Type:	Industry division or selected characteristic by detailed occupation
# Category:	Event - Intentional injury by other person
# Occupation:	Correctional officers and jailers
# 
# Download: Download as an Excel File
# Year	Annual
# 2011	35.5
# 2012	46.5
# 2013	44.8
# 2014	28.4
# 2015	44.0
# 2016	56.1
# 2018	10.9
# 2019	24.0
# 2020	84.8


# Series Id:	CSUE113330123O700
# Area:	All U.S.
# Ownership:	State government
# Data Type:	Injury and illness rate per 10,000 full-time workers
# Case Type:	Industry division or selected characteristic by detailed occupation
# Category:	Event - Intentional injury by other person
# Occupation:	Correctional officers and jailers
# 
# Download: Download as an Excel File
# Year	Annual
# 2011	123.2
# 2012	63.7
# 2013	49.2
# 2014	53.6
# 2015	71.4
# 2016	81.6
# 2017	75.3
# 2018	72.0
# 2019	71.7
# 2020	82.8

#.. wpius_5_year averages ----
wpius_5year <- wpius %>%
  filter(year %in% 2015:2019) %>%
  group_by(ocode, oname, ownf) %>%
  summarise(n=n(), 
            nge5k=sum(ftes >= 5000),
            cases_sum=sum(cases),
            ftes_mean=mean(ftes),
            ftes_sum=sum(ftes),
            rate_mean=mean(rate),
            .groups="drop") %>%
  mutate(rate_calc=cases_sum / ftes_sum * 10e3)
saveRDS(wpius_5year, here::here("data", "wpius_5year.rds"))

wpius_5year %>%
  filter(nge5k==5) %>%
  arrange(desc(rate_calc)) %>% 
  gt()

wpius_5year %>%
  filter(ocode=="333012") %>%
  arrange(desc(rate_calc)) %>% 
  gt()

#.. ihus_5year intentional harm ----
# CSUE113330123O700  17 characters
tmp <- wpi_all %>% filter(series_id=="CSUE113330123O700")

# this first step takes a bit; but the resulting df is small enough to work with quickly
ih1 <- wpi_all %>%
  filter(str_sub(series_id, 1, 6)=="CSUE11",  # event E11
         str_sub(series_id, 13, 13) %in% c("3", "6"), # datatype 3 rate, 6 is cases
         str_sub(series_id, 14, 14) == "O") # case type -- Oh means by occupation
rm(ih1)
gc(verbose=TRUE)

# simplify
ih2 <- ih1 %>%
  mutate(ocode=str_sub(series_id, 7, 12),  # detail is the occ code in the CS occupational detail file
         datatype=str_sub(series_id, 13, 13) %>% as.integer,
         own=str_sub(series_id, 15, 15) %>% as.integer,
         stfips=str_sub(series_id, 16, 17)) %>%
  select(series_id, ocode, datatype, own, stfips, year, value, footnote_codes)
count(ih2, footnote_codes) # 3 footnote Z, Rounded to zero
count(ih2, datatype)
count(ih2, own)

# factors and joins
ih3 <- ih2 %>%
  mutate(datatype=factor(datatype, levels=c(3, 6), labels=c("rate", "cases")),
         ownf=factor(own,
                     levels=c(0, 1, 7, 8, 9),
                     labels=c("allown", "private", "state", "local", "slg"))) %>%
  left_join(wpioccs %>% 
              select(ocode=occupation_code, oname, displevel=display_level),
            by="ocode") %>%
  left_join(wpistates %>%
              select(stfips=state_code, stname=state_name),
            by="stfips") %>%
  select(datatype, ocode, oname, displevel, own, ownf, stfips, stname, year, value)
count(ih3, stfips, stname)
count(ih3, displevel)
count(ih3, datatype)  # why so many cases records compared to rates records??
count(ih3, year)
count(ih3, own, ownf)
  
# pivot, and calculate implied ftes 
ih4 <- ih3 %>%
  pivot_wider(names_from = datatype) %>%
  filter(!is.na(rate)) %>%
  left_join(stcodes %>% select(stfips, stabbr), by="stfips") %>%
  mutate(stname=ifelse(stfips=="00", "United States", stname),
         ftes=cases / rate * 10e3)

ih4 %>%
  filter(ocode=="333012", own %in% c(1, 7, 8)) %>%
  ggplot(aes(year, rate, colour=ownf)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks=2000:2020)

# a few codes changed between 2018 and 2019 under an SOC revision -- remap the old codes to new
remap <- ih4 %>%
  filter(year %in% 2018:2019, displevel==4) %>% # my period of interest
  group_by(oname) %>%
  summarise(n=n(), 
            code2018=first(ocode[year==2018]),
            code2019=first(ocode[year==2019]),
            nocode=length(unique(ocode)), .groups="drop") %>%
  filter(nocode > 1)
remap 

# remap codes and then get 5-year averages
ihus_5year <- ih4 %>%
  filter(year %in% 2015:2019, stabbr=="US", displevel==4, ownf %in% c("private", "state", "local")) %>%
  # remap codes
  left_join(remap %>% select(ocode=code2018, code2019), by = "ocode") %>%
  mutate(ocode2019=ifelse(is.na(code2019),
                          ocode, 
                          code2019)) %>%
  group_by(ocode2019, oname, ownf) %>%
  summarise(n=n(), 
            nge5k=sum(ftes >= 5000),
            cases_sum=sum(cases),
            ftes_mean=mean(ftes),
            ftes_sum=sum(ftes),
            rate_mean=mean(rate),
            rate_2019=rate[year==2019],
            .groups="drop") %>%
  # calc average and put cow and soc on the file
  mutate(rate_calc=cases_sum / ftes_sum * 10e3,
         soc=paste0(str_sub(ocode2019, 1, 2), "-", substr(ocode2019, 3, length(ocode2019))),
         cow=case_when(ownf=="private" ~ 1,
                       ownf=="local" ~ 3, # local govt
                       ownf=="state" ~ 4, # state govt
                       TRUE ~ -99))
count(ihus_5year, cow, ownf)
saveRDS(ihus_5year, here::here("data", "ihus_5year.rds"))

ihus_5year %>%
  filter(ocode2019=="333012")

ihus_5year %>%
  filter(ownf %in% c("private", "state", "local")) %>%
  arrange(desc(rate_calc)) %>%
  filter(n >= 3)


ihus_5year %>%
  filter(ocode=="333012") %>%
  arrange(desc(rate_calc))

ih4 %>%
  filter(ocode=="333012", year >= 2019) %>%
  arrange(desc(rate))

# online query
# Year	Annual
# 2011	123.2
# 2012	63.7
# 2013	49.2
# 2014	53.6
# 2015	71.4
# 2016	81.6
# 2017	75.3
# 2018	72.0
# 2019	71.7 good -- matches
# 2020	82.8

ih4 %>%
  filter(stabbr=="US", displevel=="4", year == 2019, ownf %in% c("private", "state", "local")) %>%
  arrange(desc(rate))

tmp <- ih4 %>%
  filter(stabbr=="US", year == 2019, ownf %in% c("private", "state", "local")) %>%
  arrange(desc(rate))
count(tmp, displevel)

# forget state-specific data
tmp <- ih4 %>%
  filter(stabbr=="CA", displevel=="2", year == 2019) %>%
  arrange(desc(rate))


# CSU00X3330126O700	...	10940 (2019 value)

# https://github.com/tidyverse/readr/issues/1145
#..you can install the development versions of cpp11 and then re-install readr.
# devtools::install_github("r-lib/cpp11")
# I have NOT installed dev versions of vroom and reader but here is code to do so
# devtools::install_dev("vroom")
#  or devtools::install_github("r-lib/vroom/vroom")
# devtools::install_github("tidyverse/readr")

```




## Job clusters

For comparisons to the private sector, one approach is to compare against workers in jobs in a similar cluster. See <https://www.onetonline.org/find/career?c=12> <https://careertech.org/career-clusters>

Here we create a list of occupations that are in the "Law, Public Safety, Corrections & Security" job cluster.

```{r ONETIME_job_clusters}
# https://www.onetonline.org/find/career?c=12
# https://www.onetonline.org/find/career/Law_Public_Safety_Corrections_Security.xls?fmt=xls&c=12
# url <- "https://www.onetonline.org/find/career/Law_Public_Safety_Corrections_Security.xls?fmt=xls&c=12"
# url_base <- "https://www.onetonline.org/find/career/"
# fn <- "Law_Public_Safety_Corrections_Security.xls"
# download.file(url, here::here("data_raw", fn), mode="wb")

urlcsv <- "https://www.onetonline.org/find/career/Law_Public_Safety_Corrections_Security.csv?fmt=csv&c=12"
fncsv <- "Law_Public_Safety_Corrections_Security.csv"
download.file(urlcsv, here::here("data_raw", fncsv), mode="wb")

job_cluster1 <- read_csv(here::here("data_raw", fncsv))
job_cluster <- job_cluster1 %>%
  setNames(c("pathway", "occd2", "occname")) %>%
  mutate(occ=str_sub(occd2, 1, -4),
         cluster="Law, Public Safety, Corrections & Security") %>%
  select(occd2, occ, occname, pathway, cluster)

saveRDS(job_cluster, here::here("data", "job_cluster.rds"))

```


# GET DATA AND BEGIN
```{r load_data}
# load previously prepared data
gdppi <- readRDS(here::here("data", "gdppi.rds"))
cpi <- readRDS(here::here("data", "cpi.rds"))

load(file=here::here("data", "rpp.rdata"), verbose=TRUE) # max year is 2019 for all
# sarpp, marpp, and carpp with state, metro/nonmetro, and CA metro, nonmetro regional price parities

acsocodes <- readRDS(here::here("data", "acsocodes.rds")) # occp and soc occupation codes and names
pumas_caxwalk <- readRDS(here::here("data", "pumas_caxwalk.rds")) # puma to msa xwalk

#.. the main data files ----
# job categories
job_cluster <- readRDS(here::here("data", "job_cluster.rds")) # occupation pathways and job clusters
wpius_5year <- readRDS(here::here("data", "wpius_5year.rds"))
ihus_5year <- readRDS(here::here("data", "ihus_5year.rds"))

# OESW
# All states, govt
oesres_clean <- readRDS(paste0(resdir, "oesres_clean.rds"))
oesres_sec99 <- readRDS(paste0(resdir, "oesres_sec99.rds"))

# California files
caledd_oesw <- readRDS(here::here("data", "caledd_oesw.rds")) # CA econ dev oesw 2009-2021
load(file=here::here("data", "caloes.rdata"), verbose=TRUE) # cal_oes and _oescodes

# ACS-based files
corr_workers <- readRDS(here::here("data", "corr_workers.rds"))
caworkers <- readRDS(here::here("data", "caworkers.rds"))
cajobeduc <- readRDS(here::here("data", "cajobeduc.rds"))

# SCO GCC data
casco_gcc <- readRDS(here::here("data", "casco_gcc.rds")) 

```


# Wages of correctional officers

## Cross-state comparisons of correctional officers' wages

We'd expect wages to be higher when education or experience is greater. Looking at these two workforce characteristics in isolation can give us a sense of whether they will make a lot of difference when we run models that control for education and experience.

```{r states_dataprep}
# data prep
#.. OES states data prep ----
# OES -- construct a U.S. record
# corr wage, emp by state, 2012-2020
corr_oessts <- oesres_sec99 %>%
  filter(str_detect(naics_title, "State Government"), occ=="33-3012", stabbr %in% state.abb) %>%
  select(stabbr, year, occ, occname, wage=a_mean, emp=tot_emp) %>%
  mutate(caldum=stabbr=="CA")
# we have a few small-state NA values -- be careful of 2012 and 2017
# corr_oessts %>% filter(is.na(wage) | is.na(emp))
#   stabbr  year occ     occname                            wage   emp caldum
#   <chr>  <int> <chr>   <chr>                             <dbl> <dbl> <lgl> 
# 1 ID      2012 33-3012 Correctional Officers and Jailers 30720    NA FALSE 
# 2 ND      2012 33-3012 Correctional Officers and Jailers 35700    NA FALSE 
# 3 VT      2012 33-3012 Correctional Officers and Jailers 37140    NA FALSE 
# 4 RI      2017 33-3012 Correctional Officers and Jailers    NA  1080 FALSE 

corr_oesus50 <- corr_oessts %>%
  # drop any record with either wage or emp as NA
  filter(!is.na(emp), !is.na(wage)) %>%
  group_by(year, occ, occname) %>%
  summarise(stabbr="US",
            n=n(),
            caldum=FALSE,
            wage=wtd.mean(wage, weights = emp, na.rm=TRUE),
            emp=sum(emp, na.rm=TRUE), .groups = "drop")

corr_oes <- bind_rows(corr_oessts, corr_oesus50) %>%
  left_join(sarpp %>% select(stabbr, year=yearplus1, rpp),
            by=c("stabbr", "year")) %>%
  left_join(gdppi %>% select(year, igdppi), by="year") %>%
  mutate(rwage=wage * igdppi,
         rppwage = wage / rpp,
         stname=getstname(stabbr))
summary(corr_oes)
count(corr_oes, stabbr, stname)
# corr_oes %>% filter(is.na(rppwage))  # RI in 2017


#.. ACS states data preparation ----
# obs_cutoff number of observations needed in a state or other category
# glimpse(corr_workers)
corr_workers_cut <- corr_workers %>%
  mutate(stabbr2=ifelse(n >= obs_cutoff, stabbr, "other")) 
# glimpse(corr_workers_cut)
# count(corr_workers_cut, edattain)
# count(corr_workers_cut, stabbr2) # 39 states

# sanity check on the rpps -- they will vary within state, by year
corr_workers_cut %>%
  group_by(stabbr2) %>%
  summarise(n=n(),
            rppmin=min(rpp),
            rppmean=mean(rpp),
            rppmax=max(rpp))


corr_wages <- corr_workers_cut %>%
  group_by(stabbr2) %>%
  summarise(n=n(),
            wtdn=sum(pwgtp),
            rwagp=wtd.mean(rwagp, weights=pwgtp),
            rppwagp=wtd.mean(rppwagp, weights=pwgtp),
            exp=wtd.mean(exp, weights=pwgtp))

corr_ltassoc <- corr_workers_cut %>%
  group_by(stabbr2) %>%
  summarise(ltassoc=wtd.mean(ltassoc, weights = pwgtp), .groups="drop")

corr_ed <- corr_workers_cut %>%
  group_by(stabbr2, edattain) %>%
  summarise(wtdn=sum(pwgtp), .groups="drop") %>%
  group_by(stabbr2) %>%
  mutate(share=wtdn / sum(wtdn)) %>%
  select(stabbr2, edattain, share) %>%
  pivot_wider(names_from = edattain, values_from = share, values_fill = 0) %>%
  # mutate(ltassoc_check=notHSgrad + HSgrad + HSplus) %>%
  left_join(corr_ltassoc, by="stabbr2")

corr_sex <- corr_workers_cut %>%
  group_by(stabbr2, sex) %>%
  summarise(wtdn=sum(pwgtp), .groups="drop") %>%
  group_by(stabbr2) %>%
  mutate(share=wtdn / sum(wtdn)) %>%
  select(stabbr2, sex, share) %>%
  pivot_wider(names_from = sex, values_from = share, values_fill = 0)

corr_summary <- corr_wages %>%
  left_join(corr_ed, by="stabbr2") %>%
  left_join(corr_sex %>% select(stabbr2, male), by="stabbr2") %>%
  mutate(stname=get_stname(stabbr2),
         dumca=stabbr2=="CA") %>%
  select(stabbr2, stname, dumca, n, wtdn, exp, rwagp, rppwagp, male, ltassoc) %>%
  arrange(stname)

# keyfacts$corr_summary <- corr_summary

```

## Intro

Here we look at raw wages, without controlling for differences across workers such as educational attainment, as this is the starting point and is what other people will look at.

In addition, this is a sanity check on two different data sources:

-   Occupational Employment and Wage Statistics (OEWS or OES), research database: This is the gold standard for cross-state comparison in the number of workers or their average wages. But it is only one number per occupation per state per year (e.g., correctional officers in California in 2020 were paid \$88,710 on average). We don't have data for the individual workers used to derive state totals so we can't see how it varies within and across states with education, experience, etc. (Later, we will examine a version of the OES that has data for each MSA in California.) We look at this with, and without, adjusting for price differences across states.

-   American Community Survey (ACS): This is a public-use survey that has details on (anonymized) individuals - their age, educational attainment, gender, race, ethnicity, marital status, state of residence, and other information. The survey has 15 million observations nationally (including children and retired people), 840 of which are for correctional officers in California. The richness of this data allows us to control for differences in education, experience, and other characteristics (and later, it allows us to compare correctional officers to the private sector).

We don't expect summaries of the ACS to be as high-quality a measure of overall average wages as what we see in the OES, but we'd like the two data sources to tell the same basic story. The graphs below suggest that they do.

We show average wages at 2020 levels from these two sources in the two figures below.

## Wages based on the OES

### Nominal wages
```{r oes_nominal, include=TRUE, fig.width=10, fig.height=8}

pdata <- corr_oes %>%
  filter(year==2020, stabbr != "US") %>%
  arrange(desc(wage)) %>%
  mutate(stname=get_stname(stabbr),
         rank=row_number())

gtitle <- "State correctional officer wages in 2020"
gsubtitle <- NULL
capt1 <- paste0("Note: vertical line marks median (", 
                comma(median(pdata$wage), accuracy=1, prefix="$"),
                ")")
capt2 <- paste0("\nSource: ", source_oesres, ".")
capt <- paste0("\n", capt1, "\n", str_wrap(capt2, 150))

p <- pdata %>%
  ggplot(aes(y=reorder(stname, wage), x=wage)) +
  geom_point(aes(colour=caldum), size=0.75) +
  geom_col(aes(fill=caldum), size=1.5, width=0.1) +
  scale_colour_manual(values=c("blue", "red")) +
  scale_fill_manual(values=c("blue", "red")) +
  geom_text(aes(label=comma(x=wage, accuracy=1, prefix="$")),
            hjust=0, nudge_x=500, size=2.25,
            data=. %>% mutate(wage=ifelse(rank <= 5, wage, NA_real_))) + #,
            # data= . %>% mutate(wage=ifelse(wage >= 60e3, wage, NA_real_))) +
  theme_bw() +
  labs(x="Average annual wage", y=NULL,
       caption=capt) +
  ggtitle(label=gtitle, subtitle = gsubtitle) +
  theme(axis.text.y = element_text(hjust = 0)) +
  geom_vline(xintercept = median(pdata$wage), linetype="solid", colour="darkgrey", size=.5) +
  scale_x_continuous(breaks=seq(0, 100e3, 10e3), labels=label_comma(accuracy=1, prefix="$"), limits=c(0, 95e3)) +
  legend_none +
  caption_left
p

ggsave(here::here("results", "wages_oes.png"), plot=p, width=10, height=8, scale=1)
write_csv(pdata, here::here("results", "wages_oes_data.csv"))


  # geom_text(aes(x=xmoved, label=comma(x=wage, accuracy=1, prefix="$")),
  #           hjust=0, size=2.25,
  #           data=. %>% mutate(xmoved=ifelse(wage > median(pdata$wage), wage + 1000, wage - 5000))) +
  # geom_text(aes(label=comma(x=wage, accuracy=1, prefix="$")),
  #           position=position_nudge(x=ifelse(.data$wage > median(.data$wage), 1000, -1000)), 
  #           hjust=0, size=2.25) +

```

### Real wages over time
```{r wage_tab}
# https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html
# https://www.r-graph-gallery.com/ggplot2-color.html
storder <- c("CA", "US", "MA", "RI", "AZ", "NV", "OR") # use stabbr for convenience
tabdata <- corr_oes %>%
  filter(stabbr %in% storder, year %in% c(2012, 2016, 2020)) %>%
  mutate(stabbr=factor(stabbr, levels=storder)) %>%
  arrange(stabbr, year) %>%
  mutate(stname=factor(.$stname, levels=unique(.$stname))) %>%
  select(stabbr, stname, year, wage) %>%
  group_by(year) %>%
  mutate(pdiff=ifelse(stabbr != "CA", wage[stabbr=="CA"] / wage - 1, NA_real_)) %>%
  ungroup %>%
  pivot_wider(names_from = year, values_from = c(wage, pdiff))
  # %>% select(stabbr, stname, contains("2012"), contains("2016"), contains("2020"))
tabdata

tab <- bind_rows(tibble(stname="California and the U.S.:"), tabdata) %>%
  add_row(stname="Neighbors:", .after=5) %>%
  add_row(stname="States with next-highest wages in 2020:", .after=3) %>%
  gt() %>%
  cols_hide(stabbr) %>%
  tab_header(
    title = "State correctional officer wages, selected years"
      ) %>%
  cols_label(stname="",
             wage_2012="2012",
             wage_2016="2016",
             wage_2020="2020",
             pdiff_2012="2012",
             pdiff_2016="2016",
             pdiff_2020="2020") %>%
  cols_align(align="left", columns = stname) %>%
  tab_spanner(
    label = html("Average wage"),
    columns = contains("wage")
    ) %>%
  tab_spanner(
    label = "California wage % above other area",
    columns = contains("pdiff")
    )  %>%
  fmt_number(
    columns=c(contains("wage")),
    pattern = "${x}",
    decimals=0
  ) %>%
  fmt_percent(
    columns = contains("pdiff"),
    decimals = 1) %>%
  fmt_missing(columns=everything(), missing_text="") %>%
  fmt_missing(contains("pdiff"), rows=2) %>%
  tab_source_note(paste0("Sources: ", source_oesres, ".")) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = cells_body(
      rows = c(1, 4, 7)
    )
  ) %>%
  cols_width(
    stname ~ px(200),
    everything() ~ px(100)
    )

tab
gtsave(tab, filename="tab_wage_states.png", path=here::here("results"))

# library(viridis)
```


### Cost-of-living-adjusted wages

Now we look at the same data (OES), adjusted for price differences across states. Not surprisingly California wages are not as far above other states after adjusting for price differences, because California is expensive, but the differences are still large.


```{r oes_col, include=TRUE, fig.width=6, fig.height=8}
top10data <- corr_oes %>%
  filter(year==2020) %>%
  mutate(rpprank=ifelse(stabbr != "US",
                        rank(desc(rppwage)),
                        NA_real_),
         pdrppwage=rppwage[stabbr=="CA"] / rppwage - 1,
         pdrppwage=ifelse(stabbr=="CA", NA_real_, pdrppwage),  # for better display in table
         stname=ifelse(stabbr=="US", "United States average", stname)) %>%
  select(stabbr, stname,
         rppwage, rpprank, pdrppwage) %>%
  arrange(desc(rppwage)) %>%
  filter(rpprank <= 10 | stabbr=="US")

src_note <- paste0("Sources: ", source_oesres, ", and ", source_rpp, ".")

tab <- top10data %>%
  select(stname, rppwage, rpprank, pdrppwage) %>%
  gt() %>%
  tab_header(
    title = html("State correctional officer wages in 2020<br>adjusted for state cost of living differences"),
    subtitle= "Top 10 states by cost-of-living adjusted wage, plus U.S. average"
      ) %>%
  cols_label(stname="",
             rppwage="Adjusted wage",
             rpprank="Rank",
             pdrppwage=html("California<br>% above<br>other state")) %>%
  cols_align(align="left", columns = stname) %>%
  fmt_number(
    columns=c(rppwage),
    pattern = "${x}",
    decimals=0
  ) %>%
  fmt_number(
    columns=c(contains("Rank")),
    pattern = "{x}",
    decimals=0
  ) %>%
  fmt_percent(
    columns = contains("pd"),
    decimals = 1) %>%
  fmt_missing(columns=c(rpprank, pdrppwage)) %>%
  tab_source_note(src_note) %>%
  cols_width(
    stname ~ px(200),
    everything() ~ px(100)
    )

tab
gtsave(tab, filename="tab_rppwage_states.png", path=here::here("results"), expand = 10)

```


## Wages based on the ACS

The similarity between the ACS plot here and the OES plot above give us confidence when using the ACS to control for differences across individuals.

```{r include=TRUE, fig.width=6, fig.height=8}

gtitle <- "State correctional officer salaries"
gsubtitle <- "Based on a 5-year sample adjusted to 2020 income levels"

capt1 <- "Note: vertical line marks median"
capt2 <-paste0("\nSource: ", source_acs, ".")
capt <- paste0("\n", capt1, "\n", str_wrap(capt2, 100))

pdata <- corr_wages %>%
  mutate(stname=get_stname(stabbr2),
         stname=ifelse(stabbr2=="other", "Smaller states as a group", stname),
         caldum=stabbr2=="CA")

p <- pdata %>%
  ggplot(aes(y=reorder(stname, rwagp), x=rwagp)) +
  geom_point(aes(colour=caldum), size=1.5) +
  scale_colour_manual(values=c("blue", "red")) +
  theme_bw() +
  labs(x="Annual wage, no adjustments", y=NULL,
       caption=capt) +
  ggtitle(label=gtitle, subtitle = gsubtitle) +
  theme(axis.text.y = element_text(hjust = 0)) +
  geom_vline(xintercept = median(pdata$rwagp)) +
  scale_x_continuous(breaks=seq(0, 100e3, 10e3), labels=label_comma(accuracy=1, prefix="$"), limits=c(30e3, 90e3)) +
  legend_none +
  caption_left

p

ggsave(here::here("results", "wages_acs.png"), plot=p, width=10, height=8, scale=1.25)
```


## Characteristics of correctional workers in California versus the United States

### Education

Wages might be expected to be higher in states where correctional officers have greater education.

California correctional officers have about the same educational attainment as those in the median state.

```{r include=TRUE, fig.width=6, fig.height=8}
capt1 <- "Note: vertical line marks median"
capt2 <- paste0("Source: ", source_acs, "; and ", source_rpp, ".")
capt <- paste0("\n", capt1, "\n", str_wrap(capt2, 100))

p <- corr_summary %>%
  ggplot(aes(1 - ltassoc, rppwagp, label=stabbr2, colour=dumca)) +
  geom_point(size=0.275, colour="black") +
  # geom_text(size=2.5, position = position_jitter()) +
  geom_text(size=2.5, nudge_x=-0.0075) +
  geom_vline(xintercept = median(1 - corr_summary$ltassoc), size=0.1, colour="black") +
  scale_colour_manual(values=c("blue", "red")) +
  scale_x_continuous(name="% of correctional officers with associate's degree or higher",
                     labels = label_comma(scale=100, accuracy=1, suffix="%"),
                     breaks=seq(.1, 1, .05)) +
  scale_y_continuous(name="Annual wage, adjusted for state price differences",
                     labels = label_comma(accuracy=1, prefix="$")) +
  theme_bw() +
  legend_none +
  ggtitle("Wages and education of correctional officers by state, at 2019 income level",
          subtitle="Wages adjusted for price differences across states.") +
  labs(caption=capt) +
  caption_left
p

```

### Experience

Wages might be expected to be higher in states where correctional officers have greater experience.

California correctional officers have about 2 more years of experience, on average, than those in the median state.

```{r include=TRUE, fig.width=6, fig.height=8}
capt1 <- "Note: vertical line marks median"
capt2 <- paste0("Source: ", source_acs, "; and ", source_rpp, ".")
capt <- paste0("\n", capt1, "\n", str_wrap(capt2, 100))

p <- corr_summary %>%
  ggplot(aes(exp, rppwagp, label=stabbr2, colour=dumca)) +
  geom_point(size=0.275, colour="black") +
  # geom_text(size=2.5, position = position_jitter()) +
  geom_text(size=2.5, nudge_x=-0.1) +
  geom_vline(xintercept = median(corr_summary$exp), size=0.1, colour="black") +
  scale_colour_manual(values=c("blue", "red")) +
  scale_x_continuous(name="Average years of experience of correctional officers (estimated)",
                     labels = label_comma(accuracy=1),
                     breaks=seq(0, 50, 1)) +
  scale_y_continuous(name="Annual wage, adjusted for state price differences",
                     labels = label_comma(accuracy=1, prefix="$")) +
  theme_bw() +
  legend_none +
  ggtitle("Wages and experience of correctional officers by state, at 2019 income level",
          subtitle="Wages adjusted for price differences across states.") +
  labs(caption=capt) +
  caption_left
p


```

<br>
<br>
    
    

## Table summarizing California Correctional workers versus other states
```{r tab_acs_summary, include=TRUE}

# top10data  # top 10 from OES

uswtdmeans <- corr_summary %>%
  summarise(across(c(rppwagp, rwagp, exp, ltassoc, male), ~ wtd.mean(.x, weights=wtdn))) %>%
  mutate(stabbr2="US", stname="United States average")

tabdata <- top10data %>%
  select(stabbr2=stabbr) %>%
  inner_join(corr_summary, by="stabbr2") %>% # I do it this way to keep states in the top 10 order
  mutate(stname=ifelse(stabbr2=="other", "All other", stname)) %>%
  bind_rows(uswtdmeans %>% select(-stabbr2)) %>%
  mutate(assocplus = 1 - ltassoc) %>%
  select(stname, exp, assocplus)

tab <- tabdata %>%
  gt() %>%
  tab_header(
    title = html("Experience and education of state correctional officers"),
    subtitle= "Top states by cost-of-living adjusted wage, plus U.S. average"
      ) %>%
  cols_label(stname="",
             exp=html("Estimated<br>years of<br>experience"),
             assocplus=html("% with<br>associate's<br>degree or higher")) %>%
  cols_align(align="left", columns = stname) %>%
  fmt_number(
    columns=exp,
    pattern = "{x}",
    decimals=1
  ) %>%
  fmt_percent(
    columns = assocplus,
    decimals = 1) %>%
  tab_source_note(paste0("Source: ", source_acs)) %>%
  cols_width(
    stname ~ px(200),
    everything() ~ px(200)
    ) %>%
  tab_footnote(
    footnote = "Alaska and Rhode Island excluded because each has fewer than 50 observations.",
    locations = cells_title(groups="subtitle")
  )

tab
gtsave(tab, filename="tab_educ_exp.png", path=here::here("results"), expand = 10)

```

# Workplace injury tables

```{r wpiih_table}
# workplace injuries -- intentional harm by another person

topn <- 25

tabdata <- ihus_5year %>%
  filter(ownf %in% c("private", "state", "local")) %>%
  # filter(ftes_mean >= 3000) %>%
  arrange(desc(rate_calc)) %>%
  mutate(rank=row_number(),
         ownf=ifelse(ownf %in% c("state", "local"),
                     paste0(ownf, " gov"),
                     as.character(ownf)),
         label=paste0(oname, " (", ownf, ")")) %>%
  filter(rank <= topn |
           ocode2019=="333012") %>%
  select(label, rate_calc, rank, ftes_mean)

noccs <- nrow(ihus_5year)

tab <- tabdata %>%
  gt() %>%
  cols_hide(c(ftes_mean)) %>%
  tab_header(
    title = "Intentional workplace injuries caused by another person: United States 2015-2019 average",
    subtitle = paste0("Top ", topn, 
                      " occupation-sector combinations, plus correctional officers by sector")
      ) %>%
  tab_spanner(label=html("Injuries requiring days away from work"),
              columns=c(rate_calc, rank)) %>%
  cols_label(label="",
             rate_calc=html("Rate"),
             rank="Rank"
             ) %>%
  cols_align(align="left", columns = label) %>%
  fmt_number(
    columns=rate_calc,
    pattern = "{x}",
    decimals=1
  ) %>%
  fmt_number(
    columns=rank,
    pattern = "{x}",
    decimals=0
  ) %>%
  tab_source_note(paste0("Source: ", source_wpi, ".")) %>%
  cols_width(
    label ~ px(650),
    everything() ~ px(140)
    ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold") # size = px(15), , font = "arial"
      ),
    locations = cells_body(
      rows=str_detect(label, "Correctional")
      )
    ) %>%
  tab_footnote(
    footnote = "Per 10,000 full-time equivalent employees, per year.",
    locations = cells_column_labels(columns = rate_calc)
    )
tab
 
# webshot options
# default zoom=2, expand=5
gtsave(tab, filename="tab_wpih.png", path=here::here("results"), zoom=1, expand=10)

```

# All econometric models summarized -- both fe and dummy

```{r}
casco_vros <- function(cfe){
  # California state correctional officers vs rest of sample
  # based on centered fixed effects
  # assumes the cfe data frame has variables fe and casco
  cfe %>%
    mutate(cfe=fe - mean(fe[!casco]),
           cfepct=exp(cfe) -1) %>%
    filter(casco) 
}
```


## Other states, COs
```{r}
# data
corr_workers_states <- corr_workers %>%
  mutate(stabbr2=ifelse(n >= obs_cutoff, stabbr, "other")) 

```

### Fixed effects model
```{r mod_statecos}
modfe_states <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) | stabbr2,
               data=corr_workers_states)

fe_states <- fixef(modfe_states)

# centered fixed effects
cfe_states <- tibble(stabbr=names(fe_states$stabbr2), fe=fe_states$stabbr2) %>%
  mutate(cfe=fe - mean(fe),
         cfepct=exp(cfe) -1,
         ca_vsother=(1 + cfepct[stabbr=="CA"]) / (1 + cfepct) - 1,
         stname=get_stname(stabbr),
         stname=ifelse(stabbr=="other", "Small states as a group", stname),
         rank=rank(desc(cfe)),
         nrecs=n(),
         casco=stabbr=="CA"
         ) %>%
  arrange(desc(cfepct))
cfe_states

# compare CA to other states rather than to U.S.
states_vros <- casco_vros(cfe_states) # the same, within rounding

```

```{r plot_statecos}
gtitle <- "State correctional officer wages relative to those in the average state"
gsub1 <- "Controlling for experience, education, and demographic characteristics"
gsub2 <- "Wages adjusted for differences in state cost of living"
gsubtitle <- paste0(gsub1, "\n", gsub2)
capt1 <- paste0("\nSource: ", source_acs, "; and ", source_rpp, ".")
capt2 <- "Note: States with fewer than 50 observations were grouped together."
capt <- paste0(str_wrap(capt1, 100), "\n", capt2)
statefe_dots <- cfe_states  %>%
  mutate(label=ifelse(row_number() <= 5, percent(cfepct, accuracy=.1), "")) %>%
  mutate(grp=ifelse(stabbr=="CA", "CA", "other")) %>%
  ggplot(aes(y=reorder(stname, cfepct), x=cfepct)) +
  geom_col(aes(fill=grp), size=1.5, width=0.1) +
  geom_point(aes(colour=grp), size=0.75) +
  geom_text(aes(label=label),
            hjust=0, nudge_x=.003, size=2.25) +
  scale_fill_manual(values=c("red", "blue")) +
  scale_colour_manual(values=c("red", "blue")) +
  theme_bw() +
  labs(x="% above or below average state", y=NULL,
       caption=capt) +
  ggtitle(label=gtitle, subtitle = gsubtitle) +
  theme(axis.text.y = element_text(hjust = 0)) +
  geom_vline(xintercept = 0) +
  scale_x_continuous(breaks=seq(-1, 1, .05), labels=label_percent(accuracy=1)) +
  legend_none +
  caption_left

statefe_dots

ggsave(here::here("results", "statefe_bar.png"), plot=statefe_dots, width=10, height=8, scale=1.0)

```



### Dummy variable model
```{r}
# dummy variable approach
moddum_states <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + casco,
               data=corr_workers_states)
# summary(moddum_states) 
(casco_states <- casco_pct(moddum_states))

```


## Within CA FSL COs

### Fixed effects model
```{r mod_fslcorr}
caworkers_corr <- caworkers %>%
  filter(soc=="33-3012", level != "private")  # drop the 11 private

count(caworkers_corr, level)

mod_cacorrfsl <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp +
                         as.factor(year) | level,
               data=caworkers_corr)
summary(mod_cacorrfsl)

fe_cacorrfsl <- fixef(mod_cacorrfsl)

# centered fixed effects
cfe_cacorrfsl <- tibble(level=names(fe_cacorrfsl$level), fe=fe_cacorrfsl$level) %>%
  mutate(cfe=fe - mean(fe),
         cfepct=exp(cfe) -1,
         casco_vsother=(1 + cfepct[level=="state"]) / (1 + cfepct) - 1,
         casco=level=="state") %>%
  arrange(desc(cfepct)) %>%
  mutate(rank=row_number(),
         nrecs=n())
cfe_cacorrfsl

# compute pctdiff vs rest of sample
cacorrfsl_vros <- casco_vros(cfe_cacorrfsl)
cacorrfsl_vros

```

### Dummy variable model
```{r}
moddum_cacorrfsl <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp +
                            as.factor(year) + casco,
               data=caworkers_corr)
summary(moddum_cacorrfsl)

(casco_cafsl <- casco_pct(moddum_cacorrfsl))

```

## Within-California comparisons: Law, Public Safety, Corrections & Security job cluster
### Create the joblist -- job cluster subset for analysis

```{r cluster_oes}
# get numbers of workers and average wage per OES research database
df <- cal_oes %>%
  filter(atype=="state", year==2020, wtype=="annual") %>%
  mutate(occ=paste0(str_sub(soc, 1, 2), "-", str_sub(soc, 3, 6))) %>%
  filter(occ %in% job_cluster$occ) %>%
  select(occ, occname, emp, wage, starts_with("wp"))

# now oesres 
oesres_clean %>%
  filter(year==2020, stabbr=="CA", occ %in% job_cluster$occ, igroup=="4-digit") %>%
  filter(occ=="23-1022")

tmp <- oesres_clean %>%
  filter(year==2020, stabbr=="CA", occ %in% job_cluster$occ)

oes1 <- oesres_clean %>%
  filter(year==2020, stabbr=="CA", occ %in% job_cluster$occ, igroup=="4-digit") %>%
  mutate(level=case_when(str_detect(naicstitle, "Federal Executive") ~ "federal",
                          str_detect(naicstitle, "State Government") ~ "state",
                          str_detect(naicstitle, "Local Government") ~ "local",
                          TRUE ~ "private")) %>%
  group_by(occ, occname, level) %>%
  summarise(wage_sum=sum(emp * amean, na.rm=TRUE),
            emp=sum(emp, na.rm=TRUE),
            .groups="drop") %>%
  mutate(wage=wage_sum / emp)

cluster_oes <- oes1 %>%
  # filter(level != "other") %>%
  left_join(df %>%
            select(occ, occname_ca=occname, emp_ca=emp, wage_ca=wage),
            by="occ")  %>%
  arrange(occ, level) %>%
  group_by(occ) %>%
  mutate(emp_sum=sum(emp, na.rm=TRUE)) %>%
  select(occ, occname, level, emp, emp_sum, emp_ca, wage, wage_ca, occname_ca) %>%
  ungroup

```


```{r joblist_defined}
job_cluster
# drop:
#  lawyers, magistrates
#  supervisors
#  oes emp < 1000

joblist <- job_cluster %>%
  filter(!str_detect(occname, "Supervis"),
         !str_detect(occname, "Lawyer"),
         !str_detect(occname, "Magistrate"),
         !str_detect(occname, "Judge"),
         !str_detect(occname, "Law Clerk"),
         !str_detect(occname, "Bailiff")) %>% 
  left_join(cluster_oes %>% 
              select(occ, ends_with("_ca")) %>%
              distinct,
            by = "occ") %>%
  filter(!is.na(emp_ca))  # OES data show no jobs

```

```{r lawjobs_data}
caworkers_law <- caworkers %>%
  filter(soc %in% joblist$occ) %>%
  # filter(edattain %in% c("HSgrad", "HSplus", "associate")) %>%
  mutate(edattain=fct_drop(edattain), # drop unused factor levels
         occname_lev=paste0(occname, " (", level, ")")
         ) %>%
  group_by(occname_lev) %>%
  mutate(n=n(),
         occgroup=ifelse(n < obs_cutoff, "lowobs", occname_lev)) %>%
  ungroup

count(caworkers_law, occgroup, soc, occname_lev)
count(caworkers_law, occgroup)
count(caworkers_law, occname)
ns(caworkers_law)
glimpse(caworkers_law)

caworkers_law %>%
  group_by(occname_lev) %>%
  summarise(n=n(), ltassoc=mean(ltassoc), .groups="drop") %>%
  arrange(desc(ltassoc))

caworkers_law %>%
  filter(casco) %>%
  group_by(edattain) %>%
  summarise(n=n(), wtdn=sum(pwgtp), .groups="drop") %>%
  mutate(nsum=sum(n), pct=wtdn / sum(wtdn))

# ~87.6% of CA state COs are in HSgrad, HSplus, associate

caworkers_law_sum <- caworkers_law %>%
  group_by(occgroup) %>%
  summarise(n=n(), 
            wtdn=sum(pwgtp),
            soc=first(soc),
            level=first(level),
            rwagp_avg=wtd.mean(rwagp, weights = pwgtp),
            rppwagp_avg=wtd.mean(rppwagp, weights = pwgtp),
            exp_avg=wtd.mean(exp, weights = pwgtp),
            ltassoc_avg=wtd.mean(ltassoc, weights=pwgtp), .groups="drop") %>%
  mutate(soc=ifelse(occgroup=="lowobs", NA_character_, soc),  # there is not a unique soc
         level=ifelse(occgroup=="lowobs", NA_character_, level),
         geassoc_avg=1 - ltassoc_avg)

count(caworkers_law, level) %>%
  mutate(pct=n / sum(n))

```


### Fixed effects model
```{r mod_jobclust}
mod_calawjobs <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) | occgroup,
               data=caworkers_law)
summary(mod_calawjobs)


fe_calawjobs <- fixef(mod_calawjobs)

# centered fixed effects
cfe_calawjobs <- tibble(occgroup=names(fe_calawjobs$occgroup), fe=fe_calawjobs$occgroup) %>%
  mutate(casco=occgroup=="Correctional officers and jailers (state)",
         cfe=fe - mean(fe),
         cfepct=exp(cfe) -1,
         casco_vsother=(1 + cfepct[casco]) /
           (1 + cfepct) - 1) %>%
  arrange(desc(cfepct)) %>%
  mutate(rank=row_number(),
         nrecs=n())
cfe_calawjobs

calawjobs_vros <- casco_vros(cfe_calawjobs) 
calawjobs_vros

```


```{r plot_jobclust}
gtitle <- "California state correctional officer wages relative to wages for jobs in the same occupational cluster"
gsub1 <- "Controlling for experience, education, and demographic characteristics"
gsub2 <- "Wages adjusted for within-California differences in cost of living"
gsubtitle <- paste0(gsub1, ". ", gsub2, ".")

# gsubtitle <- "Adjusted for Metropolitan Statistical Area (MSA) price levels, and controlling for experience, education, and demographic characteristics"

# capt1 <- paste0("\nSource: ", source_acs, "; and ", source_rpp, ".")
# capt2 <- "Note: Occupations with fewer than 50 observations were grouped together."
# capt <- paste0(str_wrap(capt1, 100), "\n", capt2)

capt1 <- paste0("\nSource: ", source_acs, ".")
capt2 <- paste0("Price adjustments using ", source_rpp, ".")
capt3 <- "Note: Occupations with fewer than 50 observations were grouped together."
capt <- paste0(capt1, "\n", capt2, "\n", capt3)

jobclustfe_dots <- cfe_calawjobs  %>%
  mutate(label=ifelse(row_number() <= 5, percent(cfepct, accuracy=.1), "")) %>%
  mutate(grp=ifelse(casco, "CA", "other")) %>%
  mutate(occgroup=ifelse(occgroup=="lowobs", "Low-observation occupations as a group", occgroup)) %>%
  ggplot(aes(y=reorder(str_wrap(occgroup, 40), cfepct), x=cfepct)) +
  # ggplot(aes(y=reorder(occgroup, cfepct), x=cfepct)) +
  geom_col(aes(fill=grp), size=1.5, width=0.1) +
  geom_point(aes(colour=grp), size=0.75) +
  geom_text(aes(label=label),
            hjust=0, nudge_x=.003, size=2.25) +
  scale_fill_manual(values=c("red", "blue")) +
  scale_colour_manual(values=c("red", "blue")) +
  theme_bw() +
  labs(x="% above or below average job in cluster", y=NULL,
       caption=capt) +
  ggtitle(label=gtitle, subtitle = gsubtitle) +
  theme(axis.text.y = element_text(hjust = 0, size=8)) +
  geom_vline(xintercept = 0) +
  scale_x_continuous(breaks=seq(-1, 1, .05), labels=label_percent(accuracy=1)) +
  legend_none +
  caption_left

jobclustfe_dots

ggsave(here::here("results", "jobclustfe_bar.png"), plot=jobclustfe_dots, width=10, height=8, scale=1.3)

```

### Dummy variable model
```{r}
moddum_calawjobs <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + 
                            as.factor(year) + yoschool_wmean + casco,
               data=caworkers_law)
summary(moddum_calawjobs)

(casco_calawjobs <- casco_pct(moddum_calawjobs))
```

## Within-California comparisons: clustering

```{r}
# data
cluster_base <- caworkers %>%
  filter(casco | ((soc != "33-3012") & (level=="private")))

occ_stats <- cluster_base %>%
  select(soc, occname, pwgtp, agep, exp, mar, sex, edattain, yoschool, ltba, rwagp) %>%
  mutate(edattain=fct_drop(edattain), sex=fct_drop(sex)) %>%
  dummy_cols(select_columns = c("edattain", "mar", "sex"), remove_first_dummy=FALSE) %>%
  select(-c(pwgtp, sex, edattain, mar)) %>%
  group_by(soc, occname) %>%
  summarise(n=n(), across(-n, list(mean=wtd.mean, var=wtd.var)), .groups="drop") %>%
  filter(n > 1)
summary(occ_stats)

# what's the optimal number of clusters??
occ_stats %>%
  select(-c(soc, occname, n, contains("rwagp"))) %>% # we don't want wages in this
  scale() %>%
  fviz_nbclust(kmeans, method = "wss") +
    #geom_vline(xintercept = 4, linetype = 2) +
  labs(subtitle = "Elbow method")
# 6 looks good

occ_stats %>%
  select(-c(soc, occname, n, contains("rwagp"))) %>% # we don't want wages in this
  scale() %>%
  fviz_nbclust(kmeans, method = "silhouette") +
    #geom_vline(xintercept = 4, linetype = 2) +
  labs(subtitle = "silhouette method")  # 4 looks good

# set.seed(123)
# occ_stats %>%
#   select(-c(soc, occname, n, contains("rwagp"))) %>% # we don't want wages in this
#   scale() %>%
#   fviz_nbclust(kmeans, method = "gap_stat", nboot = 50) +
#   labs(subtitle = "Gap statistic method") # 10 looks good

nclust <- 10
kclust_base <- occ_stats %>%
  select(-c(soc, occname, n, contains("rwagp"))) # we don't want wages in this
ns(kclust_base)

kclust <- kclust_base %>%
  scale() %>%
  kmeans(centers=nclust)


occ_clusters <- occ_stats %>%
  mutate(cluster=kclust$cluster) %>%
  group_by(cluster) %>%
  mutate(cascogrp=soc=="33-3012",
         cascogrp=max(cascogrp) %>% as.logical)
summary(occ_clusters)

casco_group <- occ_clusters %>%
  filter(cascogrp, n>=50) %>%
  arrange(cluster, soc, occname) %>%
  select(cluster, soc, occname, n, contains("rwagp"), yoschool_mean, contains("edattain")) %>%
  arrange(desc(rwagp_mean))
sum(casco_group$n)
nrow(casco_group)

caworkers_cluster <- caworkers %>%
  filter(soc %in% casco_group$soc)  %>%
  filter(casco | ((soc != "33-3012") & (level=="private"))) %>%
  # filter(edattain %in% c("HSgrad", "HSplus", "associate")) %>%
  mutate(edattain=fct_drop(edattain), # drop unused factor levels
         occname_lev=paste0(occname, " (", level, ")")
         ) %>%
  group_by(occname_lev) %>%
  mutate(n=n(),
         occgroup=ifelse(n < obs_cutoff, "lowobs", occname_lev)) %>%
  ungroup

summary(caworkers_cluster)
caworkers_cluster %>%
  mutate(married=mar==1, male=sex=="male") %>%
  group_by(casco) %>%
  summarise(across(c(rwagp, married, male, ltassoc, ltba, ltma, agep), ~ wtd.mean(.x, weights=pwgtp)))

caworkers_cluster %>%
  group_by(occname_lev) %>%
  summarise(ltassoc=wtd.mean(ltassoc, weights = pwgtp))

```

```{r cluster_table}
tabdata <- caworkers_cluster %>%
  mutate(married=mar==1, male=sex=="male") %>%
  group_by(casco) %>%
  summarise(n=n(), across(c(rwagp, married, male, ltassoc, ltba, ltma, agep), ~ wtd.mean(.x, weights=pwgtp)),
            .groups="drop") %>%
  mutate(casco=ifelse(casco, "casco", "other")) %>%
  select(-c(ltba, ltma)) %>%
  pivot_longer(cols=-casco) %>%
  pivot_wider(names_from = casco) %>%
  mutate(name=factor(name, 
                     levels=c("n", "agep", "male", "married", "ltassoc", "rwagp"),
                     labels=c("# of observations", "Average age", "% male", "% married",
                              "% with less than an associate's degree", "Average wage"))) %>%
  arrange(name) %>%
  select(name, casco, other)
  
tabdata

tab <- tabdata %>%
  gt() %>%
  tab_header(
    title = "California state correctional officer wages compared to other workers in the same job cluster") %>%
  cols_label(name="Characteristic",
             casco="State correctional officers",
             other="Private sector workers in the cluster") %>%
  cols_align(align="left", columns = name) %>%
  fmt_number(
    columns=c(casco, other),
    rows=str_detect(name, "#"),
    decimals=0,
    pattern="{x}"
    ) %>%
  fmt_number(
    columns=c(casco, other),
    rows=str_detect(name, "age"),
    decimals=1,
    pattern="{x}"
    ) %>%
  fmt_percent(
    columns=c(casco, other),
    rows=str_detect(name, "%"),
    decimals=1
  ) %>%
  fmt_number(
    columns=c(casco, other),
    rows=str_detect(name, "wage"),
    decimals=0,
    pattern="${x}"
    ) %>%
  tab_source_note(paste0("Source: ", source_acs, ".")) %>%
  tab_options(
    table.width = pct(50)
  )

# webshot options
# default zoom=2, expand=5
gtsave(tab, filename="tab_cluster_comparison.png", path=here::here("results"), zoom=2, expand=5)
write_csv(tabdata, here::here("results", "tab_cluster_comparison_data.csv"))

```


### Fixed effects model
```{r mod_cluster}
mod_cacluster <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp +
                             as.factor(year) | occgroup,
               data=caworkers_cluster)
summary(mod_cacluster)
fe_cacluster <- fixef(mod_cacluster)

# centered fixed effects
cfe_cacluster <- tibble(occgroup=names(fe_cacluster$occgroup), fe=fe_cacluster$occgroup) %>%
  mutate(casco=occgroup=="Correctional officers and jailers (state)",
         cfe=fe - mean(fe),
         cfepct=exp(cfe) -1,
         casco_vsother=(1 + cfepct[casco]) /
           (1 + cfepct) - 1) %>%
  arrange(desc(cfepct))%>%
  mutate(rank=row_number(),
         nrecs=n())
cfe_cacluster

cacluster_vros <- casco_vros(cfe_cacluster) 
cacluster_vros

```


```{r tab_cluster_top10}
tabdata <- cfe_cacluster %>%
  select(occgroup, cfepct, rank, casco) %>%
  filter(rank <= 10)

tab <- tabdata %>%
  gt() %>%
  cols_hide(casco) %>%
  tab_header(
    title = "Regression results: Top 10 California jobs in the same job cluster as state correctional officers") %>%
  cols_label(occgroup="Occupation",
             cfepct=html("% that wage<br>is above<br>cluster average"),
             rank="Rank") %>%
  cols_align(align="left", columns = occgroup) %>%
  fmt_percent(
    columns=cfepct,
    decimals=1
  ) %>%
  fmt_number(
    columns=rank,
    decimals=0
    ) %>%
  tab_source_note(paste0("Source: ", source_acs, ".")) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
      ),
    locations = cells_body(
      rows=casco
    )
  ) %>%
  tab_options(
    table.width = pct(75)
  )
tab

# webshot options
# default zoom=2, expand=5
gtsave(tab, filename="tab_cluster_regtop10.png", path=here::here("results"), zoom=2, expand=5)
write_csv(tabdata, here::here("results", "tab_cluster_regtop10_data.csv"))
```

```{r plot_cluster}
gtitle <- "California state correctional officer wages relative to wages for jobs in the same occupational cluster"
gsub1 <- "Controlling for experience, education, and demographic characteristics"
gsub2 <- "Wages adjusted for within-California differences in cost of living"
gsubtitle <- paste0(gsub1, ". ", gsub2, ".")

capt1 <- paste0("\nSource: ", source_acs, ".")
capt2 <- paste0("Price adjustments using ", source_rpp, ".")
capt3 <- "Note: Occupations with fewer than 50 observations were grouped together."
capt <- paste0(capt1, "\n", capt2, "\n", capt3)

caclusterfe_dots <- cfe_cacluster  %>%
  mutate(label=ifelse(row_number() <= 5, percent(cfepct, accuracy=.1), "")) %>%
  mutate(grp=ifelse(casco, "CA", "other")) %>%
  mutate(occgroup=ifelse(occgroup=="lowobs", "Low-observation occupations as a group", occgroup)) %>%
  ggplot(aes(y=reorder(str_wrap(occgroup, 40), cfepct), x=cfepct)) +
  # ggplot(aes(y=reorder(occgroup, cfepct), x=cfepct)) +
  geom_col(aes(fill=grp), size=1.5, width=0.1) +
  geom_point(aes(colour=grp), size=0.75) +
  geom_text(aes(label=label),
            hjust=0, nudge_x=.003, size=2.25) +
  scale_fill_manual(values=c("red", "blue")) +
  scale_colour_manual(values=c("red", "blue")) +
  theme_bw() +
  labs(x="% above or below average job in cluster", y=NULL,
       caption=capt) +
  ggtitle(label=gtitle, subtitle = gsubtitle) +
  theme(axis.text.y = element_text(hjust = 0, size=8)) +
  geom_vline(xintercept = 0) +
  scale_x_continuous(breaks=seq(-1, 1, .05), labels=label_percent(accuracy=1)) +
  legend_none +
  caption_left

caclusterfe_dots

ggsave(here::here("results", "caclusterfe_bar.png"), plot=caclusterfe_dots, width=10, height=12, scale=1.3)

```

### Dummy variable model
```{r}
moddum_cacluster <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp +
                             as.factor(year) + casco,
               data=caworkers_cluster)
summary(moddum_cacluster)
(casco_cacluster <- casco_pct(moddum_cacluster))

```


# Summary table of casco premium (California state correctional officers)

```{r premium_table}
mod_vars <- read_delim(
"modname; vrosname; compgroup
moddum_states; states_vros; State correctional officers in other states (small states grouped together)
moddum_cacorrfsl; cacorrfsl_vros; California federal and local government correctional officers
moddum_calawjobs; calawjobs_vros; California public and private-sector workers in the Law, Public Safety, Corrections & Security job cluster
moddum_caworkered; caworkered_vros; California private-sector workers with at least a high-school degree, but less than a bachelor's degree
moddum_cacluster; cacluster_vros; California private-sector workers in occupations with similar education, experience, and worker characteristics", 
delim=";", trim_ws=TRUE
) %>% filter(modname != "moddum_caworkered")
problems()
mod_vars

modlist <- mget(mod_vars$modname)
modlist["moddum_states"]
nobs(modlist[[1]])
# mods <- namedList(moddum_states, moddum_cacorrfsl, moddum_calawjobs)

# create a data frame with needed information
f <- function(vrosname){
  df <- get(vrosname)
  df %>% select(casco_fepremium=cfepct, rank, nrecs)
}

tabdata <- mod_vars %>%
  mutate(mod=modlist[modname],
         nobs=purrr::map_int(mod, nobs),
         casco_dumpremium=purrr::map_dbl(mod, casco_pct),
         purrr::map_dfr(vrosname, f)) %>%
  mutate(ranking=paste0("#", rank, " out of ", nrecs, " groups")) %>%
  select(-mod) # mod causes trouble with gt() even if hidden
tabdata

tab <- tabdata %>%
  select(compgroup, casco_fepremium, ranking) %>%
  gt() %>%
  tab_header(
    title = "California state correctional officer wages compared to other workers",
    subtitle = "Adjusted for cost-of-living differences, and controlling for education, experience, and demographic characteristics"
      ) %>%
  cols_label(compgroup="Comparison group",
             casco_fepremium=html("California state<br>correctional officer<br>premium relative<br>to other workers"),
             ranking="Ranking"
             ) %>%
  cols_align(align="left", columns = compgroup) %>%
  cols_align(align="right", columns = ranking) %>%
  fmt_percent(
    columns=casco_fepremium,
    decimals=1
  ) %>%
  tab_source_note(paste0("Source: ", source_acs, ".")) %>%
  cols_width(
    compgroup ~ px(400),
    everything() ~ px(200)
    ) %>%
    tab_footnote(
    footnote = "The premium relative to other states (excluding California) is slightly greater than the premium in the text relative to the U.S. average (including California).",
    locations = cells_body(columns=compgroup,
                           rows=1)
  ) %>%
    tab_footnote(
    footnote = "See text and appendix for details.",
    locations = cells_title(groups="subtitle")
  ) %>%
  tab_options(
    table.width = pct(75)
  )
# tab %>%
#   tab_style(
#     style = cell_text(whitespace = "pre-wrap"),
#     locations = cells_body(
#       columns = ranking
#       )
#     )

# webshot options
# default zoom=2, expand=5
gtsave(tab, filename="tab_model_summary.png", path=here::here("results"), zoom=1.5, expand=5)
write_csv(tabdata, here::here("results", "tab_model_summary_data.csv"))
  

```


# Pension benefits
## Get data
```{r}
library(Microsoft365R)  # to download onedrive files

# constants ---------------------------------------------------------------

# xldir <- r"(C:\Users\donbo\OneDrive\Documents\CA_BU6_OneDrive\)"
# xlfn <- "Boyd_CABU6.xlsx"
static <- here::here("boyd", "Boyd_CABU6_static.xlsx")

# initial onedrive setup --------------------------------------------------
# https://cran.r-project.org/web/packages/Microsoft365R/vignettes/od_sp.html
# The purpose of this section and the next is to let me keep the Excel file open
# in onedrive, and update it with new parameters, etc. Onedrive does not let me
# read from the file while it is open, so the next section gets the latest
# version of the file and copies it to the project directory, appending "static"
# to the name. That file can then be read into R, even while keeping the
# onedrive counterpart open.

# It's important to run the next section after each significant update to the
# file, so that we are always working with the latest version of the parameters,
# etc.

od <- get_personal_onedrive()

# update onedrive data ----------------------------------------------------
odfn <- "Boyd_CABU6.xlsx"
odpath <- "Documents/CA_BU6_OneDrive/Boyd_CABU6.xlsx"

# copy the onedrive excel file to the project directory, with "static" added to name
od$download_file(src=odpath, dest=static, overwrite = TRUE) 

```

## Get updated workers data
```{r}
# update worker data -------------------------------------------------------------
workers1 <- read_excel(static, sheet="workers")

workers <- workers1 %>%
  mutate(worker=row_number(),
         yoe=2021,
         yob=yoe - aoe,
         yod=yob + aod,
         fyos=aor - aoe) %>%  # final years of service
  select(worker, yob, yoe, yod, aoe, aor, aod, fyos, fas)
workers

```

## parameters
```{r}
# update retirement plan parameters ---------------------------------------
prange <- "B2:K49"
params1 <- read_excel(static, sheet="retplan_parameters", range=prange, skip = 1)
params1

params2 <- params1 %>%
  filter(!is.na(col)) %>%
  pivot_longer(cols=-col, names_to = "xletter") %>%
  pivot_wider(names_from = col)
params2

idvars <- c("xletter", "stabbr", "tier", "tname")
lvars <- c("ss_covered", "db_covered", "db_cola_compound", "dc_covered") # logical
cvars <- NULL  # character
nvars <- setdiff(names(params2), c(idvars, lvars, cvars))  # numeric
nvars
params <- params2 %>%
  select(-xletter) %>%
  mutate(across(all_of(lvars), as.logical),
         across(all_of(nvars), as.numeric))
params
glimpse(params)
summary(params)

```

```{r}
# merge workers and parameters --------------------------------------------
names(workers)
names(params)
xvars <- c("stabbr", "tier", "tname", "db_covered", "ss_covered", "dc_covered")
paramvars <- setdiff(names(params), xvars)
data <- 
  full_join(workers, params,
            by = character()) %>%  # cartesian product
  nest(wdata=c(yob:fas)) %>%  # worker data
  nest(params=all_of(paramvars)) %>%  # retirement plan parameters
  mutate(id=row_number()) %>%
  select(id, worker, stabbr, tier, tname, db_covered, ss_covered, dc_covered, everything())
data

# data <- expand_grid(params, workers)  # same thing as full join by character()
data %>%
  unnest(wdata)

data %>%
  unnest(params)

```

## Define additional parameters and functions
```{r cpi}
#.. ONETIME get and save cpi: only do this when data are updated ----
# source(here::here("r", "ONETIME_get_and_save_cpi.r"))
#.. END ONETIME get and save cpi ----

# inflation constants
realwage_pch <-  0.009007175  # average real growth in wage index, 1950-ish to 2020
cpi_pch <- .02
nomwage_pch <- realwage_pch + cpi_pch

# Social Security parameters
ss_eecrate <- .062
source(here::here("r", "functions_socsec.r"))

source(here::here("r", "functions_DBplans.r"))
source(here::here("r", "functions_DCplans.r"))

```

## Calculate results
```{r}
# calculate results -------------------------------------------------------
data %>% unnest(cols=params)

check <- data %>%
  # filter(stabbr != "MA") %>%
  rowwise() %>%
  # build a series of list-columns each of which has a dataframe from age of entry to age of death
  mutate(base=list(fbase(wdata)),
         socsec=list(fsocsec(ss_covered, wdata, base, params))) %>%
  unnest(cols=c(base, socsec))

retinc <- data %>%
  # filter(stabbr != "MA") %>%
  rowwise() %>%
  # build a series of list-columns each of which has a dataframe from age of entry to age of death
  mutate(base=list(fbase(wdata)),
         socsec=list(fsocsec(ss_covered, wdata, base, params)),
         pension=list(pension(db_covered, stabbr, tier, wdata, base, params)),
         dcvalues=list(dcvalues(dc_covered, wdata, base, params)))
retinc
# glimpse(retinc)
```


# Employee health benefits


```{r}
# gcc benefits ----

coeh2 <- coeh %>%
  mutate(hlthpct=healthdentalvision / totalwages)
quantile(coeh2$hlthpct, na.rm=TRUE)  

coeh2 %>%
  group_by(position) %>%
  summarise(qtiledf(.data$hlthpct))

coeh2 %>%
  group_by(position) %>%
  summarise(n=n(),
            wages=sum(totalwages), 
            hdv=sum(healthdentalvision),
            across(c(regularpay, overtimepay, lumpsumpay, otherpay, totalwages, healthdentalvision), mean),
            .groups = "drop") %>%
  mutate(pct=hdv / wages,
         pctreg=healthdentalvision / regularpay,
         totvreg=totalwages / regularpay)

coeh2 %>%
  filter(hlthpct < 1, hlthpct > 0) %>%
  filter(totalwages >= 10e3, hlthpct > .1) %>%
  ggplot(aes(totalwages, hlthpct)) +
  geom_point() +
  scale_x_log10() +
  scale_y_log10()

```


# Compare wage data from different data sources
```{r}
taboes <- oesres_clean %>%
  filter(year==2020, stabbr=="CA", level=="state") %>%
  mutate(src="oes", n=nrow(.)) %>%
  select(src, n, emp, wage=amean)

tabacs <- caworkers %>%
  filter(soc=="33-3012", level=="state") %>%
  summarise(src="acs", n=n(), emp=sum(pwgtp), wage=wtd.mean(rwagp, weights = pwgtp))

tabgcc <- casco_gcc %>%
  summarise(src="gcc", n=n(), emp=n(), across(c(totwage, regpay, otpay, lumppay, otherpay), mean)) %>%
  rename(wage=totwage) %>%
  mutate(regot=regpay + otpay) %>%
  select(src, n, emp, wage, regot, everything())

tabdata <- bind_rows(taboes, tabacs, tabgcc) %>%
  mutate(src=factor(src,
                    levels=c("oes", "acs", "gcc"),
                    labels=c("Occupational Employment and Wage Statistics",
                             "American Community Survey (2019 5-year ACS PUMS)",
                             "SCO's Government Compensation in California")))
tabdata

tab <- tabdata %>%
  select(-regot) %>%
  gt() %>%
  tab_header(
    title = "California state correctional officer average pay in 2020",
    subtitle = "Different data sources"
      ) %>%
  tab_spanner("Components of total wages", columns=-c(src, n, emp, wage)) %>%
  cols_label(src=html("Data source"),
             n=html("# of records in the data"),
             emp=html("# of workers represented by the data"),
             wage=html("Total wages"),
             regpay=html("Regular pay"),
             otpay=html("Overtime pay"),
             lumppay=html("Lump sum pay"),
             otherpay=html("Other pay")
             ) %>%
  cols_align(align="left", columns = src) %>%
  fmt_number(
    columns=c(wage, contains("pay")),
    pattern="${x}",
    decimals=0
  ) %>%
  fmt_number(
    columns=c(n, emp),
    decimals=0
  ) %>%
  fmt_missing(columns = everything(), missing_text = "--") %>%
  cols_width(
    src ~ px(150),
    c(n, emp) ~ px(75),
    everything() ~ px(50)
    ) %>%
  tab_options(
    table.width = pct(85)
  )

tab
# webshot options
# default zoom=2, expand=5
gtsave(tab, filename="tab_data_compare.png", path=here::here("results"), zoom=1.5, expand=10)

```


