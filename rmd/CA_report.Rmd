---
title: "California Bargaining Unit 6 Compensation Analysis"
author: "Don Boyd"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook:
    df_print: paged
    fig_height: 6
    fig_width: 8
    toc: yes
    toc_depth: 4
    toc_float: true
    number_sections: yes
editor_options:
  chunk_output_type: inline
---

```{r links}
# https://download.bls.gov/pub/time.series/cm/
# NCS: https://download.bls.gov/pub/time.series/nb/
# https://www.pewtrusts.org/~/media/Assets/2014/08/StateEmployeeHealthCareReportSeptemberUpdate.pdf

```

```{r runall, eval=FALSE, echo=FALSE}
# When we want a final report, run the following code selectively "by hand" (interactively)
# -- NEVER using Knit with eval=TRUE
# note <br> breaks line for html output but \n should break for pdf; also could try |

rmdfn <- ".CA_report.rmd" # this file
outfn <- paste0("report_", format(Sys.time(), "%Y-%m-%d"), ".html")
rmarkdown::render(rmdfn, output_format="html_document", output_file=outfn)

# library("RCurl")
# ftpUpload(outfn, "ftp://kffrig:boyd4812@files.000webhost.com/public_html/KFF_RIG_MedicaidCuts_new.html")

# Note may b safest to fully exit RStudio and restart it before running whole thing. Otherwise knitr may get confused
# and include repetitive information in the output html file.

```

```{r setup, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = FALSE, include=FALSE, eval=TRUE, message = FALSE, warning = FALSE,
                      fig.width=5, fig.height=4)
```

```{r libraries}

library(tidyverse)
options(tibble.print_max = 80, tibble.print_min = 80) # if more than 60 rows, print 60 - enough for states
library(scales)
library(lubridate)
library(purrr)
library(readxl)
library(vroom)
library(haven)
library(RSQLite)

library(Hmisc)

library(kableExtra)
library(gt)
library(knitr)
library(arrow)

library(maps)
# https://cran.r-project.org/web/packages/usmap/vignettes/mapping.html
library(usmap)
library(gridExtra)
library(RcppRoll)
library(ggbreak)
library(patchwork)
library(RColorBrewer)

library(fixest)
library(cgwtools)  # for resave

library(btools)
library(bdata)
```

```{r locations}
# acsdir <- r"(E:\data\acs\)"
# pumsdir <- paste0(acsdir, "pums/")
# csvdir <- paste0(pumsdir, "csv/")

rppdir <- r"(E:\data\BEA_regional_price_parities\)"

resdir <- r"(E:\data\oesw\oes_research\)"

wpid <- r"(E:\data\BLS_WorkplaceInjuries\)"

oeswcad <- r"(E:\data\oesw_caledd\)"

pumsdir <- r"(E:\data\acs\pums\)"
pumsdocs <- paste0(pumsdir, r"(5year\documentation\)")
fnpumscodes <- "ACSPUMS2015_2019CodeLists.xlsx"

sqlitedir <- r"(E:\data\acs\pums\sqlite\)"

acsfn <- "acs2019_5year"
acsdb <- paste0(sqlitedir, acsfn, ".sql3")

```

```{r constants}
# 33-3012	Correctional Officers and Jailers  OES code
# 3802 Correctional officers and jailers 33-3012   # occ code 2018
# NY, MA
# TX, FL
# AZ, NV, OR, WA

compstates <- c("AZ", "NV", "OR", "WA", # near neighbors
                "TX", "FL",  # large
                "NY", "MA")  # large, expensive

obs_cutoff <- 50


#.. graph theme items ----
legend_none <- theme(legend.position = "None")
legend_notitle <- theme(legend.title = element_blank())
caption_left <- theme(plot.caption = element_text(hjust = 0))

#.. source notes ----
source_oesres <- "U.S. Bureau of Labor Statistics, Occupational Employment and Wage Statistics Research Database"

# key facts empty list
keyfacts <- list()

```

# Reading this document

For key conclusions see [the key conclusions section](#conclusions)

For details, you can read through this document sequentially, or look for sections where the header includes "Key result" or "Key data" (look at the table of contents).

# Introduction

The goals of this project are to address two main questions in relation to California Correctional Peace Officers (Bargaining Unit 6 -- BU6):

-   What do relevant available data say about:

    -   How unit members are compensated relative to appropriate comparisons, including other states and, to the extent practical, the private sector?
    -   How much higher or lower is their compensation?
    -   How has their absolute and relative compensation changed since the last compensation study (prepared in 2013, released in 2015)?

    In doing this, adjust for regional cost differences to the extent practical. Pay attention to the fact that salaries and benefits of new hires have changed in recent years.

-   What are the leverage points -- the key methodological and data choices that might influence what a new CalHR study would conclude?

This report has a section on data preparation and a section on data analysis. There is no data analysis in the data preparation section. It serves as my documentation, and will help me in writing the report. However, it may be of interest to you.

# Data preparation

NOTE to self: Only run when data or methods change.

```{r functions_misc, eval=FALSE}
get_stname <- function(stabbr){
  sts <- c("US", "DC", state.abb)
  allnames <- c("United States", "District of Columbia", state.name)
  allnames[match(stabbr, sts)]
}

save(get_stname, file=here::here("data", "misc_functions.rdata"))
# load(file=here::here("data", "misc_functions.rdata"), verbose=TRUE)

```

## Regional price measures

This section:

-   Gets regional price parity indexes (i.e., regional price indexes) from the [Bureau of Economic Analysis](https://apps.bea.gov/regional/downloadzip.cfm) (BEA) for states, Metropolitan Statistical Areas (MSAs), and the metro-nonmetro areas of individual states, for all available years (2008-2019).
-   Parses the data and saves for later use.

We need these data because we want to adjust for regional price differences when comparing correctional officer salaries across states, and when comparing these salaries to private sector salaries in different regions of California.

```{r rpp_info}

# https://apps.bea.gov/regional/downloadzip.cfm
# SARPP.zip is states
# MARPP.zip is metropolitan areas
# PARPP.zip is metro/non-metro areas within states


# https://www.bea.gov/news/2020/real-personal-income-state-and-metropolitan-area-2019
# Regional Price Parities in 2019
# 
# Regional price parities (RPPs) measure the differences in price levels across states and metropolitan areas for a given year and are expressed as a percentage of the overall national price level. The all items RPP covers all consumption goods and services, including housing rents. Areas with high/low RPPs typically correspond to areas with high/low price levels for rents.
# 
# States with the highest RPPs were Hawaii (119.3), California (116.4), and New York (116.3) (table 3).
# States with the lowest RPPs were Mississippi (84.4), Arkansas (84.7), and Alabama (85.8).
# Across states, California had the highest RPP for housing rents (153.6), and Mississippi had the lowest (60.0).
# Large metropolitan areas with the highest RPPs were San Francisco-Oakland-Berkeley, CA (134.5), New York-Newark-Jersey City, NY-NJ-PA (125.7), and Los Angeles-Long Beach-Anaheim, CA (118.8) (table 6).
# Large metropolitan areas with the lowest RPPs were Cleveland-Elyria, OH (89.9), St. Louis, MO-IL (90.1), and Cincinnati, OH-KY-IN (90.6).
# Across large metropolitan areas, San Francisco-Oakland-Berkeley, CA, had the highest RPP for housing rents (200.3), and Cleveland-Elyria, OH, had the lowest (76.3).
# Across all metropolitan areas, San Jose-Sunnyvale-Santa Clara, CA, had the highest RPP for housing rents (224.0), and Beckley, WV, had the lowest (44.0).
```

```{r get_rpp, eval=FALSE}
# non metro price indexes
# https://apps.bea.gov/iTable/iTable.cfm?reqid=70&step=1&acrdn=8

#.. state price indexes ----
# con <- unz(paste0(dir, "/", "SQGDP.zip"), fn) # read directly from zip file
zname <- "SARPP.zip"
fn <- "SARPP_STATE_2008_2019.csv"
con <- unz(paste0(rppdir, zname), fn) # read directly from zip file
df <- read_csv(con, col_types = cols(.default = "c"))

sarpp1 <- df %>%
  filter(LineCode=="1") %>%
  mutate(stfips=str_sub(GeoFIPS, 1, 2)) %>%
  left_join(stcodes %>% select(stfips, stabbr), by = "stfips")
sarpp1 %>% select(stfips, stabbr, GeoName)
  
sarpp <- sarpp1 %>%
  pivot_longer(cols=`2008`:`2019`, names_to = "year", values_to = "rpp") %>%
  mutate(stfips=as.integer(stfips), year=as.integer(year), rpp=as.numeric(rpp) / 100) %>%
  select(stabbr, stfips, year, rpp)

sarpp %>%
  filter(stabbr %in% c("US", "CA", "NY", "FL", "TX", "MA")) %>%
  ggplot(aes(year, rpp, colour=stabbr)) +
  geom_line() +
  geom_point()

#.. metropolitan area indexes ----
zname <- "MARPP.zip"
fn <- "MARPP_MSA_2008_2019.csv"
con <- unz(paste0(rppdir, zname), fn) # read directly from zip file
df <- read_csv(con, col_types = cols(.default = "c"))
glimpse(df)

marpp <- df %>%
  filter(LineCode=="1") %>%
  pivot_longer(cols=`2008`:`2019`, names_to = "year", values_to = "rpp") %>%
  mutate(fips=as.integer(GeoFIPS), 
         year=as.integer(year), 
         rpp=as.numeric(rpp) / 100) %>%
  select(fips, geoname=GeoName, year, rpp)


#.. metro-nonmetro by state price indexes ----
zname <- "PARPP.zip"
fn <- "PARPP_PORT_2008_2019.csv"
con <- unz(paste0(rppdir, zname), fn) # read directly from zip file
df <- read_csv(con, col_types = cols(.default = "c"))
glimpse(df)

parpp <- df %>%
  filter(LineCode=="1") %>%
  pivot_longer(cols=`2008`:`2019`, names_to = "year", values_to = "rpp") %>%
  mutate(type=case_when(str_sub(GeoFIPS, 3, 5)=="998" ~ "metro",
                        str_sub(GeoFIPS, 3, 5)=="999" ~ "nonmetro",
                        str_sub(GeoFIPS, 3, 5)=="000" ~ "US",
                        TRUE ~ "ERROR"),
         stfips=str_sub(GeoFIPS, 1, 2),
         year=as.integer(year), 
         rpp=as.numeric(rpp) / 100) %>%
  left_join(stcodes %>% select(stfips, stabbr), by = "stfips") %>%
  mutate(stfips=as.integer(stfips)) %>%
  select(stfips, stabbr, geoname=GeoName, type, year, rpp)

#.. which ones are in California ----
carpp <- marpp %>%
  filter(str_detect(geoname, coll("CA"))) %>%
  mutate(stabbr="CA", type="metro") %>%
  bind_rows(parpp %>%
              filter(type=="nonmetro", stabbr=="CA") %>%
              select(stabbr, geoname, type, year, rpp))
count(carpp, fips, geoname)


# create a lagyear variable for each file so that we can merge against 1 year earlier
sarpp <- sarpp %>% mutate(yearplus1=year + 1)
marpp <- marpp %>% mutate(yearplus1=year + 1)
carpp <- carpp %>% mutate(yearplus1=year + 1)

save(sarpp, marpp, carpp, file=here::here("data", "rpp.rdata"))

# There are 26 Californial regional price indexes
# fips  geoname                                                                  n
#    <chr> <chr>                                                                <int>
#  1 12540 Bakersfield, CA (Metropolitan Statistical Area)                         12
#  2 17020 Chico, CA (Metropolitan Statistical Area)                               12
#  3 20940 El Centro, CA (Metropolitan Statistical Area)                           12
#  4 23420 Fresno, CA (Metropolitan Statistical Area)                              12
#  5 25260 Hanford-Corcoran, CA (Metropolitan Statistical Area)                    12
#  6 31080 Los Angeles-Long Beach-Anaheim, CA (Metropolitan Statistical Area)      12
#  7 31460 Madera, CA (Metropolitan Statistical Area)                              12
#  8 32900 Merced, CA (Metropolitan Statistical Area)                              12
#  9 33700 Modesto, CA (Metropolitan Statistical Area)                             12
# 10 34900 Napa, CA (Metropolitan Statistical Area)                                12
# 11 37100 Oxnard-Thousand Oaks-Ventura, CA (Metropolitan Statistical Area)        12
# 12 39820 Redding, CA (Metropolitan Statistical Area)                             12
# 13 40140 Riverside-San Bernardino-Ontario, CA (Metropolitan Statistical Area)    12
# 14 40900 Sacramento-Roseville-Folsom, CA (Metropolitan Statistical Area)         12
# 15 41500 Salinas, CA (Metropolitan Statistical Area)                             12
# 16 41740 San Diego-Chula Vista-Carlsbad, CA (Metropolitan Statistical Area)      12
# 17 41860 San Francisco-Oakland-Berkeley, CA (Metropolitan Statistical Area)      12
# 18 41940 San Jose-Sunnyvale-Santa Clara, CA (Metropolitan Statistical Area)      12
# 19 42020 San Luis Obispo-Paso Robles, CA (Metropolitan Statistical Area)         12
# 20 42100 Santa Cruz-Watsonville, CA (Metropolitan Statistical Area)              12
# 21 42200 Santa Maria-Santa Barbara, CA (Metropolitan Statistical Area)           12
# 22 42220 Santa Rosa-Petaluma, CA (Metropolitan Statistical Area)                 12
# 23 44700 Stockton, CA (Metropolitan Statistical Area)                            12
# 24 46700 Vallejo, CA (Metropolitan Statistical Area)                             12
# 25 47300 Visalia, CA (Metropolitan Statistical Area)                             12
# 26 49700 Yuba City, CA (Metropolitan Statistical Area)                           12


```

## Occupational Employment and Wage Statistics (OES or OESW)

This section downloads, parses, and saves:

-   [OES research data](https://www.bls.gov/oes/current/oes_research_estimates.htm) for the government sector, many years. This has the advantage of breaking out ownership (state, local government), by state, by detailed occupation, for many years.

```{r bls_research_corr, eval=FALSE}
# https://www.bls.gov/oes/current/oes_research_estimates.htm
# The OEWS program provides wage and employment estimates by state and industry
# beginning with the May 2012 reference period. These estimates are intended for
# research purposes, and users should be aware of the limitations of the data.
# Estimates prior to May 2012 are not available. Estimates are only available
# for states; industry-specific estimates for metropolitan areas are not
# available. Estimates are only available for detail and major occupation
# groups; industry-specific estimates for broad and minor occupation groups are
# not available.

urlbase <- "https://www.bls.gov/oes/special.requests/"

stcodes
# Add Guam to stcodes
stcodes2 <- bind_rows(stcodes,
                      tibble(stabbr="GU", stfips="66", stname="Guam"))

#.. All NAICS sectors for 2016-2020 ----
# clean up and slim down the externally created file
oesres1 <- readRDS(paste0(resdir, "oesres_allsectors.rds"))
glimpse(oesres1)
count(oesres1, stabbr, area, area_title)
count(oesres1, annual) # 24641=1, 4.5m=NA  # record does not have hourly data
count(oesres1, hourly)  # record does not have annual data
count(oesres1, o_group)  # for some years, tells whether it is detailed, major, total, or something else
count(oesres1, group) # same
count(oesres1, group, o_group)
count(oesres1, i_group)


oesres2 <- oesres1 %>%
  filter(stabbr %in% c("DC", state.abb)) %>%
  mutate(ogroup=ifelse(is.na(o_group), group, o_group)) %>%
  select(stabbr, year, occ, occname, ogroup,
         igroup=i_group, naics, naicstitle=naics_title, 
         emp=tot_emp, hmean=h_mean, amean=a_mean)
count(oesres2, ogroup)

count(oesres2, naics, naicstitle)

# assign level to corrections
f_corrlevel <- function(occ, naics){
  case_when(occ != "33-3012" ~ NA_character_,
            naics %in% c("99", "999000") ~ "fslg",
            naics == "999100" ~ "federal",
            naics == "999200" ~ "state",
            naics == "999300" ~ "local",
            TRUE ~ "private")
  }

oesres3 <- oesres2 %>%
  mutate(level=f_corrlevel(occ, naics))
count(oesres3, level)

saveRDS(oesres3, paste0(resdir, "oesres_clean.rds"))


```

### California EDD OESW data for California

```{r caledd_oesw, eval=FALSE}
# from open data
url <- "https://data.edd.ca.gov/api/views/pwxn-y2g5/rows.csv?accessType=DOWNLOAD"
fn <- "Occupational_Employment_and_Wage_Statistics__OEWS_.csv"
# download.file(url, paste0(oeswcad, fn), mode="wb")  # only download if data base changed

df1 <- read_csv(paste0(oeswcad, fn), col_types=cols(.default = "c"))
glimpse(df1)
summary(df1)

df2 <- df1 %>%
  select(atype=1, aname=2, year=3, qtr=4, indname=5, soc=6, occname=7, wtype=8, emp=9, wage=10)
count(df2, atype) # 4
# California-Statewide	1598			
# California - Statewide	19438			
# Metropolitan Area	355428			
# OES Survey Region	38744	
count(df2, atype, aname)  # 43
count(df2, indname)  # 1, all industries
count(df2, soc, occname)  # 1,110
count(df2, wtype)  # 2 Annual wage or salary, Hourly wage
count(df2, qtr)  # only 1

# qy(1, 2000) qtr <- c("1", "2") year <- c("2000", "2001") btools::qy(as.integer(qtr), as.integer(year))

df3 <- df2 %>%
  filter(str_detect(wtype, "Annual")) %>%
  select(atype, aname, year, soc, occname, emp, wage) %>%
  mutate(year=as.integer(year),
         emp=as.numeric(emp),
         wage=as.numeric(wage),
         soc=ifelse(soc=="0",
                    soc,
                    paste0(str_sub(soc, 1, 2), "-", str_sub(soc, 3, -1))))
count(df3, soc, occname)

# fix some errors in the data!
df4 <- df3 %>%
  # wow! shouldn't have to fix this
  mutate(emp=ifelse(emp==0, NA_real_, emp),
         wage=ifelse(wage==0, NA_real_, wage),
         occname=str_replace(occname, coll(" **"), ""),
         occname=str_replace(occname, coll("*"), ""))

diffnames <- df4 %>%
  select(soc, year, occname) %>%
  distinct() %>%
  group_by(soc) %>%
  mutate(nnames=length(unique(occname))) %>%
  ungroup %>%
  filter(nnames > 1) %>%
  arrange(soc, year)

# get most recent occname for each code
df5 <- df4  %>%
  group_by(soc) %>%
  mutate(mroccname=unique(occname[year==max(year)])) %>%
  ungroup

check <- df5 %>% filter(mroccname != occname)

caledd_oesw <- df5 %>%
  select(atype, aname, year, soc, occname=mroccname, emp, wage)
saveRDS(caledd_oesw, here::here("data", "caledd_oesw.rds"))

```

## Job clusters

For comparisons to the private sector, one approach is to compare against workers in jobs in a similar cluster. See <https://www.onetonline.org/find/career?c=12> <https://careertech.org/career-clusters>

Here we create a list of occupations that are in the "Law, Public Safety, Corrections & Security" job cluster.

```{r job_clusters}
# https://www.onetonline.org/find/career?c=12
# https://www.onetonline.org/find/career/Law_Public_Safety_Corrections_Security.xls?fmt=xls&c=12
# url <- "https://www.onetonline.org/find/career/Law_Public_Safety_Corrections_Security.xls?fmt=xls&c=12"
# url_base <- "https://www.onetonline.org/find/career/"
# fn <- "Law_Public_Safety_Corrections_Security.xls"
# download.file(url, here::here("data_raw", fn), mode="wb")

urlcsv <- "https://www.onetonline.org/find/career/Law_Public_Safety_Corrections_Security.csv?fmt=csv&c=12"
fncsv <- "Law_Public_Safety_Corrections_Security.csv"
download.file(urlcsv, here::here("data_raw", fncsv), mode="wb")

job_cluster1 <- read_csv(here::here("data_raw", fncsv))
job_cluster <- job_cluster1 %>%
  setNames(c("pathway", "occd2", "occname")) %>%
  mutate(occ=str_sub(occd2, 1, -4),
         cluster="Law, Public Safety, Corrections & Security") %>%
  select(occd2, occ, occname, pathway, cluster)

saveRDS(job_cluster, here::here("data", "job_cluster.rds"))

```

## PUMA-MSA crosswalk for California

This section:

-   Gets a [crosswalk](https://usa.ipums.org/usa/resources/volii/MSA2013_PUMA2010_crosswalk.xls) from [IPUMS USA](https://usa.ipums.org/) between:
-   Public Use Microdata Areas (PUMAs), relatively small geographic areas defined for and used in the Census Bureau's American Community Survey (ACS) that is rarely used outside of the ACS; (there are 265 PUMAs in California)l and
-   Metropolitan Statistical Areas, larger and more-widely known geographic areas; (there are 26 MSAs in California);
-   Parses the data
-   Creates a California subset, and
-   Saves for later use

We need such a crosswalk for two reasons:

-   We only have BEA regional price indexes for MSAs, not for PUMAs. ACS microdata identifies the PUMA for each person in the file, but not their MSA. Thus, we need a way to map the 265 California PUMAs in the ACS to the 26 California MSAs, so that we can get the MSA regional price index for each person in the data.
-   There are relatively few observations in some PUMAs for some occupational categories. Thus, the geographically larger MSAs can be more useful for substate regional analyses in California than the PUMAs. Plus, MSAs are more familiar to most people than are PUMAs.

```{r acs_pumas_notes}
# https://www.census.gov/programs-surveys/geography/guidance/geo-areas/pumas.html
# Public Use Microdata Areas (PUMAs) are non-overlapping, statistical geographic
# areas that partition each state or equivalent entity into geographic areas
# containing no fewer than 100,000 people each. They cover the entirety of the
# United States, Puerto Rico, Guam, and the U.S. Virgin Islands. The Census
# Bureau defines PUMAs for the tabulation and dissemination of decennial census
# and American Community Survey (ACS) Public Use Microdata Sample (PUMS) data.
# Additionally, the ACS and Puerto Rico Community Survey use them to disseminate
# their respective period estimates.

# The delineation of new PUMAs occurs after the completion of the decennial
# census as part of a program involving the State Data Centers (SDCs). Decennial
# census population counts and updated census tracts are critical inputs into
# the delineation process.

# PUMA Character 5 Public use microdata area code (PUMA) based on 2010 Census
# definition (areas with population of 100,000 or more, use with ST for unique
# code) 00100..70301 .Public use microdata area codes

# https://www2.census.gov/geo/docs/reference/puma/
# https://www2.census.gov/geo/docs/reference/puma/2010_PUMA_Names.txt

# https://www.brookings.edu/wp-content/uploads/2018/07/ES_THP_071018_where_work_pays_tech_appendix.pdf
# IPUMS has created a crosswalk between PUMAs and metropolitan statistical areas
# (MSAs) that denotes what percent of a given PUMA is in a given MSA. We use
# this crosswalk to group PUMAs into metropolitan areas and state
# non-metropolitan areas. An individual is characterized as living in a MSA if
# they live in a PUMA that is more than 50% in that MSA. They are classified as
# living in a state nonmetropolitan area if they live in a PUMA that is less
# than 50% in any metropolitan area. All states except for Delaware, New Jersey,
# and Rhode Island (and the District of Columbia) have non-metropolitan areas.

# PUMAs to MSAs -- looks like 24-26 MSAs
# https://usa.ipums.org/usa-action/variables/met2013#description_section
# https://usa.ipums.org/usa/resources/volii/MSA2013_PUMA2010_crosswalk.xls
# https://rdrr.io/github/greaterlouisvilleproject/glptools/man/MSA_PUMA.html


# PUMAs to counties -- 58 counties
# https://www.psc.isr.umich.edu/dis/data/resource/detail/1527.html
# https://www.psc.isr.umich.edu/dis/workshop/utilities/p2c.html
# https://www.psc.isr.umich.edu/dis/data/resource/detail/1528.html
# https://www.psc.isr.umich.edu/dis/workshop/utilities/p2c.html
# Three additional fields are output:  the five‐digit FIPS county code, county name, and total county population based on the PUMA populations given in the p2c.equ cross‐walk file.

```

```{r acs_pumas_caxwalk, eval=FALSE}
# https://usa.ipums.org/usa/resources/volii/MSA2013_PUMA2010_crosswalk.xls
pumasdir <- r"(E:\data\acs\pums\pumas\)"
pfn <- "MSA2013_PUMA2010_crosswalk.xls"

# MSA Code	MSA Title	State FIPS Code	State Name	PUMA Code	PUMA Name	MSA 2010 Population	PUMA 2010 Population	Intersection 2010 Population	Percent MSA Population	Percent PUMA Population

pumamsa1 <- read_excel(paste0(pumasdir, pfn)) 
names(pumamsa1)
pumamsa2 <- pumamsa1 %>%
  setNames(c("msacode", "msaname", "stfips", "stname", "puma", "pumaname",
             "msapop", "pumapop", "interpop",
             "pctmsa", "pctpuma")) 
# do we assign any puma to more than one msa??
dups <- pumamsa2 %>%
  group_by(puma, pumaname) %>%
  mutate(n=n()) %>%
  ungroup %>%
  filter(n > 1) %>%
  arrange(puma, pumaname, desc(interpop)) 

pumamsa3 <- pumamsa2 %>%
  # for each puma, keep only the msa to which it has the most assigned pop (interpop)
  # so that we assign 1 and only 1 msa for each puma %>%
  arrange(stfips, puma, pumaname, desc(interpop)) %>%
  group_by(puma, pumaname) %>%
  filter(row_number()==1) %>%
  ungroup %>%
  mutate(across(c(stfips, puma, msacode), as.integer))

pumas_caxwalk <- pumamsa3 %>%
  filter(stfips==6)

# how far off are we?
pumas_caxwalk %>%
  group_by(msacode, msaname) %>%
  summarise(msapop=first(msapop),
            pumasum=sum(interpop),
            .groups = "drop") %>%
  mutate(pdiff=pumasum / msapop -1) %>%
  arrange(-abs(pdiff)) # almost perfect

saveRDS(pumas_caxwalk, here::here("data", "pumas_caxwalk.rds"))

```

## Worplace injuries

```{r eval=FALSE}
url_base <- "https://download.bls.gov/pub/time.series/hc/"
files <- c("hc.age", "hc.case", "hc.category", "hc.category2", "hc.contacts", "hc.data.0.Current", "hc.data.1.AllData", "hc.datatype", "hc.event", "hc.footnote", "hc.gender", "hc.industry", "hc.los", "hc.nature", "hc.occupation", "hc.pob", "hc.race", "hc.series", "hc.source", "hc.txt")
keep <- setdiff(files, "hc.data.0.Current")

url_base <- "https://download.bls.gov/pub/time.series/cs/"
files <- c("cs.age", "cs.case", "cs.category", "cs.contacts", "cs.data.0.Current", "cs.data.1.AllData", "cs.datatype", "cs.event", "cs.footnote", "cs.gender", "cs.hour", "cs.industry", "cs.los", "cs.nature", "cs.occupation", "cs.ownership", "cs.pob", "cs.race", "cs.series", "cs.source", "cs.special", "cs.state", "cs.time", "cs.txt", "cs.weekday")
keep <- setdiff(files, "cs.data.0.Current")

for(file in keep){
  url <- paste0(url_base, file)
  path <- paste0(wpid, "cs/",  file)
  download.file(url, path, mode="wb")
}

# get and save the workplace injuries data
# Field #/Data Element		Length		Value(Example)
# 1.  series_id			  17		HCUSH332233
# 2.  year			   4		1998
# 3.  period			   3		M01
# 4.  value			  12		2360
# 5.  footnote_codes		  10		It varies
# 
# The series_id (HCUSH332233) can be broken out into:
# Code				=			Value
# survey abbreviation		=			HC
# seasonal adjustment code	=			U
# case category			=			SH
# detail code			=			3322
# datatype code			=			3
# case type code			=			3


df <- read_table(paste0(wpid, "cs/", "cs.data.1.AllData"), col_types = "cicnc")
count(df, year)




a <- proc.time()
df <- vroom(paste0(wpid, "cs/", "cs.data.1.AllData"), col_types = "cicnc")
b <- proc.time()
b - a # 31 secs

# a1 <- proc.time()
# df1 <- read_table(paste0(wpid, "cs/", "cs.data.1.AllData"), col_types = "cicnc")
# b1 <- proc.time()
# b1 - a1  # 123 secs

df2 <- df %>%
  filter(str_sub(series_id, 1, 6)=="CSU00X",  # occupational detail
         str_sub(series_id, 13, 14)=="3O")  # datatype and case code

# survey abbreviation		=			cs
# seasonal adjustment code	=			U
# category code			=			00X
# detail code			=			00XXXX
# datatype code			=			3
# case code			=			E
# ownership code			=			1
# state code			=			00
df3 <- df2 %>%
  mutate(detail=str_sub(series_id, 7, 12),
         own=str_sub(series_id, 15, 15),
         stfips=str_sub(series_id, 16, 17)) %>%
  select(series_id, detail, own, stfips, year, value, footnote_codes)
count(df3, detail)  # 1,253
count(df3, own)  # 0, 1, 7, 8, 9
count(df3, stfips)  # 47 including US
count(df3, year) # 2011-2019
count(df3, footnote_codes) %>% NA for all

# create factors
wpioccs <- read_tsv(paste0(wpid, "cs/", "cs.occupation"), col_types = "ccccc")
wpistates <- read_tsv(paste0(wpid, "cs/", "cs.state"), col_types = "ccccc")

df4 <- df3 %>%
  rename(ocode=detail) %>%
  left_join(wpioccs %>% 
              select(ocode=occupation_code, otext=occupation_text),
            by = "ocode") %>%
  left_join(wpistates %>% select(stfips=state_code, stname=state_name), by="stfips") %>%
  left_join(stcodes %>% select(stname, stabbr), by="stname") %>%
  mutate(stfips=as.integer(stfips), 
         stabbr=case_when(stfips==00 ~ "US",
                          stfips==66 ~ "GU",
                          TRUE ~ stabbr))
summary(df4)
count(df4, stfips, stname)
count(df4, stfips, stabbr, stname)

glimpse(df4)
wpirates <- df4 %>%
  select(stabbr, year, own, ocode, otext, value)

saveRDS(wpirates, here::here("data", "wpirates.rds"))


```

## American Community Survey (ACS) data preparation

This section has two subsections:

-   Preparation of codes needed for use with the ACS
-   Preparation of the two main ACS data subsets used in the analysis, extracting relevant information from an SQLITE database of the ACS. This program does not get the full ACS - I did that in a separate program that downloaded the ACS and created the SQLITE database. That was done separately because of the size of the ACS.

### Preparation of ACS codes

```{r}
# fn <- paste0(pumsdocs, "PUMS_Data_Dictionary_2015-2019.csv")
# dict <- read_csv((fn), col_names=FALSE)

```

#### Define a "worker"

This section defines variables to pull from the ACS, and what a "worker" is:

-   The 2015-2019 ACS is a sample of approximately 15 million people nationally.
-   Only some of them are workers (some are children, some are retired, some are prisoners, some are unemployed, etc.)
-   Currently I define a worker as someone who:
-   Is an employee of a private not-for-profit or for-profit entity, or a federal, state, or local government employee. I exclude anyone who is self-employed, or working without pay on a family business or farm, or was unemployed; and
-   Is at least 18 years old
-   Earned at least \$10,000

We need to define a worker for purposes of comparing correctional officer wages to those of other workers. The definition here is based largely on definitions used in academic papers that estimate wage regressions.

```{r acs_worker}
acsvars_string <- "serialno, st, puma, powsp, powpuma, adjinc, pwgtp, agep, cow, mar, schl, sex, wagp, hisp, rac1p, occp, naicsp"

# define the filter definition for a worker so we  have it in only one place
# worker <- expression(wagp >= 10e3, agep >= 18)  # haven't gotten this to work
# sworker <- "schl > 15 & wagp >= 10e3 & agep >= 18"  # as a string - works with filter(eval(parse(text=sworker))), albeit awkward
sworker <- "wagp >= 10e3 & agep >= 18"  # as a string - works with

save(acsvars_string, sworker, file=here::here("data", "acs_constants.rdata"))

```

#### Get a crosswalk of occupation codes

This section:

-   Gets a [crosswalk](https://www2.census.gov/programs-surveys/acs/tech_docs/pums/code_lists/ACSPUMS2015_2019CodeLists.xlsx) between occupation codes used by the Bureau of the Census in the ACS and the somewhat more detaled occupation codes maintained by the Bureau of Labor Statistics and also CalHR (California Human Resources)
-   Parses and saves the data for later use.

We need this crosswalk so that we can (a) identify correctional officers and people in other occupations, and (b) collapse identify selected occupations that are similar in some way to correctional officers.

```{r acs_occ_codes, eval=FALSE}
acsocodes1 <- read_excel(paste0(pumsdocs, fnpumscodes),
                      sheet="OCCP & SOCP",
                      range="A11:C881",
                      col_names=c("occp", "soc", "occname"))
acsocodes <- acsocodes1 %>%
  filter(nchar(occp)==4) %>%
  mutate(occp=as.integer(occp))

saveRDS(acsocodes, here::here("data", "acsocodes.rds"))

# https://www.labormarketinfo.edd.ca.gov/OccGuides/detail.aspx?Soccode=518031&Geography=0601000000

```

#### Define other ACS codes

This section has functions that develop variables that will serve as controls in regression equations, generally by collapsing detailed ACS variables into more-aggregated categories. For example, it:

-   Race and ethnicity variables are collapsed from 9 race categories by multiple ethnic categories into a single variable with 5 categories
-   Years of schooling is calculated
-   Educational attainment is collapsed into
-   Work experience is calculated as age minus years of schooling minus 6

```{r acs_factors}

#.. COW Character 1 ----
# Class of worker
# b .Not in universe (less than 16 years old/NILF who last worked .more than 5 years ago or never worked)
# 1 .Employee of a private for-profit company or business, or of an .individual, for wages, salary, or commissions
# 2 .Employee of a private not-for-profit, tax-exempt, or .charitable organization
# 3 .Local government employee (city, county, etc.)
# 4 .State government employee
# 5 .Federal government employee
# 6 .Self-employed in own not incorporated business, professional .practice, or farm
# 7 .Self-employed in own incorporated business, professional .practice or farm
# 8 .Working without pay in family business or farm
# 9 .Unemployed and last worked 5 years ago or earlier or never .worked

f_cow <- function(cow){
  levs <- 1:9
  labs <- c("Private, for profit",
            "Private, not for profit",
            "Local government",
            "State government",
            "Federal government",
            "Self-employed, unincorporated",
            "Self-employed, incorporated",
            "Unpaid family or farm",
            "Unemployed 5+ years")
  # cbind(levs, labs)
  factor(cow, levels=levs, labels=labs)
}

#.. MAR Character 1 ----
# Marital status
# 1 .Married
# 2 .Widowed
# 3 .Divorced
# 4 .Separated
# 5 .Never married or under 15 years old

f_marstat <- function(mar){
  factor(mar,
         levels=1:5,
         labels=c("married", "widowed", "divorced", "separated", "neverM"))
}


#.. RAC1P Character 1 ----
# Recoded detailed race code
# 1 .White alone
# 2 .Black or African American alone
# 3 .American Indian alone
# 4 .Alaska Native alone
# 5 .American Indian and Alaska Native tribes specified; or .American Indian or
# Alaska Native, not specified and no other races
# 6 .Asian alone
# 7 .Native Hawaiian and Other Pacific Islander alone
# 8 .Some Other Race alone
# 9 .Two or More Races

f_race_hisp <- function(rac1p, hisp) {
  # hisp==1 is NOT hispanic
  y <- ifelse(hisp==1, rac1p, 0)
  y <- factor(y)
  levels(y) <- list("White alone, not Hispanic"=1, 
                    "Black alone, not Hispanic"=2,
                    "Hispanic, any race"=0,
                    "Asian alone, not Hispanic"=6,
                    "Other or multiple race, not Hispanic"=c(3:5, 7:9))
  return(y)
}

#.. SCHL Character 2 ----
# Educational attainment
# bb .N/A (less than 3 years old)
# 01 .No schooling completed
# 02 .Nursery school, preschool
# 03 .Kindergarten
# 04 .Grade 1
# 05 .Grade 2
# 06 .Grade 3
# 07 .Grade 4
# 08 .Grade 5
# 09 .Grade 6
# 10 .Grade 7
# 11 .Grade 8
# 12 .Grade 9
# 13 .Grade 10
# 14 .Grade 11
# 15 .12th grade - no diploma
# 16 .Regular high school diploma
# 17 .GED or alternative credential

# 18 .Some college, but less than 1 year
# 19 .1 or more years of college credit, no degree

# 20 .Associate's degree
# 21 .Bachelor's degree
# 22 .Master's degree
# 23 .Professional degree beyond a bachelor's degree
# 24 .Doctorate degree

f_yoschool <- function(schl, agep){
  # estimate years of schooling based on educational attainment
  yoschool <- case_when(schl <= 14 ~ 12,  # no higher than 11th grade -- give them 11 years
                      schl %in% 15:17 ~ 12,  # 12th grade, HS diploma or alternative
                      schl %in% 18:19 ~ 13,  # +/- another year
                      schl == 20 ~ 14,  # associate's
                      schl == 21 ~ 16,  # bachelor's
                      schl == 22 ~ 18,  # master's -- 2 years?
                      schl == 23 ~ 19,  # professional degree
                      schl == 24 ~ 20,  # doctorate
                      TRUE ~ NA_real_)
  ifelse(yoschool > agep - 6,
         agep - 6,
         yoschool)
}


f_edattain <- function(schl){
  edattain <- case_when(schl <= 15 ~ "notHSgrad",
                        schl %in% 16:17 ~ "HSgrad",
                        schl %in% 18:19 ~ "HSplus",
                        schl == 20 ~ "associate",
                        schl == 21 ~ "BA",
                        schl %in% 22:24 ~ "MAplus",
                        TRUE ~ "other")
    # put edattain values in desired order
    edattain <- factor(
             edattain,
             levels=c("HSgrad", "HSplus", "associate", "BA", "MAplus", "notHSgrad", "other"))
    # make hsgrad first in sorts??
    edattain
}
# f_edattain(11)



f_create_vars <- function(df){
  # create multiple new variables for df
  # df has acs variables
  df %>%
    mutate(year=str_sub(serialno, 1, 4) %>% as.integer,
           adjinc=adjinc / 1e6,
           rwagp=wagp * adjinc,
           yoschool=f_yoschool(schl, agep),
           ltassoc=schl < 20,
           agep2=agep^2,
           exp=agep - yoschool - 6,
           exp2=exp^2,
           lrwagp=log(rwagp),
           sex=factor(sex, levels=1:2, labels=c("male", "female")),
           rachisp=f_race_hisp(rac1p, hisp),
           edattain=f_edattain(schl),
           marstat=f_marstat(mar))
  }

# tmp <- df1 %>% mutate(create_vars(.))
save(f_cow, f_marstat, f_race_hisp, f_yoschool, f_edattain, f_create_vars,
     file=here::here("data", "acs_functions.rdata"))

```

### Create ACS data subsets to be used in the analysis

```{r connect_acsdb}

load(file=here::here("data", "acs_constants.rdata"), verbose=TRUE)
load(file=here::here("data", "acs_functions.rdata"), verbose=TRUE)

# dbDisconnect(db) # in case it is connected - will throw an error if not, but that's ok
db <- dbConnect(SQLite(), dbname=acsdb)

```

#### Create subset representing all state correctional workers in the U.S.

This subset has approximately 9,800 observations.

We construct real wages for each worker by using the BEA state-level regional price parity index for the state for the relevant year of the person sampled (one of 2015-2019).

```{r acs_corrections_US, eval=FALSE}
# get all state government corrections officers in the US
corr_sqlcmd <- paste0("SELECT ", acsvars_string, " FROM pus WHERE occp=3802") # 10 secs
system.time(corr_base <- collect(tbl(db, sql(corr_sqlcmd))))  # 3 secs
glimpse(corr_base) # 21,989 obs
summary(corr_base)
count(corr_base, st)
count(corr_base, puma, st)
count(corr_base %>% filter(st==06), puma) %>% arrange(-n)
max(corr_base$puma) # 70301

corr_workers <- corr_base %>%
  filter(eval(parse(text=sworker))) %>% 
  filter(cow == 4) %>%  # state government
  mutate(f_create_vars(.)) %>%
  left_join(stcodes %>% 
              select(st=stfips, stabbr) %>% 
              mutate(st=as.integer(st)),
            by="st") %>%
  left_join(sarpp %>%
              select(stabbr, year, rpp),  # merge on the prior year
            by=c("stabbr", "year")) %>%
  mutate(rppwagp=rwagp / rpp,  # rwagp is real wage (adjusted for year), rppwagp is region adjusted
         lrppwagp=log(rppwagp)) %>%  
  group_by(stabbr) %>%
  mutate(n=n()) %>%
  ungroup

summary(corr_workers)

saveRDS(corr_workers, here::here("data", "corr_workers.rds"))

```

#### Create subset representing all sampled workers in California

This subset has approximately 640,000 observations.

We construct real wages for each California worker by using the BEA MSA-level regional price parity index for the worker's California MSA, or for non-metro areas as a whole if the worker is not in an MSA, for the relevant year of the person sampled (one of 2015-2019).

```{r acs_caworkers, eval=FALSE}
sqlcmd <- paste0("SELECT ", acsvars_string, " FROM pus WHERE st=06") # 10 secs

system.time(cadf <- collect(tbl(db, sql(sqlcmd))))  # 4 secs
glimpse(cadf)
summary(cadf)
count(cadf, st) # 1.9m
count(cadf, puma) %>% arrange(-n)

# cadf %>% 
#   mutate(year=str_sub(serialno, 1, 4)) %>% 
#   group_by(year) %>%
#   summarise(minadjinc=min(adjinc), maxadjinc=max(adjinc))
#   year  minadjinc maxadjinc
#   <chr>     <int>     <int>
# 1 2015    1080470   1080470
# 2 2016    1073449   1073449
# 3 2017    1054606   1054606
# 4 2018    1031452   1031452
# 5 2019    1010145   1010145

caworkers <- cadf %>%
  filter(eval(parse(text=sworker))) %>%
  filter(cow %in% 1:5) %>%
  mutate(f_create_vars(.),
         cowf=f_cow(cow)) %>%
  # get state abbreviation
  left_join(stcodes %>% 
              select(st=stfips, stabbr) %>% 
              mutate(st=as.integer(st)),
            by="st") %>%
  left_join(acsocodes, by="occp") %>%
  # get msa (fips) code and msaname that the puma is (mostly) within
  left_join(pumas_caxwalk %>% 
              select(puma, pumaname, msacode, msaname),
            by = "puma") %>%
  # get regional price parity index
  left_join(carpp %>% 
              filter(type=="metro") %>%
              select(msacode=fips, year, rpp),
            by=c("msacode", "year")) %>%
  mutate(msacode=ifelse(is.na(msacode), -9999, msacode),
         msaname=ifelse(is.na(msaname), "nonmetro", msaname),
         type=ifelse(msacode==-9999, "nonmetro", "metro")) %>%
  # merge again to get regional price parity for the nonmetro areas
  left_join(carpp %>% 
              filter(type=="nonmetro") %>%
              select(type, year, rpp_nonmetro=rpp),
            by=c("type", "year")) %>%
  mutate(rpp=ifelse(type=="nonmetro", rpp_nonmetro, rpp),
         rppwagp=rwagp / rpp,  # rwagp is real wage (adjusted for year), rppwagp is region adjusted
         lrppwagp=log(rppwagp)) %>%
  select(-rpp_nonmetro)
summary(caworkers)

count(caworkers, occp, occname) %>% arrange(-n)
count(caworkers, occp, soc, occname) %>% filter(str_sub(soc, 1, 3)=="33-")

saveRDS(caworkers, here::here("data", "caworkers.rds"))

```

#### Create ACS summary of educational attainment of california workers by occupation and sector

```{r job_educ, eval=FALSE}
cajobeduc <- caworkers %>%
  group_by(soc, occp, occname, cow, cowf, edattain) %>%
  summarise(n=n(),
            wtdn=sum(pwgtp),
            yoschool=median(yoschool, na.rm=TRUE),
            ltassoc=sum(ltassoc * pwgtp),
            rwagp=sum(rwagp * pwgtp),
            rppwagp=sum(rppwagp * pwgtp),
            .groups="drop") %>%
  group_by(soc, occp, occname, cow, cowf) %>%
  summarise(n=sum(n),
            ltassoc=sum(ltassoc),
            assoc=sum(wtdn[edattain %in% c("associate")]),
            ba=sum(wtdn[edattain %in% c("BA")]),
            maplus=sum(wtdn[edattain %in% c("MA+")]),
            rwagp=sum(rwagp),
            rppwagp=sum(rppwagp),
            # MUST put wtdn last so it is not revised before being used
            wtdn=sum(wtdn),
            .groups="drop") %>%
  mutate(across(c(ltassoc, assoc, ba, maplus, rwagp, rppwagp), ~ .x / wtdn)) %>%
  select(soc, occname, occp, cow, cowf, n, wtdn, everything())
summary(cajobeduc)

saveRDS(cajobeduc, here::here("data", "cajobeduc.rds"))

```

# Retrieve data

Get previously created data, needed in the following sections.

```{r load_data}
# load previously prepared data
# functions
load(file=here::here("data", "misc_functions.rdata"), verbose=TRUE)
load(file=here::here("data", "acs_functions.rdata"), verbose=TRUE)

# codes -- do I need to load the codes?
load(file=here::here("data", "acs_constants.rdata"), verbose=TRUE)
load(file=here::here("data", "rpp.rdata"), verbose=TRUE) # max year is 2019 for all
acsocodes <- readRDS(here::here("data", "acsocodes.rds"))
pumas_caxwalk <- readRDS(here::here("data", "pumas_caxwalk.rds"))

#.. the main data files ----
# job categories
job_cluster <- readRDS(here::here("data", "job_cluster.rds"))
wpirates <- readRDS(here::here("data", "wpirates.rds"))

# OESW
# All states, govt
oesres_clean <- readRDS(paste0(resdir, "oesres_clean.rds"))
oesres_sec99 <- readRDS(paste0(resdir, "oesres_sec99.rds"))

# California files
caledd_oesw <- readRDS(here::here("data", "caledd_oesw.rds"))
load(file=here::here("data", "caloes.rdata"), verbose=TRUE)

# ACS-based files
corr_workers <- readRDS(here::here("data", "corr_workers.rds"))
caworkers <- readRDS(here::here("data", "caworkers.rds"))
cajobeduc <- readRDS(here::here("data", "cajobeduc.rds"))


keyfacts <- list()


```

# Wages of correctional officers

## Cross-state comparisons of correctional officers' wages

### Descriptive analysis

We'd expect wages to be higher when education or experience is greater. Looking at these two workforce characteristics in isolation can give us a sense of whether they will make a lot of difference when we run models that control for education and experience.

```{r states_dataprep}
# data prep
# OES -- construct a U.S. record
corr_oessts <- oesres_sec99 %>%
  filter(str_detect(naics_title, "State Government"), occ=="33-3012", stabbr %in% state.abb) %>%
  select(stabbr, year, occ, occname, wage=a_mean, emp=tot_emp) %>%
  mutate(caldum=stabbr=="CA")

corr_oesus50 <- corr_oessts %>%
  group_by(year, occ, occname) %>%
  summarise(stabbr="US",
            caldum=FALSE,
            wage=wtd.mean(wage, weights = emp, na.rm=TRUE),
            emp=sum(emp, na.rm=TRUE), .groups = "drop")

corr_oes <- bind_rows(corr_oessts, corr_oesus50) %>%
  left_join(sarpp %>% select(stabbr, year=yearplus1, rpp),
            by=c("stabbr", "year")) %>%
  mutate(rwage = wage / rpp)
summary(corr_oes)
# corr_oes %>% filter(is.na(rwage))  # RI in 2017
keyfacts$corr_oes <- corr_oes

# keyfacts$caavgwage <- corr_oes %>% filter(stabbr=="CA", year==2020) %>% .$wage
# keyfacts$maavgwage <- corr_oes %>% filter(stabbr=="MA", year==2020) %>% .$wage


# ACS
# obs_cutoff number of observations needed in a state or other category
glimpse(corr_workers)
corr_workers_cut <- corr_workers %>%
  mutate(stabbr2=ifelse(n >= obs_cutoff, stabbr, "other")) 
glimpse(corr_workers_cut)
count(corr_workers_cut, edattain)
count(corr_workers_cut, stabbr2) # 39 states

# sanity check on the rpps -- they will vary within state, by year
corr_workers_cut %>%
  group_by(stabbr2) %>%
  summarise(rppmin=min(rpp),
            rppmean=mean(rpp),
            rppmax=max(rpp))


corr_wages <- corr_workers_cut %>%
  group_by(stabbr2) %>%
  summarise(n=n(),
            wtdn=sum(pwgtp),
            rwagp=wtd.mean(rwagp, weights=pwgtp),
            rppwagp=wtd.mean(rppwagp, weights=pwgtp),
            exp=wtd.mean(exp, weights=pwgtp))

corr_ltassoc <- corr_workers_cut %>%
  group_by(stabbr2) %>%
  summarise(ltassoc=wtd.mean(ltassoc, weights = pwgtp), .groups="drop")

corr_ed <- corr_workers_cut %>%
  group_by(stabbr2, edattain) %>%
  summarise(wtdn=sum(pwgtp), .groups="drop") %>%
  group_by(stabbr2) %>%
  mutate(share=wtdn / sum(wtdn)) %>%
  select(stabbr2, edattain, share) %>%
  pivot_wider(names_from = edattain, values_from = share, values_fill = 0) %>%
  # mutate(ltassoc_check=notHSgrad + HSgrad + HSplus) %>%
  left_join(corr_ltassoc, by="stabbr2")

corr_sex <- corr_workers_cut %>%
  group_by(stabbr2, sex) %>%
  summarise(wtdn=sum(pwgtp), .groups="drop") %>%
  group_by(stabbr2) %>%
  mutate(share=wtdn / sum(wtdn)) %>%
  select(stabbr2, sex, share) %>%
  pivot_wider(names_from = sex, values_from = share, values_fill = 0)

corr_summary <- corr_wages %>%
  left_join(corr_ed, by="stabbr2") %>%
  left_join(corr_sex %>% select(stabbr2, male), by="stabbr2") %>%
  mutate(stname=get_stname(stabbr2),
         dumca=stabbr2=="CA") %>%
  select(stabbr2, stname, dumca, n, wtdn, exp, rwagp, rppwagp, male, ltassoc) %>%
  arrange(stname)

keyfacts$corr_summary <- corr_summary

```

#### Miscellaneous

```{r include=FALSE}
# Number of correction officers per capita and average wage, not interesting
pdata <- corr_oes %>%
  filter(year==2020) %>%
  left_join(spop.a %>%
              filter(year==2020) %>%
              select(stabbr, pop=value),
            by=c("stabbr")) %>%
  mutate(epop100k=emp / (pop / 100e3))

pdata %>%
  ggplot(aes(epop100k, wage, label=stabbr)) +
  geom_point() +
  geom_text()

```

#### Wages

Here we look at raw wages, without controlling for differences across workers such as educational attainment, as this is the starting point and is what other people will look at.

In addition, this is a sanity check on two different data sources:

-   Occupational Employment and Wage Statistics (OEWS or OES), research database: This is the gold standard for cross-state comparison in the number of workers or their average wages. But it is only one number per occupation per state per year (e.g., correctional officers in California in 2020 were paid \$88,710 on average). We don't have data for the individual workers used to derive state totals so we can't see how it varies within and across states with education, experience, etc. (Later, we will examine a version of the OES that has data for each MSA in California.) We look at this with, and without, adjusting for price differences across states.

-   American Community Survey (ACS): This is a public-use survey that has details on (anonymized) individuals - their age, educational attainment, gender, race, ethnicity, marital status, state of residence, and other information. The survey has 15 million observations nationally (including children and retired people), 840 of which are for correctional officers in California. The richness of this data allows us to control for differences in education, experience, and other characteristics (and later, it allows us to compare correctional officers to the private sector).

We don't expect summaries of the ACS to be as high-quality a measure of overall average wages as what we see in the OES, but we'd like the two data sources to tell the same basic story. The graphs below suggest that they do.

We show average wages at 2020 levels from these two sources in the two figures below.

##### Key data: Wages based on the OES

```{r include=TRUE, fig.width=6, fig.height=8}

gtitle <- "State correctional officer salaries"
gsubtitle <- NULL
capt1 <- "\nSource: Author's analysis of U.S. Bureau of Labor Statistics, Occupational and Employment Statistics Research Data."
capt <- capt1
pdata <- corr_oes %>%
  filter(year==2020, stabbr != "US") %>%
  mutate(stname=get_stname(stabbr))


p <- pdata %>%
  ggplot(aes(y=reorder(stname, wage), x=wage)) +
  geom_point(aes(colour=caldum), size=1.5) +
  scale_colour_manual(values=c("blue", "red")) +
  theme_bw() +
  labs(x="Annual wage, no adjustment for cross-state price differences", y=NULL,
       caption=capt) +
  ggtitle(label=gtitle, subtitle = gsubtitle) +
  theme(axis.text.y = element_text(hjust = 0)) +
  geom_vline(xintercept = median(pdata$wage)) +
  scale_x_continuous(breaks=seq(0, 100e3, 10e3), labels=label_comma(), limits=c(30e3, 90e3)) +
  legend_none +
  caption_left

p

ggsave(here::here("results", "wages_oes.png"), 
       plot=p, width=10, height=8, scale=1.25)
write_csv(pdata, here::here("results", "wages_oes_data.csv"))
# keyfacts$wages_oes_data <- pdata



```

Now we look at the same data (OES), adjusted for price differences across states. Not surprisingly California wages are not as far above other states after adjusting for price differences, because California is expensive, but the differences are still large.

```{r include=TRUE, fig.width=6, fig.height=8}

gtitle <- "State correctional officer salaries"
gsubtitle <- "Adjusted for differences in state cost of living"
capt1 <- "\nSource: Author's analysis of U.S. Bureau of Labor Statistics, Occupational and Employment Statistics Research Data."
capt <- capt1
pdata <- corr_oes %>%
  filter(year==2020, stabbr != "US") %>%
  left_join(sarpp %>% filter(year==2019) %>% select(stabbr, rpp),
            by="stabbr") %>%
  mutate(stname=get_stname(stabbr),
         rwage=wage / rpp)

p <- pdata %>%
  ggplot(aes(y=reorder(stname, rwage), x=rwage)) +
  geom_point(aes(colour=caldum), size=1.5) +
  scale_colour_manual(values=c("blue", "red")) +
  theme_bw() +
  labs(x="Annual wage, adjusted for cross-state price differences", y=NULL,
       caption=capt) +
  ggtitle(label=gtitle, subtitle = gsubtitle) +
  theme(axis.text.y = element_text(hjust = 0)) +
  geom_vline(xintercept = median(pdata$rwage)) +
  scale_x_continuous(breaks=seq(0, 100e3, 10e3), labels=label_comma()) +
  legend_none +
  caption_left

p

ggsave(here::here("results", "real_wages_oes.png"), 
       plot=p, width=10, height=8, scale=1.25)
keyfacts$real_wages_oes <- pdata


```

##### Wages based on the ACS

The similarity between the ACS plot here and the OES plot above give us confidence when using the ACS to control for differences across individuals.

```{r include=TRUE, fig.width=6, fig.height=8}

gtitle <- "State correctional officer salaries"
gsubtitle <- NULL
capt1 <- "\nSource: Author's analysis of U.S. Bureau of the Census, American Community Survey."
capt <- capt1
pdata <- corr_wages %>%
  mutate(stname=get_stname(stabbr2),
         stname=ifelse(stabbr2=="other", "Smaller states as a group", stname),
         caldum=stabbr2=="CA")

p <- pdata %>%
  ggplot(aes(y=reorder(stname, rwagp), x=rwagp)) +
  geom_point(aes(colour=caldum), size=1.5) +
  scale_colour_manual(values=c("blue", "red")) +
  theme_bw() +
  labs(x="Annual wage, no adjustments", y=NULL,
       caption=capt) +
  ggtitle(label=gtitle, subtitle = gsubtitle) +
  theme(axis.text.y = element_text(hjust = 0)) +
  geom_vline(xintercept = median(pdata$rwagp)) +
  scale_x_continuous(breaks=seq(0, 100e3, 10e3), labels=label_comma(), limits=c(30e3, 90e3)) +
  legend_none +
  caption_left

p

ggsave(here::here("results", "wages_acs.png"), 
       plot=p, width=10, height=8, scale=1.25)


```

##### Wages in California relative to other states, over time, based on the OES

```{r include=TRUE}
# count(corr_oes, stabbr)
pdata <- corr_oes %>%
  filter(stabbr %in% c("US", "CA", compstates)) %>%
  group_by(year) %>%
  mutate(pdwage=wage / wage[stabbr=="US"] * 1 - 1,
         stname=get_stname(stabbr)) %>%
  ungroup %>%
  filter(stabbr != "US")

keyfacts$wages_oes_time <- pdata

cols <- c('#a6cee3','#1f78b4','black','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6')

capt1 <- "\nSource: U.S. Bureau of Labor Statistics, Occupational Employment and Wage Statistics Research Database"
capt2 <- "Note: Not adjusted for price differences across states."
capt <- paste0(capt1, "\n", capt2)

p <- pdata %>%
  ggplot(aes(year, pdwage, colour=stabbr)) +
  geom_line(size=1.0) +
  geom_point() +
  geom_hline(yintercept = 0) +
  scale_colour_manual(values=cols) +
  # scale_size_manual(values=c(1, rep(.5, 8))) +
  labs(y="% above or below U.S. average", x=NULL,
       caption=capt) +
  scale_y_continuous(breaks=seq(-1, 1, .05), labels = label_percent(accuracy=1)) +
  ggtitle("State correctional officers' salaries relative to U.S. average",
          subtitle="California, neighbors, and selected other states") +
  theme_bw() +
  legend_notitle +
  caption_left
p


```

#### Education

Wages might be expected to be higher in states where correctional officers have greater education.

California correctional officers have about the same educational attainment as those in the median state.

```{r include=TRUE, fig.width=5, fig.height=4}
p <- corr_summary %>%
  ggplot(aes(1 - ltassoc, rppwagp, label=stabbr2, colour=dumca)) +
  geom_point(size=0.275, colour="black") +
  # geom_text(size=2.5, position = position_jitter()) +
  geom_text(size=2.5, nudge_x=-0.0075) +
  geom_vline(xintercept = median(1 - corr_summary$ltassoc), size=0.1, colour="black") +
  scale_colour_manual(values=c("blue", "red")) +
  scale_x_continuous(name="% of corrections officers with associate's degree or higher",
                     labels = label_comma(scale=100, accuracy=1, suffix="%"),
                     breaks=seq(.1, 1, .05)) +
  scale_y_continuous(name="Annual wage, adjusted for state price differences",
                     labels = label_comma(accuracy=1, prefix="$")) +
  theme_bw() +
  legend_none +
  ggtitle("Wages and education of corrections officers by state",
          subtitle="Wages adjusted for price differences across states.") +
  labs(caption="\nNote: vertical line marks median") +
  caption_left
p

```

#### Experience

Wages might be expected to be higher in states where correctional officers have greater experience.

California correctional officers have about 2 more years of experience, on average, than those in the median state.

```{r include=TRUE, fig.width=5, fig.height=4}
p <- corr_summary %>%
  ggplot(aes(exp, rppwagp, label=stabbr2, colour=dumca)) +
  geom_point(size=0.275, colour="black") +
  # geom_text(size=2.5, position = position_jitter()) +
  geom_text(size=2.5, nudge_x=-0.1) +
  geom_vline(xintercept = median(corr_summary$exp), size=0.1, colour="black") +
  scale_colour_manual(values=c("blue", "red")) +
  scale_x_continuous(name="Average years of experience of corrections officers (estimated)",
                     labels = label_comma(accuracy=1),
                     breaks=seq(0, 50, 1)) +
  scale_y_continuous(name="Annual wage, adjusted for state price differences",
                     labels = label_comma(accuracy=1, prefix="$")) +
  theme_bw() +
  legend_none +
  ggtitle("Wages and experience of corrections officers by state",
          subtitle="Wages adjusted for price differences across states.") +
  labs(caption="\nNote: vertical line marks median") +
  caption_left
p


```

### Econometric models of correctional officers' wages vs. other states

In this model, we regress real wages (adjusted for price differences across states) of state correctional officers in the 50 states, in log form, on:

-   Experience (and experience squared - the usual econometric approach)
-   Educational attainment
-   Controls for marital status, sex, race/ethnicity, and which year the person was in the sample (2015-2019)

We also include state fixed effects - essentially a dummy variable for each state.

The state fixed effects are the main result we are interested in. They tell how much a state's correctional officer wages are above or below the U.S. average, in percentage terms (approximately), after controlling for the items above.

```{r acs_corr_models}
# https://cran.r-project.org/web/packages/fixest/fixest.pdf
# https://cran.r-project.org/web/packages/fixest/vignettes/fixest_walkthrough.html

# count(corr_workers, edattain)
# count(corr_workers %>% filter(stabbr=="CA"), edattain)
# count(corr_workers, stabbr2, stabbr)
femod <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) | stabbr2,
               data=corr_workers_cut, notes=FALSE)
# suppress note about dropping edattainother
keyfacts$statemod <- femod


```

#### Checks on results

We begin with a summary of model results. This is a check on things, before we get to the fixed effects.

Easiest just to talk about what it means, if you are interested.

```{r include=TRUE, rows.print=25}
summary(femod)

```

<br> <br> <br>

Now comes another reasonableness check. We graph the coefficients on `exp` and `exp2` to make sure it shows that wages rise as workers have more experience (all else equal); usually they will fall at some point, and so we expect it to look like an inverted U but with the peak occuring late in career (we don't see a full U).

```{r include=TRUE}
# check the wage-experience profile for reasonableness
p <- tibble(exp=0:40, exp2=exp^2, e1=exp * coef(femod)["exp"], e2=exp2 * coef(femod)["exp2"]) %>%
  mutate(earn=e1 + e2) %>%
  ggplot(aes(exp, earn)) +
  geom_line() +
  labs(x="Experience (years)", y="Log earnings") +
  scale_x_continuous(breaks=seq(0, 100, 5)) +
  ggtitle("Estimated U.S. average earnings-experience profile for correctional officers") +
  theme_bw()
p

```

#### Key result: differences across states (state fixed effects)

```{r acs_corr_model_results, include=TRUE, fig.width=6, fig.height=8}
# , fig.height=8, fig.width=10
fe <- fixef(femod)
# summary(fe)

cfe <- tibble(stabbr=names(fe$stabbr2), fe=fe$stabbr2) %>%
  mutate(cfe=fe - mean(fe),
         stname=get_stname(stabbr),
         stname=ifelse(stabbr=="other", "Small states as a group", stname),
         rank=rank(desc(cfe)))
keyfacts$statecfe <- cfe

gtitle <- "State correctional officer salaries relative to those in the average state"
gsubtitle <- "Adjusted for state price levels, and controlling for experience, education, and demographic characteristics"
capt1 <- "Source: Author's analysis of U.S. Bureau of the Census, American Community Survey, 2015-2019 PUMS."
capt2 <- "Price adjustments using U.S. Bureau of Economic Analysis Regional Price Parities."
capt3 <- "Note: States with fewer than 50 observations were grouped together."
capt <- paste0(capt1, "\n", capt2, "\n", capt3)
statefe_dots <- cfe %>%
  # filter(stabbr != "Other") %>%
  mutate(grp=ifelse(stabbr=="CA", "CA", "other")) %>%
  ggplot(aes(y=reorder(stname, cfe), x=cfe * 100)) +
  geom_point(aes(colour=grp), size=1.5) +
  scale_colour_manual(values=c("red", "blue")) +
  theme_bw() +
  labs(x="% above or below average state", y=NULL,
       caption=capt) +
  ggtitle(label=gtitle, subtitle = gsubtitle) +
  theme(axis.text.y = element_text(hjust = 0)) +
  geom_vline(xintercept = 0) +
  scale_x_continuous(breaks=seq(-100, 100, 5)) +
  legend_none +
  caption_left

statefe_dots

ggsave(here::here("results", "statefe_dots.png"), 
       plot=statefe_dots, width=10, height=8, scale=1.25)
  
```

## Within-California comparisons: Federal, state, and local government correctional officers

```{r}
#.. ACS subset for regression ----
cacorr_df <- caworkers %>%
  filter(soc=="33-3012", cow %in% 3:5) %>%
  mutate(cowf=factor(cow, levels=c(4, 3, 5), labels=c("state", "local", "federal"))) %>%
  arrange(cowf)

```

### Descriptive analysis

#### Wages over time (OES)

```{r corrca_fsl, include=TRUE}

pdata <- oesres_clean %>%
  filter(occ=="33-3012", stabbr=="CA", level %in% c("federal", "state", "local")) %>%
  mutate(level=str_to_sentence(level),
         level=factor(level, levels=c("Federal", "State", "Local"))) %>%
  arrange(year, level)

capt <- paste0("\nSource: ", source_oesres)
colors <- c('#e41a1c','#377eb8','#4daf4a')
p <- pdata %>%
  ggplot(aes(year, amean, colour=level)) +
  geom_line(size=1.0) +
  geom_point() +
  scale_colour_manual(values=colors) +  # c("green", "blue", "black")
  labs(y="Average annual wage", x=NULL,
       caption=capt) +
  scale_y_continuous(breaks=seq(0, 100e3, 10e3),
                     labels = label_comma(accuracy=1),
                     limits=c(0, NA)) +
  ggtitle("Correctional officers' salaries in California by level of government") +
  theme_bw() +
  legend_notitle +
  caption_left
p

ggsave(here::here("results", "wages_corrca_fsl.png"), plot = p,
       width=10, height=8, scale=1)

# df1 %>%
#   group_by(year) %>%
#   mutate(pdamean=amean[level=="state"] / amean - 1) %>%
#   filter(level != "state") %>%
#   ggplot(aes(year, pdamean, colour=level)) +
#   geom_line() +
#   geom_point()

```

### Education, experience, wages, and within-California cost-of-living adjustment (ACS)

```{r include=TRUE}
# descriptive statistics
sumstats <- cacorr_df %>%
  group_by(cowf) %>%
  summarise(n=n(), wtdn=sum(pwgtp), 
            rwagp=wtd.mean(rwagp, weights = pwgtp),
            rppwagp=wtd.mean(rppwagp, weights = pwgtp),
            yoschool=wtd.mean(yoschool, weights = pwgtp),
            exp=wtd.mean(exp, weights = pwgtp)) %>%
  mutate(irwagp=rwagp[cowf=="state"] / rwagp - 1,
         irppwagp=rppwagp[cowf=="state"] / rppwagp - 1)

tabdata <- sumstats %>%
  select(cowf, yoschool, exp, rwagp, irwagp, irppwagp) %>%
  mutate(cowf=str_to_sentence(cowf))

tabdata %>% 
  gt() %>%
  tab_header(
    title = "Summary statistics for correctional officers in California",
    subtitle = "By level of government"
      ) %>%
  cols_label(cowf="Level of government",
             yoschool="Education",
             exp="Experience",
             rwagp="Average wage",
             irwagp="Unadjusted",
             irppwagp="Price-adjusted") %>%
  tab_spanner(
    label = "Average years of:",
    columns = c(yoschool, exp)
    ) %>%
  tab_spanner(
    label = md("State wage relative to other wages<br>Unadjusted, and adjusted for cost of living"),
    columns = c(irwagp, irppwagp)
    ) %>%
  fmt_number(
    columns=c(yoschool, exp),
    decimals=1
  ) %>%
  fmt_number(
    columns=c(rwagp),
    decimals=0
  ) %>%
  fmt_percent(
    columns = c(irwagp, irppwagp),
    decimals = 1) %>%
  tab_source_note("Sources: Bureau of the Census, American Community Survey 2015-2019; and Bureau of Economic Analysis, Regional Price Parities.")


```

### Econometric models

```{r}
caworkers
summary(caworkers)
count(caworkers, cow)


count(df, cow, cowf)
# count(df, soc, occname)

df %>%
  group_by(cowf) %>%
  summarise(n=n(), wtdn=sum(pwgtp), 
            rwagp=wtd.mean(rwagp, weights = pwgtp),
            rppwagp=wtd.mean(rppwagp, weights = pwgtp),
            yoschool=wtd.mean(yoschool, weights = pwgtp),
            exp=wtd.mean(exp, weights = pwgtp)) %>%
  mutate(irwagp=rwagp[cowf=="state"] / rwagp - 1,
         irppwagp=rppwagp[cowf=="state"] / rppwagp - 1)


mod1 <- feols(lrppwagp ~ cowf + exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year),
               data=df)
summary(mod1)

```

## Within-California comparisons: Law enforcement occupations (regardless of whether public or private)

```{r}
caworkers

job_cluster


camod1 <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + cowf,
               data=df)

```

## Comparisons of California state correctional officers' wages to those of other California workers

We want to compare wages of California correctional officers to wages of other workers in California, particularly in the private sector, but how can we do this given that correctional workers:

-   Are mostly (but not always) employed by the government
-   Work in a potentially dangerous and stressful work environment
-   Have firearms training (although they generally do not carry guns on the job)

### Descriptive analysis of state correctional officers' wages vs. other the private sector in California

#### Where California corrections officers live, vs. other California workers

```{r}
# quick look at workers by msa
count(caworkers, occp, occname)
places <- caworkers %>%
  mutate(co=ifelse(occp==3802, "co", "other")) %>%
  group_by(co, msacode, msaname, rpp) %>%
  summarise(wtdn=sum(pwgtp), .groups="drop") %>%
  group_by(co) %>%
  mutate(pct=wtdn / sum(wtdn)) %>%
  select(-wtdn) %>%
  ungroup %>%
  pivot_wider(names_from = co, values_from = pct) %>%
  mutate(diff=co - other) %>%
  arrange(-abs(diff))
places
  # arrange(-other)
# need to collapse by county! Or MSA?

place_plot <- places %>%
  ggplot(aes(rpp, diff, label=msaname)) +
  geom_point(colour="blue", size=1) +
  geom_text(colour="blue", size=2) +
  geom_vline(xintercept = 1) +
  geom_hline(yintercept = 0) +
  labs(x="Relative cost of area", y="Relative number of correctional officers") +
  theme_bw() +
  ggtitle("Correctional officers tend to live in less-expensive areas than California workers overall")
place_plot  

```

```{r place_table, include=TRUE}
tabdata <- places %>%
  mutate(msaname=ifelse(msacode==-9999, " -- Non-metro areas", str_replace(msaname, ", CA", "")),
         rpp=ifelse(msacode==-9999, 99.8/100, rpp),  # the CA non metro value in 2017
         rpppct=rpp - 1) %>%
  select(msacode, msaname, rpppct, co, other) %>%
  arrange(rpppct) %>%
  mutate(cotot=cumsum(co), othertot=cumsum(other))
oddrows <- seq(1, nrow(tabdata), 2)

lowrows <- tabdata %>% 
  mutate(rownum=row_number()) %>%
  filter(rpppct < 0)

tab <- tabdata %>%
  gt() %>%
  cols_hide(
    columns = c(msacode)
  ) %>%
  tab_header(
    title = "Cost of Living Where Correctional Officers Live, Relative to Other California Workers",
    subtitle = "Arranged from lowest-cost to highest-cost area"
      ) %>%
  cols_label(msaname="Area of residence",
             rpppct=md("Price level<br>% above/below<br>national average"),
             co=md("Correctional<br>officers"),
             other=md("All other<br>California workers"),
             cotot=md("Correctional<br>officers"),
             othertot=md("All other<br>California workers")) %>%
  tab_spanner(
    label = "% of workers who live in this area",
    columns = c(co, other)
    ) %>%
  tab_spanner(
    label = "Cumulative % of workers",
    columns = c(cotot, othertot)
    ) %>%
  fmt_percent(
    columns = c(rpppct, co, other, cotot, othertot),
    decimals = 1) %>%
  # fmt_percent(
  #   columns = c(rpppct),
  #   decimals = 4) %>%
  tab_style(
    style = list(
      cell_fill(color = "grey95")
      ),
    locations = cells_body(
      rows=oddrows
      )
    ) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightcyan"),
      cell_text(weight = "bold")
      ),
    locations = cells_body(
      columns = c(cotot, othertot),
      rows = msaname=="Chico"  # (rpppct > -.001) & (rpppct < .001)
      )
  ) %>%
  tab_footnote(
    footnote = "Area with prices closest to national average.",
    locations = cells_body(
      columns = c(msaname),
      rows = msaname=="Chico"  # (rpppct > -.001) & (rpppct < .001)
      )
    ) %>%
  tab_source_note("Sources: Bureau of the Census, American Community Survey 2015-2019; and Bureau of Economic Analysis, Regional Price Parities.")
tab
gtsave(tab, filename="residence_and_prices.html", path=here::here("results"))

```

### Education

```{r rows.print=25}
# what are HS jobs?

summary(cajobeduc)
tmp <- cajobeduc %>% filter(str_sub(soc, 1, 3)=="33-")
# hsjobs <- jobeduc %>%
#   filter(ltassocpct >= .55)

caworkers2 <- caworkers %>%
  left_join(cajobeduc %>%
              select(occp, cow, ltassoc, assoc, ba, maplus),
            by=c("occp", "cow"))

tmp <- caworkers2 %>%
  filter(ltassoc >= .7, ltassoc <= .8)

tmp2 <- tmp %>%
  filter(!str_detect(occname, coll("supervisor", ignore_case = FALSE))) %>%
  group_by(soc, occp, occname, cow, cowf) %>%
  summarise(n=n(), wtdn=sum(pwgtp), 
            across(c(ltassoc, assoc, ba, maplus), ~ first(.x)), 
            rppwagp=wtd.mean(rppwagp, weights = pwgtp)) %>%
  # filter(n >= 50) %>%
  arrange(-rppwagp)
         
```

### Econometric models of correctional officers' wages vs. comparison groups in California

```{r}
# bring in occupation injury rate
glimpse(caworkers)
count(caworkers, cow, cowf)
# 1	Private, for profit	532326		
# 2	Private, not for profit	58365		
# 3	Local government	68291		
# 4	State government	35840		
# 5	Federal government	23766	
# ownership_code	ownership_name
# 0	All ownerships
# 1	Private industry
# 7	State government
# 8	Local government
wpirates2 <- wpirates %>%
  mutate(own=as.integer(own),
         ownf=factor(own,
                     levels=c(0, 1, 7, 8, 9),
                     labels=c("All", "Private", "State government", "Local government", "SLG combined")),
         cow=case_when(own==1 ~ 1L,
                       own==7 ~ 4L,
                       own==8 ~ 3L, 
                       TRUE ~ NA_integer_),
         soc=paste0(str_sub(ocode, 1, 2),
                                "-",
                                str_sub(ocode, 3, 6))) %>%
  filter(!is.na(cow))


# 9	State and local government combined

tmp <- wpirates %>%
              filter(stabbr=="US") %>%
              mutate(soc=paste0(str_sub(ocode, 1, 2),
                                "-",
                                str_sub(ocode, 3, 6))) %>%
              select(year, stabbr, soc, wpirate=value)


caworkers_wfi <- caworkers %>%
  left_join(wpirates %>%
              filter(stabbr=="US") %>%
              mutate(soc=paste0(str_sub(ocode, 1, 2),
                                "-",
                                str_sub(ocode, 3, 6))) %>%
              select(year, soc, wpirate=value),
            by = c("year", "soc")) %>%
  mutate(caco=ifelse(cow==4 & soc=="33-3012", TRUE, FALSE))

summary(caworkers_wfi)
caworkers_wfi %>%
  filter(is.na(wpirate)) %>%
  filter(str_sub(soc, 1, 2)=="33") %>%
  count(soc, occname) %>%
  arrange(desc(n))

```

#### Models comparing state correctional officers to other correctional officers

```{r include=FALSE, rows.print=25}
df <- caworkers_wfi %>%
  filter(soc=="33-3012")

camod1 <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + cowf,
               data=df)

camod1 <- feols(lrppwagp ~ wpirate + exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + cowf,
               data=df %>% filter(!is.na(wpirate)))

camod1 <- feols(lrppwagp ~ wpirate + exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + caco,
               data=df %>% filter(!is.na(wpirate)))

camod1 <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + caco,
               data=df)

camod1 <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + caco,
               data=df)

camod1 <- feols(lrwagp ~ exp + exp2 + edattain + sex + caco,
               data=df)

summary(camod1)

cafe1 <- fixef(camod1)
# summary(fe)

cfe <- tibble(stabbr=names(fe$stabbr2), fe=fe$stabbr2) %>%
  mutate(cfe=fe - mean(fe),
         stname=get_stname(stabbr),
         stname=ifelse(stabbr=="other", "-- other states as a group", stname))

```

#### Models comparing correctional officers to jobs in the same occupational cluster

```{r include=FALSE, rows.print=25}

df <- caworkers_wfi %>%
  filter(soc %in% job_cluster$occ)

camod1 <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + cowf,
               data=df)

camod1 <- feols(lrppwagp ~ wpirate + exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + cowf,
               data=df %>% filter(!is.na(wpirate)))

camod1 <- feols(lrppwagp ~ wpirate + exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + caco,
               data=df %>% filter(!is.na(wpirate)))

camod1 <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + caco,
               data=df)

camod1 <- feols(lrppwagp ~ exp + exp2 + edattain + marstat + sex + rachisp + as.factor(year) + caco,
               data=df)

camod1 <- feols(lrwagp ~ exp + exp2 + edattain + sex + caco,
               data=df)

summary(camod1)

cafe1 <- fixef(camod1)
# summary(fe)

cfe <- tibble(stabbr=names(fe$stabbr2), fe=fe$stabbr2) %>%
  mutate(cfe=fe - mean(fe),
         stname=get_stname(stabbr),
         stname=ifelse(stabbr=="other", "-- other states as a group", stname))


#### Models comparing correctional officers to jobs where workers have similar education
```

```{r acs_ca_model, rows.print=25}
glimpse(caworkers)

coed <- cajobeduc %>% 
  filter(soc=="33-3012", cow==4)
coltassoc <- coed$ltassoc

diff <- .05
hsj <- cajobeduc %>%
  # filter(ltassoc >= .6, ltassoc <= .7, wtdn >= 5000)
  filter(ltassoc >= (coltassoc - diff), ltassoc <= (coltassoc + diff), wtdn >= 1000)

# mod1 <- feols(lwage ~ edattain + sex + exp + exp2 + marstat | soc, data=caworkers)
# summary(mod1)
df <- caworkers_wfi %>%
  filter(soc %in% hsj$soc)

# regdf <- caworkers %>% 
#   filter(soc %in% hsj$soc)
# count(regdf, edattain)
# count(regdf, sex)
# count(regdf, marstat)

# mod2 <- feols(lrwagp ~ edattain + exp + exp2 + sex + marstat + rachisp | soc, data=regdf)
# mod2 <- feols(lrppwagp ~ edattain + exp + exp2 + sex + marstat + rachisp + year | soc, data=df)
mod2 <- feols(lrppwagp ~ wpirate + edattain + exp + exp2 + sex + marstat + rachisp + as.factor(year) + caco , data=df)

mod2 <- feols(lrppwagp ~ wpirate + edattain + exp + exp2 + sex + marstat + rachisp +
                as.factor(year) + caco | as.factor(msacode), data=df)

# mod2 <- feols(lwage ~ edattain + exp + exp2 + female + married - 1 | soc, data=regdf)
summary(mod2)  # default clusters on soc
# summary(mod2, cluster= ~ soc)

# tmp <- feols(lwage ~ edattain + sex + exp + exp2 + marstat -1 | soc, data=regdf, demeaned = TRUE)
# fixef(tmp)

# fe <- fixef(mod1)
fe <- fixef(mod2)
fe
# summary(fe)
# fe$soc["33-3012"]
# p <- plot(fe)
# p
# str(p)

cfe <- tibble(soc=names(fe$soc), fe=fe$soc) %>%
  left_join(ocodes, by="soc") %>%
  mutate(cfe=fe - mean(fe)) %>% # centered fixed effects
  arrange(-cfe) %>%
  mutate(rank=row_number())
cfe

cfe %>% filter(soc=="33-3012")

# repeat with msa fixed effects
mod3 <- feols(lrwagp ~ edattain + exp + exp2 + sex + marstat + rachisp | soc + as.factor(msacode), data=regdf)
# mod2 <- feols(lwage ~ edattain + exp + exp2 + female + married - 1 | soc, data=regdf)
summary(mod3)  # default clusters on soc
# summary(mod2, cluster= ~ soc)

# tmp <- feols(lwage ~ edattain + sex + exp + exp2 + marstat -1 | soc, data=regdf, demeaned = TRUE)
# fixef(tmp)

# fe <- fixef(mod1)
fe3 <- fixef(mod3)
fe3
plot(fe3)
# summary(fe)
# fe$soc["33-3012"]
# p <- plot(fe)
# p
# str(p)

cfe3 <- tibble(soc=names(fe3$soc), fe=fe3$soc) %>%
  left_join(ocodes, by="soc") %>%
  mutate(cfe=fe - mean(fe)) %>% # centered fixed effects
  arrange(-cfe) %>%
  mutate(rank=row_number())
cfe3




```

# Benefits of correctional officers

# Key conclusions {#conclusions}

```{r}
# get key facts
# nominal wages in 2020
uswage <- keyfacts$corr_oes %>% filter(stabbr=="US", year==2020) %>% .$wage
cawage <- keyfacts$corr_oes %>% filter(stabbr=="CA", year==2020) %>% .$wage
mawage <- keyfacts$corr_oes %>% filter(stabbr=="MA", year==2020) %>% .$wage

# gap vs. U.S. in nominal wages
gap2016 <- keyfacts$wages_oes_time %>% filter(stabbr=="CA", year==2016) %>% .$pdwage
gap2020 <- keyfacts$wages_oes_time %>% filter(stabbr=="CA", year==2020) %>% .$pdwage

# real wages in 2020
df2 <- keyfacts$real_wages_oes %>%
  mutate(rank=rank(desc(rwage)))
rwageca <- keyfacts$corr_oes %>% filter(stabbr=="CA", year==2020) %>% .$rwage
rwagerec2 <- keyfacts$corr_oes %>% 
  filter(year==2020, stabbr %in% state.abb) %>% 
  arrange(-rwage) %>%
  filter(row_number()==2)
rwage2 <- rwagerec2$rwage
rwagename2 <- get_stname(rwagerec2$stabbr)
usrwage <- keyfacts$corr_oes %>% filter(stabbr=="US", year==2020) %>% .$rwage

caltassoc <- keyfacts$corr_summary %>%
  filter(stabbr2=="CA") %>%
  .$ltassoc
mdnltassoc <- median(keyfacts$corr_summary$ltassoc)

calexp <- keyfacts$corr_summary %>%
  filter(stabbr2=="CA") %>%
  .$exp
mdnexp <- median(keyfacts$corr_summary$exp)


# keyfacts$statemod
cacfe <- keyfacts$statecfe %>% filter(stabbr=="CA") %>% .$cfe
cfe2 <- keyfacts$statecfe %>% filter(rank==2) %>% .$cfe
cfename2 <- keyfacts$statecfe %>% filter(rank==2) %>% .$stname

```

1.  Wages

-   Comparisons with correctional officers in other states

    -   California correctional officer wages are the highest in the nation. Before adjusting for cost of living differences, the average wage is `r percent(cawage / mawage - 1, accuracy=.1)` higher than the next-highest state, Massachusetts, and `r percent(cawage / uswage - 1, accuracy=.1)` higher than the U.S.-average correctional officer wage.

    -   California correctional officer wages have been consistently much higher than the United States average for state correctional officers and than the average for the second-highest state, for many years. The gap versus the United States average rose from `r percent(gap2016, .1)` in 2016 to `r percent(gap2020, .1)` in 2020.

    -   California has the highest cost of living in the nation. After adjusting for cost of living, California correctional officer wages are still the highest in the nation. They are `r percent(rwageca / rwage2 -1, accuracy=.1)` above the second-highest state, `r rwagename2`, and `r percent(rwageca / usrwage - 1, accuracy=.1)` above the United States average.

    -   All else equal, we might expect wages to be higher where educational attainment or experience is higher.

        -   About `r percent(caltassoc, accuracy=.1)` of California correctional officers have less than an associate's degree, compared to `r percent(mdnltassoc, accuracy=.1)` in the median state.
        -   The average California correctional officer has about `r number(calexp, accuracy=.1)` years of experience, compared to `r number(mdnexp, accuracy=.1)` in the median state.

    -   After adjusting for cost of living differences and controlling for education, experience, and demographic differences, California correctional officers' wages are about `r percent(cacfe, .1)` above the average state, and `r percent(cacfe / cfe2 -1, .1)` above the second-highest state, `r cfename2`. (This conclusion is based on wage regressions run on a sample of `r comma(nobs(keyfacts$statemod))` correctional officers in the United States.)

2.  Benefits

# Appendix - IGNORE BELOW HERE FOR NOW

## OES data

```{r oes_notes}
# https://www.bls.gov/oes/oes_con.htm
# Two types of OEWS estimates can be downloaded directly from this website in Excel (XLS) format:
# 
# Occupational employment and wage estimates by geographic area (national, state, metropolitan, and nonmetropolitan area)
# National Occupational employment and wage estimates by industry (sector, 3-, 4-, and selected 5- and 6-digit North American Industry Classification System levels)
# Download Occupational Employment and Wage Estimates
# 
# In addition to the estimates that can be downloaded directly from this website, historical OEWS estimates are available upon request through the contact information above. Historical OEWS estimates consist of the 1988 to 1995 national occupational employment and wage data by industry, for most industries at the 2- and 3-digit Standard Industrial Classification (SIC) levels. Estimates for 1988 - 1995 contain only employment data. Between 1988 and 1995 covered industries were surveyed once in a three-year cycle. The OEWS program now surveys all covered industries each year.
# 
# Note: 1996 estimates are not available.
# 
# OEWS State Employment and Wage Estimates
# Occupational Employment and Wage Statistics estimates, by occupation and by industry, for individual states are available from the states' Labor Market Information (LMI) or Research, Analysis, and Statistics offices which are part of their State Employment Security Agencies (SESAs). Availability, format and medium of the data varies by state. To obtain OEWS estimates for a particular state, please contact the appropriate office on the State Contact List.
```

```{r}
# main oes data
# Hi, I'm looking for OES data for states, and possible metro areas, ideally in a single file. I have found the year-by-year state Excel files (https://www.bls.gov/oes/tables.htm) which are awkward to work with but not a bad last resort, and I have found the link for the new OEWS-titled data (https://download.bls.gov/pub/time.series/oe/) but that is only for the latest release. I was hoping you have the historical data in a single csv or flat ASCII file, for all years and states (and maybe metro areas). Would you have a link to a download site for these data? Many thanks in advance. Don Boyd

```

```{r bls_research}
#.. BLS state research estimates ----
# https://www.bls.gov/oes/current/oes_research_estimates.htm
# The OEWS program provides wage and employment estimates by state and industry
# beginning with the May 2012 reference period. These estimates are intended for
# research purposes, and users should be aware of the limitations of the data.
# Estimates prior to May 2012 are not available. Estimates are only available
# for states; industry-specific estimates for metropolitan areas are not
# available. Estimates are only available for detail and major occupation
# groups; industry-specific estimates for broad and minor occupation groups are
# not available.
oes <- readRDS(paste0(resdir, "oesres_sec99.rds"))
glimpse(oes)
count(oes, own_code, o_group)
count(oes, naics_title)

# get 1st-line supervisors and corrections officers
# 33-1011	First-Line Supervisors of Correctional Officers	High school diploma or equivalent
# 33-3012	Correctional Officers and Jailers	High school diploma or equivalent
corr <- oes %>%
  filter(occ %in% c("33-1011", "33-3012"),
         !str_detect(naics_title, "Federal")) %>%
  mutate(level=case_when(str_detect(naics_title, "State") ~ "state",
                         str_detect(naics_title, "Local") ~ "local",
                         TRUE ~ "ERROR"))
count(corr, level, own_code, o_group)
count(corr, naics_title)
count(corr, year, level) %>% pivot_wider(names_from = level, values_from = n)
corr %>% filter(stabbr=="CA", year==2012)
corr %>% filter(is.na(stabbr))
count(corr, stabbr)
summary(corr)  # annual has no data

corr2 <- corr %>%
  filter(stabbr %in% state.abb) %>%
  select(year, occ, occname, stabbr, area=area_title, level, emp=tot_emp, awage=a_mean, awage_mdn=a_median)

corr2 %>% filter(stabbr=="CA")


```

## Graphs and tables of OES research

```{r}

corr2 %>%
  filter(year==2020) %>%
  select(year, occ, occname, stabbr, level, awage) %>%
  pivot_wider(names_from = level, values_from = awage) %>%
  group_by(occ) %>%
  mutate(across(c(state, local), list(rank = ~ rank(-.x)))) %>%
  ungroup %>%
  arrange(occ, state_rank)

cols <- c('#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6')
cols <- c('#a6cee3','#1f78b4','black','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6')

p <- corr2 %>%
  filter(occ=="33-3012", stabbr %in% compstates, level=="state") %>%
  mutate(cadum=ifelse(stabbr=="CA", 1, 0) %>% as.factor) %>%
  arrange(desc(cadum), area) %>%
  ggplot(aes(year, awage / 1000, colour=area)) +
  geom_line(size=1.0) +
  geom_point() +
  scale_colour_manual(values=cols) +
  # scale_size_manual(values=c(1, rep(.5, 8))) +
  labs(y="Average annual wage ($thousands)", x=NULL,
       caption="Source: U.S. Bureau of Labor Statistics, Occupational Employment and Wage Statistics") +
  scale_y_continuous(breaks=seq(0, 200, 10), labels = scales::dollar, limits=c(0, NA)) +
  ggtitle("Average annual salaries of state correctional officers",
          subtitle="California, neighbors, and selected other states") +
  theme_bw() +
  theme(legend.title = element_blank(),
        plot.caption = element_text(hjust = 0))
p
ggsave(here::here("results", "oes_wages.png"), plot = p,
       width=10, height=8, scale=1)


```

## Education requirements

```{r}
# https://www.bls.gov/oes/additional.htm
# The typical education level required to enter an occupation is based on education and training categories from the BLS Employment Projections program. Because of changes to the occupational classification system that began with the May 2019 OEWS estimates and because the entry-level educational requirements assigned to some occupations have changed, the May 2020 OEWS data by typical-entry level educational requirement are not directly comparable to OEWS typical entry-level education data prior to 2019. The May 2020 estimates are based primarily on the system of education and training requirements used for the 2018-2028 employment projections.

# https://www.bls.gov/oes/2020/may/education_2020.xlsx
# 33-1011	First-Line Supervisors of Correctional Officers	High school diploma or equivalent
# 33-3012	Correctional Officers and Jailers	High school diploma or equivalent

# ONETIME
# ujobed <- "https://www.bls.gov/oes/2020/may/education_2020.xlsx"
# download.file(url=ujobed, destfile=here::here("data_raw", "education_2020.xlsx"), mode="wb")
# END ONETIME

jobed1 <- read_excel(here::here("data_raw", "education_2020.xlsx"), sheet = "educ_list", skip=3)
jobed <- jobed1 %>%
  setNames(c("occ", "occname", "entryed"))
count(jobed, entryed)
jobed %>%
  filter(str_sub(occ, 1, 2)=="33")

# get 2020 records in CA for HS jobs
# hsjobs <- jobed %>%
#   filter(entryed=="High school diploma or equivalent")
# 
# oeshs1 <- readRDS(paste0(resdir, "oesres_allsectors.rds")) %>%
#   filter(stabbr=="CA", year==2020, occ %in% hsjobs$occ)
# 
# oeshs2 <- oeshs1 %>%
#   filter(tot_emp >= 1000, i_group=="sector") %>%
#   select(stabbr, year, occ, occname, naics, naics_title, i_group, tot_emp, h_mean, a_mean) %>%
#   arrange(-a_mean)
# 
# 
# oeshs3 <- oeshs1 %>%
#   filter(tot_emp >= 10000, i_group=="sector", 
#          !str_detect(occname, coll("supervisor", ignore_case = TRUE))) %>%
#   select(stabbr, year, occ, occname, naics, naics_title, i_group, tot_emp, h_mean, a_mean) %>%
#   arrange(-a_mean)
# 
# # collapse by occupation ----
# oeshs_mean <- oeshs2 %>%
#   filter(i_group=="sector", 
#          !str_detect(occname, coll("supervisor", ignore_case = TRUE))) %>%
#   mutate(totwage=tot_emp * a_mean) %>%
#   group_by(stabbr, year, occ, occname) %>%
#   summarise(tot_emp=sum(tot_emp), totwage=sum(totwage), .groups = "drop") %>%
#   mutate(awage=totwage / tot_emp) %>%
#   arrange(-awage)
# summary(oeshs_mean)
# 
# tabdata <- oeshs_mean %>%
#   filter(tot_emp >= 10000) %>%
#   arrange(-awage) %>%
#   mutate(rank=row_number()) %>%
#   select(rank, occ, occname, tot_emp, awage)

# alternative approach to tabdata
tabbase <- 
  readRDS(paste0(resdir, "oesres_allsectors.rds")) %>%
  filter(stabbr=="CA", year==2020) %>%# my alternative
  filter(i_group=="sector", !is.na(a_mean), !is.na(tot_emp)) %>% # djb verify this
  select(stabbr, year, occ, occname, naics, naics_title, i_group, tot_emp, h_mean, a_mean) %>%
  # collapse by occupation
  filter(i_group=="sector") %>%
  # filter(!str_detect(occname, coll("supervisor", ignore_case = TRUE))) %>%
  mutate(totwage=tot_emp * a_mean) %>%
  group_by(stabbr, year, occ, occname) %>%
  summarise(tot_emp=sum(tot_emp), totwage=sum(totwage), .groups = "drop") %>%
  mutate(awage=totwage / tot_emp)


# get top 20 jobs by employment plus all other
pct_ltassoc <- 70
ncats <- 40
minemp <- 5000
# 	53-7062
tabdata <- tabbase %>%
  left_join(hscodes %>%
              select(occ=occ2, pct), by="occ") %>%
  filter(pct >= pct_ltassoc) %>%
  arrange(desc(tot_emp)) %>%
  mutate(erank=row_number(),
         # pick one or the other of the following
         keep=ifelse(erank <= ncats, TRUE, FALSE),
         # keep=ifelse(tot_emp >= minemp, TRUE, FALSE),
         # now use it
         egroup=ifelse(keep, erank, 999),
         occ=ifelse(keep, occ, ""),
         occname=ifelse(keep, occname, "  All other")) %>%
  group_by(keep, stabbr, year, occ, occname) %>%
  summarise(tot_emp=sum(tot_emp), totwage=sum(totwage), .groups = "drop") %>%
  mutate(awage=totwage / tot_emp,
         premium=awage[occ=="33-3012"] / awage - 1) %>%
  arrange(desc(keep), -awage) %>%
  mutate(rank=ifelse(keep, row_number(), NA_real_)) %>%
  select(rank, occ, occname, tot_emp, awage, premium)
tabdata

count(tabdata, keep)

tab <- tabdata %>%
  gt() %>%
  tab_header(
    title = "Occupations in California where typical entry education requirement is a high school diploma",
      subtitle = "Public and/or private sector occupations with at least 10,000 employees"
      ) %>%
  cols_label(rank="Rank",
             occ=md("Code"),
             occname=md("Occupation"),
             tot_emp=md("Employment  
                        in 2020"),
             awage=md("Average wage  
                      in 2020")) %>%
  # tab_spanner(
  #   label = "Rate adjustment:",
  #   columns = c(actual, adjust)
  #   ) %>%
  fmt_number(
    columns = c(tot_emp),
    decimals = 0) %>%
  fmt_currency(
    columns = c(awage),
    decimals = 0) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightgrey")
      ),
    locations = cells_body(
      rows=c(1)
      )
    ) %>%
  tab_source_note("Source: Bureau of Labor Statistics Occupational Employment and Wage Statistics, Research Database.")
  # tab_footnote(
  #   footnote = "Source: Bureau of Labor Statistics Occupational Employment and Wage Statistics, Research Database.",
  #   locations = cells_title(groups = "title")
  #   )

tab
# gtsave(tab, filename="hspay.png", path=here::here("results"))
gtsave(tab, filename="hspay_v2.html", path=here::here("results"))


# Most criminal investigators and detectives earn an associate degree in criminal justice or law enforcement, and some earn a bachelor's degree. Most graduate from a police training academy and work as police officers to gain law enforcement experience. A promotion is often required to become a criminal investigator.

#djb: While BLS says that Detectives and Criminal Investigators (the highest paying HS job on the list) typically need a HS diploma for entry, CalHR (https://www.calhr.ca.gov/state-hr-professionals/pages/8610.aspx) says all levels of the criminal investigator series need to have the equivalent of at least 2 years of college. 


# California Correctional Officer requirements
# https://www.cdcr.ca.gov/por/minimum-qualifications-2/minimum-qualifications/
# Graduation from a U.S. high school, G.E.D. or equivalent from a U.S. institution, or a California High School Proficiency Examination (CHSPE) certificate is required, or possession of a college degree (Associate of Arts or higher) from an accredited college or university.

#.. CalHR job requirements ----
# Correctional officer
# https://www.calhr.ca.gov/state-hr-professionals/Pages/9662.aspx
# Education: Equivalent to completion of the twelfth grade.

# Investigator Series
# https://www.calhr.ca.gov/state-hr-professionals/pages/8610.aspx
# Education requirements are more stringent but it is possible to substitute experience for education.
# For example, one of the education requirements is:
# Education: Equivalent to completion of two years of college with a major in criminal justice, law enforcement, criminology, administration of justice, police science, or a comparable field of study. (Additional qualifying experience may be substituted for the required education on a year-for-year basis. Applicants who are being considered for Investigator positions assigned as Peace Officer status (as defined by California state law) must possess the educational equivalent to completion of the twelfth grade.) and


# BLS ----
# https://www.onetonline.org/link/summary/33-3051.00  Police and detectives etc...
# Job Zone: Education	Most occupations in this zone require training in vocational schools, related on-the-job experience, or an associate's degree.

# https://www.onetonline.org/link/summary/33-3012.00 Correctional officer
# Education	These occupations usually require a high school diploma.

# https://www.onetonline.org/link/summary/11-3071.00 Transportation, Storage, and Distribution Managers
# Education	Most of these occupations require a four-year bachelor's degree, but some do not.


```

### Education data development

```{r}
# find jobs with similar education requirements to corrections officers
edir <- r"(E:\data\CA_BU6_project\db_26_0_excel\)"
fnecats <- "Education, Training, and Experience Categories.xlsx"
fneoccs <- "Education, Training, and Experience.xlsx"

ecats1 <- read_excel(paste0(edir, fnecats), sheet=1)
eoccs1 <- read_excel(paste0(edir, fneoccs), sheet=1)

catnames <- c("elid", "elname", "scaleid", "scalename", "cat", "catdesc")
ecats <- ecats1 %>%
  setNames(catnames)

ednames <- c("occ", "occname", "elid", "elname", "scaleid", "scalename", "cat", "pct",
             "n", "se", "lci", "uci", "recsuppress", "date", "domain")
eoccs <- eoccs1 %>%
  setNames(ednames)

#.. edoccs 33-3012.00 ----
# create factors for education
edcodes <- ecats %>%
  filter(scaleid=="RL") %>%
  # create short labels
  mutate(catlabel=case_when(cat == 3 ~ "Post-Secondary Certificate",
                            cat == 7 ~ "Post-Baccalaureate Certificate",
                            cat == 9 ~ "Post-Master's Certificate",
                            cat == 10 ~ "First Professional Degree",
                            TRUE ~      catdesc))

edoccs <- eoccs %>%
  filter(scaleid=="RL") %>%
  select(occ, occname, cat, pct, recsuppress, n) %>%
  left_join(edcodes %>% select(cat, catlabel), by="cat")

# hsjobs <- edoccs %>%
#   filter(cat==2, pct>=80)
# hsjobs %>% 
#   arrange(desc(pct))

# hscodes <- edoccs %>%
#   filter(cat==2, pct>=70) %>%
#   mutate(occ2=str_sub(occ, 1, 7)) %>%
#   .$occ2

hscodes <- edoccs %>%
  filter(cat %in% c(1, 2)) %>%
  group_by(occ, occname) %>%
  summarise(pct=sum(pct), n=sum(n), .groups = "drop") %>%
  mutate(occ2=str_sub(occ, 1, 7)) %>%
  arrange(desc(pct))

hscodes %>% filter(str_detect(occ, "53-7062")) # djb figure this out!!
# also this
# 1-3031.01
# Treasurers and Controllers
# 0.00
# 50
# 11-3031
# 10
# 11-3031.03
# Investment Fund Managers
# 0.00
# 50
# 11-3031
  
hscodes %>% filter(str_detect(occname, "Correction"))  
  

```

## Descriptive statistics from Cal OES

```{r}
count(cal_oes, wtype)
count(cal_oes, atype)


base <- 2009
dflong <- cal_oes %>%
  filter(soc=="333012", wtype=="annual", atype=="state") %>%
  pivot_longer(cols=wage:wp90) %>%
  group_by(name) %>%
  mutate(ivalue=value / value[year==base] * 100 - 100,
         cagr2009=(value / value[year==2009])^(1 / (year - 2009)) * 100 - 100,
         cagr2012=(value / value[year==2012])^(1 / (year - 2012)) * 100 - 100,
         cagr2016=(value / value[year==2016])^(1 / (year - 2016)) * 100 - 100)


cal_oes %>%
  filter(soc=="333012", wtype=="annual", atype=="state") %>%
  ggplot(aes(year, wage)) +
  geom_line() +
  geom_point()

dflong %>%
  ggplot(aes(year, ivalue, colour=name)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(breaks=seq(-50, 50, 5)) +
  geom_hline(yintercept = 0)

dflong %>%
  ggplot(aes(year, cagr2016, colour=name)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(breaks=seq(-50, 50, 0.5)) +
  geom_hline(yintercept = 0)

dflong %>%
  filter(year >= 2012) %>%
  ggplot(aes(year, cagr2012, colour=name)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(breaks=seq(-50, 50, 0.5)) +
  geom_hline(yintercept = 0)


```

## Notes about other studies

### Hedonic wage regressions

```{r eval=FALSE}
# Biggs Illinois
# The sample is limited to individuals who work for the state government or for the private sector; federal employees or employees of non-profits are excluded. The sample also is limited to individuals who work 35 or more hours per week and 50 or more weeks per year. The model used here controls for: Years of education; Undergraduate degree field (for those with a college education and above); Potential work experience (equal to age minus years of education minus 6) and experience-squared; Broad occupation (eight categories); place of residence (based upon the Census Bureau’s Public Use Microdata Areas, or PUMAs); Usual hours of work per week; Gender; Race; Hispanicity; Marital status; Immigrant status; Year; and State government employee. Our model has several key differences that can influence the results. First, we control for the number of hours worked per week. Since Illinois state government employees work about 1.5 fewer hours per week than private sector workers, excluding weekly hours worked makes state government employees appear relatively less well paid. Second, we include a variable for the employee’s undergraduate college major, acknowledging that certain majors lead to higher pay in the workforce than others….Third, we include data on the location within the state in which the employee lives.

# Biggs Illinois
# Wages - hedonic (human capital) - ACS controls vs above:
#   state gov penalty of about 2%, w/no firm size adjustment (add'l penalty of 7.2% if firm size adjust)


```

### Benefits

```{r}
# Biggs Illinois
# p.4 notes they received unpublished ECEC in Biggs and Richwine (2014),
#   for private workers and a small number of public benefits
#   HC, RHC, and pensions drawn from specific sources
# HC:
#   IL -- Pew 2014 -- about 42% higher than private (implies ~ 20.2% of salaries I think)
#   private -- ECEC -- about 14.2% of salaries (must be for region)
# RHC:
#   IL -- NC from AV, div salaries, gives 19.4% 
#   private --  (not in the ECEC)
#     based on Biggs Richwine, which adjusted CBO, data -- nationally 0.5% NC, IL 0.48%
# Pensions:
#   IL -- tot NC of 20.9% adjusted to 41.8% using DR of 5.0% vs. earnings assump of 7.25% (appears
#         to assume 32.7 year - perhaps full career?), less eec of 5.4%,
#         leaving er NC of 36.4%
#   private -- ECEC -- er contribs of 2.6 to DC + 1.4 to DB = 4.0 erc, vs 36.4% public
# Other FB (paid leave - vacation, holiday, personal time); emp prem for life, DB; legally req
#           benefits wf wno AA rZWAM nXewm YUm QX:
#   IL -- ECEC (for region)
#   private -- ECEC (for region)

# Biggs Richwine
# HC: 
  # Our principal source is data compiled by the National Conference of State
  # Legislatures (NCSL).37 These data show monthly employer and employee health
  # premiums for individual and family coverage in 2012. In certain cases, data
  # for 2012 were not available through the NCSL. In these cases we used NCSL
  # data from prior years, adjusted upward by the rate of growth of overall
  # health premiums through 2012. In several other cases, we obtained data
  # directly from state sources, such as budget documents.
#  NCS useful


```
